#!/usr/bin/env python
# Copy data between different machines running jive5a(b(c))
import socket, time, sys, math, copy, itertools, pydoc, re, os, datetime, string, traceback, subprocess, shlex

## Current version
version="$Id$"

## Shorthands
RUN    = subprocess.Popen
SHLEX  = lambda arg: shlex.split(arg) if isinstance(arg, type("")) else arg
STDOUT = lambda cmd: RUN(SHLEX(cmd), stdout=subprocess.PIPE).communicate(None)[0]
LINES  = lambda cmd: STDOUT(cmd).split('\n')

## Support for m5copy acting as interpreter of a text-file, as if the
## text file were executable. m5copy can read from stdin by giving a "-"
## (dash) as last argument on the command line.
##
## The first line in the script (the #! line) is interpreted as template command
## line where occurrences of the form "{n}" will be replaced by the n-th
## field from each uncommented line.
##
##    $> cat copy_files
##    #!/usr/bin/env m5copy -udt -r {0} file://remote.host.ip/{1} file:///path/to/dest/
##    # pull the following files from remote.host.ip to local machine
##    # each file at a different line rate
##    100M /aap/noot/em048a_on_no0001.m5a
##    256k /aap/noot/rk1418.m5a
##    1G   /aap/noot/gm038_od_no0012.vdif
##
##    $> chmod +x copy_files
##    $> ./copy_files
##
## Reading from stdin:
##
##    $> echo /mnt/disk/1/* | m5copy -udt file:///{0} DST -
##    # with "DST" being the destination URL

## We never ever take a file name as command line argument.
## Unless we are being called to interprete a text file, in which case it is
## the final argument. When "./copy_files" is executed (see example above), m5copy
## is called with the following command line:
##
##      sys.argv = ["m5copy", "-udt", "-r", "{0}",
##                  "file://remote.../{1}", "file:///...",
##                  "./copy_files"]
##
## i.e. the name of the script file is appended at the end of the command
## line found in the script file itself.
##
## If the last argument on the command line is '-', we read from stdin
if len(sys.argv)>1 and (os.path.isfile(sys.argv[-1]) or sys.argv[-1]=='-'):
    # Form single string command line, stripping the last element
    cmdLine = " ".join(sys.argv[:-1])

    # Generators that generate lines from different sources of input
    def filereader(fn):
        with open(fn) as f:
            for line in f:
                yield line
        raise StopIteration
    def stdinreader():
        while True:
            try:
                line = raw_input()
                yield line
            except EOFError:
                raise StopIteration

    # Decide where to read from
    linesrc = sys.argv[-1]
    linesrc = stdinreader() if linesrc=='-' else filereader(linesrc)

    # And do it
    for line in linesrc:
        # strip comment and then leading + trailing whitespace
        line = re.sub("#.*$", "", line).strip()
        # if nothing left, go on
        if not line:
            continue
        # Make new commandline and execute it
        cmd = cmdLine.format(*SHLEX(line))
        print "#",cmd
        rv  = RUN( SHLEX(cmd) ).wait()
        if rv!=0:
            print "m5copy exited with non-zero return code {0}".format(rv)
            sys.exit( rv )
    # and we're done
    sys.exit( 0 ) 

# parse jive5ab version number string into a number
# such that we can easily compare
def parse_version(txt):
    # jive5ab versions are X.Y[.Z[(.-)gunk]]
    # find all the sequences that are made solely out of digits -
    # the actual parts of the version number.
    # Then convert to int.
    # Then start multiplying by 10000 for the first version digit and
    # by x/100 for each next digit and add them up.
    return reduce(lambda (vsn, factor), x: (vsn + x*factor, factor/100.0),
                  map(int, re.findall(r"[0-9]+", txt)),
                  (0.0, 10000))[0]

## Bastard Python devs. "datetime.timedelta" objects
## only acquired ".total_seconds()" in 2.7
def total_seconds(td):
    if hasattr(td, 'total_seconds'):
        return td.total_seconds()
    else:
        return  (td.microseconds + (td.seconds + td.days * 24 * 3600) * 10**6) / 10**6

## Standardized date/time format
def timestampNow():
    return datetime.datetime.now().strftime("%Y-%b-%dT%Hh%Mm%Ss")

# A very special type of exception that might be raised
class IgnoreFile(Exception):
    pass


########################################
# Attempt to find the external IP
# address of this machine. On multi-homed
# machines it will return None
#
# This method is used in order to be able
# to set a default external ip address
# in case someone tries to do a network
# copy *into* the local machine (i.e. the
# machine m5copy is running on); in this
# case, the DST::controlip == 127.0.0.1 
# and telling a remote jive5ab to connect
# to that address isn't going to work
# very well, is it?
##########################################
def get_local_ext_ip(unique=True):
    # I've looked all over the 'net but there is
    # no portable Python way to get the
    # available interface addresses, other than
    # executing ifconfig ... (bah!)
    rxIf   = re.compile(r"^(?P<if>[^:]+):?\s+(Link|flags)")
    rxInet = re.compile(r"^\s*inet\s+((addr)?\s*:?\s*)(?P<inet>\S+)")

    # Note: this should never *break* m5copy
    try:
        tmp    = set()
        curIF  = None

        ifconfig = subprocess.Popen(["/sbin/ifconfig", "-a"], stdout=subprocess.PIPE)
        for line in ifconfig.communicate()[0].split('\n'):
            mo = rxIf.match(line)
            if mo:
                curIF = mo.group('if')
                continue
            mo = rxInet.match(line)
            if mo:
                # inspect the inet address; we're definitely skipping
                # 127.0.0.1 and multicast addresses
                inet = mo.group('inet')
                msb  = int( inet.split('.')[0] )
                if not (inet=="127.0.0.1" or (msb>=224 and msb<=239)):
                    tmp.add( inet )
        # tmp is the set of all IP addresses for this machine that are
        # not loopback or multicast
        if unique:
            return tmp.pop() if len(tmp)==1 else None
        else:
            return tmp
    except:
        return None


############################
## Support for 'enums'
##
## X = enum("AAP", "NOOT")
##
## var = X.AAP
##  ...
## if var == X.AAP:
##     ...
############################

class enum(object):
    def __init__(self, *seq):
        self.enums = seq
        for e in self.enums:
            setattr(self, e, e)

    # you can iterate over the enum to find out all defined values
    def __iter__(self):
        class enumiter(object):
            def __init__(self,enuminst):
                self.iterable = enuminst
                self.iter     = iter(enuminst.enums)
            def next(self):
                return getattr(self.iterable, self.iter.next())
        return enumiter(self)

    def __getitem__(self, idx):
        if idx in self.enums:
            return idx
        raise IndexError,"{0} does not exist".format(idx)

## take a list of (pattern, replacement) tuples and run them 
## over the string to produce the final edited string
subber   = lambda acc, (pat, repl): re.sub(pat, repl, acc)
sub      = lambda txt, lst: reduce(subber, lst, txt)

## expands string "1:10,13,20:22" into [1,2,3,4,5,6,7,8,9,10,13,20,21,22]
##   and "5:2" into [5,4,3,2]
##
## Supports arbitrary increments
##    1:10:2 => [1,3,5,7,9]
## Support arithmetic:
##  "2*10:3*10,12-2:12+2"
##  All expressions will be converted to int after evaluating
def expand_string_range(s, rchar=":"):
    rxNum = re.compile(r"^\d+$")
    rxRng = re.compile(r"^(?P<s>[-\d\.+*/%()]+)"+rchar+"(?P<e>[-\d\.+*/%()]+)(:(?P<step>[-+]?\d+))?$")
    def count_from_to(s,e,step):
        while abs(s-e)>=abs(step):
            #print "s:{0} e:{1} diff:{2}".format(s, e, abs(s-e))
            yield s
            s = s + step
        if abs(s-e)<=abs(step):
            yield s
        raise StopIteration
    def mkcounter(item):
        mo = rxRng.match(item)
        if mo:
            # start, end may be expressions
            (s,e) = (int(eval(mo.group('s'))), int(eval(mo.group('e'))))
            defstep = 1 if (s<e) else -1
            step    = mo.group('step')
            step    = int(step) if step else defstep
            # Test if we actually *can* count from start -> end using step:
            # e.g.:    1 -> 10, step -1 isn't going to end very well is it?
            #         -1 -> -10, step 1         ,,           ,,
            # Step size "0" is ONLY allowed if start==end!
            # Also assure ourselves that the step direction and counting
            # direction are identical
            if (not step and (s-e)) or (((e-s) * step )<0):
                raise RuntimeError,"cannot count from {0} to {1} with step {2}".format(s, e, step)
            return count_from_to(s, e, step)
        else:
            mo = rxNum.match(str(eval(item)))
            if not mo:
                raise ValueError, "{0} is not a number! (It's a free man!)".format(item)
            # 'item' may be an expression!
            item = int(eval(item))
            # Note: seems superfluous to return a counter for 1 number but now
            # we have a list of iterables which can easily be transformed into
            # one list via itertools.chain() (see below)
            return count_from_to(item, item, 1)
    return list(itertools.chain(*[mkcounter(x) for x in s.split(",")]))


# given a number + unit, return number between 1.0 and scale +prefix+unit
#  ie.  1024000 "Byte" => "1000 kByte"
def sciprint(num, unit, scale=1000, fmt=".2f"):
    if num<1.0:
        prefixes = ["m", "u", "n", "f", "p", ""] 
        fn       = lambda (n, p), pfx: (n*scale, pfx) if n<1.0 and (n*scale!=n) else (n, p)
    else:
        prefixes = ["k", "M", "G", "T", "P", "E"]
        fn       = lambda (n, p), pfx: (n/scale, pfx) if n>scale else (n, p)
    (n, p) = reduce(fn, prefixes, (float(num), ""))
    return "{0:{n_fmt}} {1}{2}".format(n, p, unit, n_fmt=fmt)



def progress_print(x):
    sys.stdout.write(x)
    sys.stdout.flush()

## A function returning a nice progress update including a bar + percentage, a la scp(1)
def progress(cur, s, e, sz):
    frac = (float(cur - s)/float(e - s)) if e!=s else 0
    pos  = int( frac * sz )
    if pos==0:
        pos = 1
    return "Progress |" + "="*(pos-1) + ">" + " "*(sz-pos)+"| {0:6.2f}%".format(frac*100)


class Progress(object):
    def __init__(self, size):
        self.now       = datetime.datetime.now
        self.size      = size
        self.lastTime  = self.now()
        self.lastCount = 0
        self.maxLen    = 0

    def __call__(self, current, start, end):
        now   = self.now()
        count = (current - start)
        dt    = total_seconds(now - self.lastTime)
        speed = 0.0
        if dt>0:
            speed = (count - self.lastCount) / dt
        txt = "\r" + progress(current, start, end, self.size)+" "+sciprint(speed, "byte/s", 1024)
        self.maxLen = max(self.maxLen, len(txt))
        progress_print( txt + " "*(self.maxLen - len(txt)) )
        self.lastTime  = now
        self.lastCount = count

    def say(self, txt):
        self.maxLen = max(self.maxLen, len(txt))
        progress_print( "\r" + txt + " "*(self.maxLen - len(txt)) )

    def done(self):
        progress_print( "\r" + " "*(self.maxLen) + "\r" )

class DummyProgress(object):
    def __init__(self):
        pass
    def __call__(self, current, start, end):
        pass
    def say(self, txt):
        pass
    def done(self):
        pass

### Sometimes you need a random sequence of 'n' alphanumerical characters
rndChars    = string.letters + string.digits
random_word = lambda n: ''.join(map(lambda x: rndChars[ord(x)%len(rndChars)], os.urandom(n)))
        


############################################################################
## Defaults for the transfer: standard TCP protocol, Mark5 control,data port
############################################################################

mtu            = 1500
ipd            = 0
timeOut        = None
realtime       = False
nthread        = 1
queries        = False
verbose        = True
protocol       = "tcp"
socbuf         = "4M"
dataport       = 2630
duplicates     = False
controlport    = 2620
uri_type       = enum("SRC", "DST")
media_type     = enum("FILE", "DISK", "VBS", "MK6", "IN", "MEM")
bank_type      = enum("A", "B")
uniqSuffix     = lambda scannum: ".scan." + str(scannum)
allowOverwrite = False  # this is a dangerous one ...
ignoreExisting = False
doResume       = False

# jive5ab features that are version dependent
supportsMk6           = parse_version("2.6.0") # jive5ab 2.6.0 and up support mk6/set_disks &cet
supportsEcho          = parse_version("2.6.0") # shutting down command echoing only
                                               # on cmd socket, not globally
supportsTransient     = parse_version("2.7.3") # transient runtimes - they get autmatically
                                               # deleted if the control connection dies
supportsResumeVersion = "2.6.1"
supportsResume        = parse_version(supportsResumeVersion) # net2file has to return the file size for this
                                                             # disk2file has to have a special 'resume' mode

def usage():
    elp = get_local_ext_ip()
    def_dataip= "DST::host (destination control ip/host)" if elp is None else elp
    pydoc.pager( 
"""
Usage: {progname} [options] SRC DST

Copy VLBI data from SRC to DST. Both SRC and or DST may be located on remote
machines; the default is to address data on the local machine. There is a
possibility to force the data over a different network in case there exists a
different/faster network between the SRC and DST machines than the control
network. Please find examples at the end of the documentation.

Options:

    -h        print this message and exit
    -v        print current version and exit
    -q        be quiet, do not display progress (default: {def_verbose})
    -a        allow duplicate scan names on a disk pack to be 
              automatically renamed to <scan>.<scannumber> (default: {def_allow})
    -udt      use UDT as protocol (default: {def_proto})
    -rt       allow real time transfer. Only supported on "in://" and
              "mem://" SRC transfers. If set, it will enable the
              (unreliable) e-VLBI protocol "UDPs" - UDP with sequence number.
    -p <port> use this port number for data channel (default: {def_data_port})
    -m <mtu>  use this MTU (default: {def_mtu})
              Note: only used when using UDT or real-time protocol!
    -r <rate> limit transmit data rate to <rate> bits per second.
              (default: unlimited - as fast as it will go).
              For your convenience you may use the suffixes 'kMG',
              metric thousands ("x1000"), not binary thousands.
              Note: only effective when using UDT!
    -t <#sec> set socket timeout to <#sec> seconds. Note that the
              program may use different time out values yet; m5copy knows
              that some commands generally take longer to complete than
              others. m5copy uses the maximum time out value of the
              internally specified value and the command line supplied
              value, if any.
    -n <num>  use <num> parallel chunk transfers when doing
              flexbuff => flexbuff transfers (default: {def_nthread})
    -mode <X> for some transfers it is necessary to actually know the 
              actual data format. This option exists to manually override
              the automatic detection built in in m5copy (in case it
              misdetects the format) or when it fails to correctly
              determine the format. The mode <X> is given in "libmk5access"
              (cf. W. Brisken) one-string-describes-all format:
                format-datarate-numberOfChannels-bitsPerSample
              e.g.
                mark5b-1024-16-2      for 1Gbps Mark5B
                vdif_8000-8192-32-2   for 8Gbps VDIF with 8000 byte data
                                      array size

    If the destination is "file://" and it already exists, the default
    action for m5copy is to fail: no data will be overwritten. Several
    options can modify this behaviour:

    --ignore_existing  
              Ignore existing FILE(S) on the destination. With this option,
              "wildcard" file transfers can be resumed; files that have
              already been transferred will be skipped over, in stead
              of m5copy exiting. This assumes that files that exist are
              complete.
    --allow_overwrite
              All destination FILE(S) will be overwritten, irrespective of
              their completeness level. Basically this restarts the whole
              transfer as if nothing existed on the remote system.
    --resume
              Existing FILE(s) at the destination that are shorter than
              their corresponding source will be resumed: the bytes missing
              will be appended. The resume does not verify that source and
              destination MD5 sums are equal. If the exact same m5copy
              command is re-run with '--resume', though, it is guaranteed
              that source and destination bytes match.
                

    SRC, DST: uri-like VLBI data locations. Supported formats:

    mk5://[host][:port][:dataip][/BANK|VSN]/<scan id>
        This addresses a scan on a Mark5 disk pack.

        For SRC uri the <scan id> may be a name, number or a comma-
            separated list of numbers or range of numbers: 1-10,13,14.
            The name may contain the wildcard characters '*' or '?' -
            all scan names matching the pattern will be transferred.
            For scan number ranges, the range is inclusive the last number.

        For DST uri the <scan id> will ONLY be interpreted as name;
            we cannot force the scan id number - it depends on what
            is already recorded on the target disk pack. If the name
            happens to be numeric, your scan will be called that.

        The BANK may be provided as "A" or "B" (case insensitive) but is
        optional. If nothing is specified the current active bank on the
        Mark5 will be used.
        
        If something is specified for BANK|VSN and it's not "A" or "B", the
        string will be interpreted as VSN. An error will happen if the given
        VSN cannot be found/switched to on the indicated Mark5.

    file://[host][:port][:dataip]/path/to/(file|dir/)
        Addresses a file or directory on disk (trailing slash means directory).

        In SRC file URIs wildcards '*' and '?' are allowed, provided you're
        running m5copy on the machine itself. Remote wildcards are NOT
        supported. 
        
        SRC file URIs may never address a directory. DST file URIs _MUST_
        name a directory IF the source consists of multiple files/scans.

    mk6://[host][:port]/[DISKS/][recording]
        This makes the system record data in native Mark6 format(*) on the
        indicated machine. Since jive5ab 2.6.1, "mk6://" can be used as
        source URI. In order to transfer a Mark6 recording with older
        versions of jive5ab, mount a Mark6-aware FUSE file system and use
        a "file://" source URI.

        For SRC uri, the [recording] name is not optional.

        On the Mark6 the disks are mounted by module. jive5ab does NOT
        automatically scan all Mark6 modules for recording (this is by
        design). As a result, the user must specify on which disk module (by
        slot number or MSN) should be recorded: the "DISKS/" part of the
        URI.

        DISKS is a comma-separated list of disks, ending with a slash, that
        should be recorded on. Each element in the list can be one of:

            - a Mark6 module slot: "1", "2", "3" or "4" (or sequence
              thereof, like "12")
            - built-in aliases 
                "flexbuff" -> select all available FlexBuff mountpoints
                "mk6"      -> select all mounted Mark6 disk modules
            - a Mark6 module's MSN (if the eMSN file is correctly created
              on the meta data partition)
            - a shell globbing pattern, e.g.:
                /mnt/disks/1/*   (which is what "1" is shorthand for)
            - a fully qualified path:
                /path/to/here

        Examples:

        This will record on the module in slot #3 (needs Mark6 expansion
        chassis):
            m5copy SRC mk6://mark6.jive.nl/3/

        This will record on the modules identified by the MSNs, irrespective
        of in which slot they're mounted:
            m5copy SRC mk6://10.88.0.45/OAN+1234,TEST0001/

        (*) Native Mark6 format is the format version 2 as written by the
        MIT Haystack dplane software.

    vbs://[host][:port][:dataip]/[DISKS/][recording]
        Addresses a vlbi_streamer (vbs) recording on a FlexBuff.  VBS -> VBS
        transfers are an 'rsync' operation rather than a copy. Therefore
        some restrictions apply for those transfers. Since jive5ab 2.6.1
        "vbs://" recordings can also be copied to any of the other, valid,
        destinations.

        In SRC vbs URIs the recording MUST be specified and wildcard
        expansion is only allowed on the local machine.

        On SRC vbs URIs, the "[:dataip]" is not supported. The recording
        name may only be set if the data source is 'mk5://' or 'file://'
        because in VBS -> VBS transfers the name of the recording is
        transferred implicitly; on account of this essentially being an
        rsync operation.

        "DISKS/" is an optional argument for vbs recordings. When given it
        is a comma-separated list of disks, ending with a slash, that should
        be recorded on. See under "mk6://" for a full description of the
        DISKS element.
        
    in://[host][:port]/[amount[kMGs]]
        Addresses the I/O board in the Mark5, to which the formatter or
        DBBC is directly connected to. This is a SRC URI only!

        With this SRC you can take data directly from the telescope and save
        it somewhere: on the local Mark5 or, if the network and the disks
        on the remote system are fast enough too, on a remote system.

        'amount' is the amount of data to capture. If 'amount' is not
        specified, the transfer will run until you cancel the transfer by
        pressing ^C. 
        
        'amount' given without unit means "number of bytes". With unit
        suffix of 'k', 'M' or 'G', the program will attempt to capture as
        close to the amount of bytes, kB, MB or GB as specified. The
        'thousands' here are binary thousands, thus powers of 1024.

        'amount' with unit 's' (for seconds) will capture data for that
        amount of seconds. Again,this is only an approximation.

        When using this SRC, it is assumed that _someone else_ has correctly
        set up the Mark5 mode and play rate or clock setting (Mark5B).

    mem://[host][:port]/[amount[kMGs]]
        Addresses the memory buffer inside jive5ab. If jive5ab is started
        with the '-b' option on the Mark5, recorded data will be mirrored in
        a memory buffer inside jive5ab. This one is also SRC only URI.

        With this SRC you can take data directly from that buffer and save
        it somewhere: on the local Mark5 or, if the network and the disks
        on the remote system are fast enough too, on a remote system.

        The explanation of the 'amount' parameter is identical to that under
        the 'in://' explanation.

        It should be pointed out that with this SRC, if there is no
        recording going on, no data will flow. You can start this transfer
        and it will start the data flow as soon as someone else turns on
        recording. However, if you specified the duration in seconds, the
        time will count from the moment of invocation, irrespective of if
        there is data flowing.

        Just to be absolutely clear about it:

        IF JIVE5AB IS NOT IN BUFFERING MODE, NO DATA WIL BE TRANSFERRED BY
        THIS TRANSFER. EVAR.

        If this statement doesn't mean anything to you but still sounds like
        you want to use this form of transport, contact the author for an
        explanation.


ALL KINDS OF IPv4 ADDRESSES

    The "host" and "port" fields in the URI's are for the CONTROL channel:
    m5copy will send the VSI/S formatted commands to this address.
    
    The "dataip" override field is only allowed in the DST uri. It is
    optional and will override the destination ip/host address (the DST
    control IP) where the data will be sent to.
    
    Typically this option is used to force data over a faster network
    between the SRC and DST machines, bypassing the CONTROL network.

    Note: setting the data port is done using a separate option on the
    command line.

    Defaults are:
        host        localhost/127.0.0.1
        port        {def_ctrl_port}
        dataip      {def_data_ip}


EXAMPLES

    On a Mark5, copy scan 1-10 from local disk => local file ("disk2file").
    Each scan will end up in "/data/<scanname>.m5a":

        m5copy mk5:///1-10 file:///data/

    Extract scan 200 and rename it:

        m5copy mk5:///200 file:///data/scan200.m5a

    You can force the scans of a specific experiment to be read from a
    specific VSN:

        m5copy mk5:///cmva-007/ek035* file:///data/

    Or from a specific bank:

        m5copy mk5:///B/*ef* file:///data/

    Do a file server => Mark5 copy, forcing data to to a specific VSN,
    "file2net2disk". Each file will become a new scan on the disk pack with
    the name of the file with its extension removed:

        m5copy file:///data/gr* mk5://10.88.0.50/jod+017/

    Do a remote disk2file; i.e. trigger a local disk2file on a Mark5 from
    e.g. your control computer ("remote disk2file"):

        m5copy mk5://10.88.0.50/1-10 file://10.88.0.50/data/

    Push data from a specified VSN loaded in a remote Mark5 to a directory
    on a remote file server. Assume the Mark5 and file server's "control"
    IPv4 addresses are on the 10.88.0.* subnet and there is a high-speed
    data link between the Mark5 and the file server over a different IPv4
    subnet, 192.42.120.*. The file server has IPv4 addresses
    10.88.0.22 (control) and 192.42.120.110 (fat data pipe).

    Using this form of m5copy ensures the data will go over the fast
    192.42.120.* network whilst the control commands are sent over the
    normal network, "disk2net2file". The SRC jive5ab will be told to open
    the data connection to "dataip=192.42.120.110":

        m5copy mk5://10.88.0.50/ file://10.88.0.22::192.42.120.110/data/


    Copy 512MB of data directly from the I/O board to a remote file:

        m5copy in://effelsberg.ip.address/512M file://io11.mpg-bonn.de/data/

""".format(progname=sys.argv[0], def_proto=protocol, def_data_port=dataport, \
           def_ctrl_port=controlport, def_mtu=mtu, def_verbose=verbose, \
           def_nthread=nthread, def_allow=duplicates, def_data_ip=def_dataip) )


# One-liner to split a list of things into two lists, one satisfying the predicate, the other not
partition = lambda p, l: reduce(lambda (y,n), x: (y+[x], n) if p(x) else (y, n+[x]), l, ([], []))

######
# Utils
######


# will always resolve to IPv4 address such that 
# user can mix names/ip-addresses and the system will
# still compare them equal (provided they resolve to
# the same IPv4 address, of course)
def resolve_ip(host_or_ip):
    # the socket.getaddrinfo returns a list of 5-element tuples
    # we only want the IPv4 address out of the 5th element ("(ip, port)")
    # and we default to the first returned entry for the host
    try:
        return socket.getaddrinfo(host_or_ip, 0, socket.AF_INET, socket.SOCK_STREAM)[0][4][0]
    except:
        print "Failed to resolve the following name '{0}'".format(host_or_ip)
        sys.exit( -4 )


rxBytenumOffset  = re.compile(r"^(?P<sign>[-+])?(?P<amount>[0-9]+)(?P<scale>[kMG])?$")
rxBytenumRate    = re.compile(r"^(?P<sign>\+)?(?P<amount>[0-9]+(\.[0-9]*)?|\.[0-9]+)(?P<scale>[kMG])?$")
scaleTableBinary = {'k': 1024, 'M':1024*1024, 'G': 1024*1024*1024, '':1, None:1}
scaleTableMetric = {'k': 1000, 'M':1000000, 'G': 1000000000, '':1, None:1}

def procByte(bn, tp, rxBytenum, scaleTable):
    mo = rxBytenum.match(bn)
    if not mo:
        raise RuntimeError, "{0}: invalid byte number".format(bn)
    # passed the regex test, now we can do stuff
    amount = tp(mo.group('amount'))
    scale  = mo.group('scale')
    sign   = mo.group('sign')
    if scale:
        amount *= scaleTable[scale]
    return (sign if sign else '')+str(amount)

rxAbsByteNumber = re.compile("^[0-9]+$")
def isAbsoluteByteNumber(bn):
    return bn is not None and rxAbsByteNumber.match(bn)

def isRelativeToEnd(bn):
    return bn is not None and bn[0]=='-'

def isRelativeToStart(bn):
    return bn is not None and bn[0]=='+'

# Make an object out of attributes+values
def mkobj(**attrs):
    return reduce( lambda acc, (k,v): setattr(acc, k, v) or acc, attrs.iteritems(), \
        type('', (), {'__str__': lambda self: "{" + ": ".join(["{0}={1}".format(a, getattr(self, a)) for a in attrs]) + "}"})() )

def mkse():
    return mkobj(startByte=None, endByte=None)

# process start/end byte numbers for disk2net transfer
# in: startbyte, endbyte, alreadyhave
# out: object with two attributes
#       .scan_set = object w/ attributes .startByte, .endByte
#       .disk2net =     id.
# containing the byte number strings to pass
# in the corresponding phase of the transfer
def seByte2net(startByte, endByte, alreadyHave):
    rv = mkobj( scan_set=mkse(), disk2net=mkse() )

    ss  = rv.scan_set
    d2n = rv.disk2net
    # any byte number can be:
    #   num, -num, +num, time, -time, +time
    #
    # start byte numbers that must be given in scan_set are:
    #    -num, +num, time, -time, +time
    #
    # in disk2net only absolute byte numbers can be given,
    # apart from end byte, which may be '+num' to indicate
    # relative to start
    abStart       = isAbsoluteByteNumber(startByte)
    abEnd         = isAbsoluteByteNumber(endByte)
    endRelToStart = isRelativeToStart(endByte)

    if abStart:
        # must be given in disk2net. Must account for
        # bytes already there.
        d2n.startByte = int(startByte)

        if alreadyHave:
            d2n.startByte = d2n.startByte + alreadyHave

        # does end follow start?
        if endRelToStart:
            # we can only support numbers here, no times!
            # because we have to go through the 'disk2file' method
            try:
                eb = int(endByte)
            except ValueError:
                raise RuntimeError, "Cannot have absolute byte start combined with time duration"
            # do we have to account for bytes already received?
            if alreadyHave:
                eb = eb - alreadyHave
                if eb<0:
                    raise RuntimeError, "The remote file has more bytes than requested via +amount"
            # make sure it comes out as relative to start (ie leading '+')
            d2n.endByte = "+"+str( eb )


    # non-absolute byte numbers/times must be set in scan_set
    if startByte and not abStart:
        # everything going into scan set is unaffected 
        # by the fact if there are bytes already there
        ss.startByte = startByte
        if endRelToStart:
            ss.endByte = endByte

    # If an endByte was given, it depends on what it was (number, time,
    # absolute or relative) to where it goes.
    # Take care: one case of endByte has already been dealt with.
    if endByte and not (abStart and endRelToStart):
        # absolute byte number can only be given in one place
        # unaffected by amount of bytes already there
        if abEnd:
            d2n.endByte = endByte
        else:
            # it's not absolute nor relative to start
            # we assume it's a time and thus it must go
            # into scan_set
            ss.endByte = endByte

    # disk2net start offset None and alreadyHave not None?
    if d2n.startByte is None and alreadyHave is not None:
        d2n.startByte = "+"+str(alreadyHave)
    return rv

# process start/end byte for disk2file / scan_set combo.
# because disk2file has a special 'resume' file-open mode,
# we don't have to deal with 'alreadyHave'
def seByte2file(startByte, endByte):
    rv = mkobj( scan_set=mkse(), disk2file=mkse() )

    ss  = rv.scan_set
    d2f = rv.disk2file
    # any byte number can be:
    #   num, -num, +num, time, -time, +time
    #
    # start byte numbers that must be given in scan_set are:
    #    -num, +num, time, -time, +time
    #
    # in disk2file only absolute byte numbers can be given,
    # apart from end byte, which may be '+num' to indicate
    # relative to start
    if startByte:
        # absolute byte numbers can only be given in disk2file
        # everything else goes into scan_set
        if isAbsoluteByteNumber(startByte):
            d2f.startByte = startByte
        else:
            ss.startByte  = startByte

    if endByte:
        # same as with startByte
        if isAbsoluteByteNumber(endByte):
            d2f.endByte   = endByte
        else:
            ss.endByte    = endByte
    return rv


def seString(bn):
    return "" if bn is None else bn

class URI(object):
    ## define a static method - the URI factory
    @staticmethod
    def makeURI(src_or_dst, media):
        if src_or_dst==uri_type.SRC:
            return SourceURI(media, src_or_dst)
        elif src_or_dst==uri_type.DST:
            return DestURI(media, src_or_dst)
        else:
            raise ValueError, "Cannot create neither a source or dest URI type"

    def __init__(self, media, src_or_dst):
        self.direction   = src_or_dst
        # who to talk to
        self.controlIP   = None
        self.controlPort = None

        # will be "media_type.FILE" or "media_type.DISK" or "media_type.VBS"
        if not media in media_type:
            raise RuntimeError, "Unrecognized media type '{0}'".format(media)
        self.mediaType   = media

        # contents of path will depend on 
        # media type
        self.path        = None

    def get_direction(self):
        return self.direction

    def __str__(self):
        # do we have these attributes?
        haveSE  = (hasattr(self,'startByte') and hasattr(self, 'endByte'))
        # are any of these not None?
        needSE  = haveSE and (self.startByte or self.endByte)
        # then we possibly need to tag them on
        seBytes = (":"+ (self.startByte if self.startByte else "") + ":" + (self.endByte if self.endByte else "")) if needSE else ''
        return "{0}::{1} [{2}:{3}{4}] {5}{6}{7}".format(self.direction, self.mediaType, self.controlIP, self.controlPort, \
                                                (":"+(self.dataIP if self.dataIP else "<controlIP>") if hasattr(self,'dataIP') else ""), \
                                                ((self.bank+"/" if self.bank else "") if hasattr(self, 'bank') else ""), self.path, \
                                                seBytes)

    def parseStartEndByte(self, sb, eb, strict=False):
        # if any of the start/end bytes are set and we
        # do not have one of the attributes ... 
        if (sb or eb) and not (hasattr(self, 'startByte') and hasattr(self, 'endByte')):
            raise RuntimeError, "{0} does not support configuring start and/or end byte number".format(str(self))

        # try to convert [kMG] to numbers, if that fails, look at strict parameter
        # wether or not it's allowed to #fail
        if sb:
            try:
                self.startByte = procByte(sb, int, rxBytenumOffset, scaleTableBinary)
            except:
                if strict:
                    raise
                # ok, pass on value unmodified
                self.startByte = sb
        
        if eb:
            try:
                self.endByte = procByte(eb, int, rxBytenumOffset, scaleTableBinary)
            except:
                if strict:
                    raise
                # ok, pass on value unmodified
                self.endByte = eb

class SourceURI(URI):
    def __init__(self, media, src_or_dst):
        super(SourceURI, self).__init__(media, src_or_dst)

        # Some URIs support start, end byte
        # These will be *functions* which both will be 
        # passed the current start and end byte of the scan
        # being processed such they can do the appropriate offset
        # magic (eg negative numbers work from the end etc),
        # but always only on data source(s)
        self.startByte   = None
        self.endByte     = None

        if self.mediaType==media_type.DISK:
            self.bank    = None
            self.VSN     = None



class DestURI(URI):
    def __init__(self, media, src_or_dst):
        super(DestURI, self).__init__(media, src_or_dst)
        self.dataIP      = None

        if self.mediaType==media_type.DISK:
            self.bank    = None
            self.VSN     = None


rxDisk    = re.compile(r"^mk5:")
rxFile    = re.compile(r"^file:")
rxVBS     = re.compile(r"^(?P<type>vbs|mk6):")
rxINorMEM = re.compile("^(?P<type>in|mem):")

## For URI parsing we must know if we're parsing source or destination
## URI's. 'src_or_dst' is an 'enum' (see below)
def parseURI(uri, src_or_dst):
    if rxDisk.match(uri):
        return parseDisk(uri, src_or_dst)
    elif rxFile.match(uri):
        return parseFile(uri, src_or_dst )
    elif rxVBS.match(uri):
        return parseVBS(uri, src_or_dst )
    elif rxINorMEM.match(uri):
        return parseINorMEM(uri, src_or_dst )
    else:
        raise ValueError, "Unrecognized URI '{0}'".format(uri)


## Not loosely modelled after jive5ab's OPTARG macro, honestly .... ;-)
def OPTARG(lst, n, default=None):
    try:
        return lst[n] if len(lst[n]) else default
    except IndexError:
        return default


# supported:
#  mk5://[host][:port][:dataip]/[BANK|VSN/]<scanname:scanids>[:[<start>][:<end>|+<amount>]]
# So, before the first "/" is all kind of host/ip/port crap.
# note that "[:dataip]" is only supported on source URIs
def parseDisk(uri_org, src_or_dst):
    uri = re.sub("^mk5:", "", uri_org)
    rv = URI.makeURI(src_or_dst, media_type.DISK)

    # the host/port/dataip is between the leading double slash and the third
    # slash
    mo = re.match(r"^//([^/]*)/", uri)
    if not mo:
        raise RuntimeError, "{0}: invalid - does not match //.../".format(uri_org)
    hoststuff = mo.group(1)

    # now that we have matched the hoststuff out of it, we can take it out
    # of the URI
    path = re.sub(r"^//[^/]*/", "", uri)

    # any slashes remaining in the path means that a bank/vsn was passed
    slashed = path.split("/")
    if len(slashed)>2:
        raise RuntimeError, "{0}: invalid - too many slashes in bank/scan part".format(uri_org)

    # the last part is always the scanid/number
    # On a source disk, we MUST have a scan name, on DST it *may* be a scan name
    b, p = (None, None)
    if len(slashed)==2:
        (b, p) = slashed
    else:
        p = path

    # Did anyone mention start/end byte?
    p_split = p.split(':')
    rv.path = p_split[0]  # path is always the first bit

    if rv.direction==uri_type.SRC:
        if not rv.path:
            raise RuntimeError, "{0}: source URI MUST have a scan name/id".format(uri_org)

    # if there's a leading part, it's the bank/vsn
    if b:
        b = b.upper()
        if not b in bank_type:
            # must be VSN then
            if hasattr(rv, 'VSN'):
                rv.VSN = b
            else:
                raise RuntimeError, "{0}: media type {1} does not support setting VSN to {2}".format(uri_org, rv.mediaType, b)
        else:
            if hasattr(rv, 'bank'):
                rv.bank = b
            else:
                raise RuntimeError, "{0}: media type {1} does not support setting bank to {2}".format(uri_org, rv.mediaType, b)

    # Now parse the host/port stuff
    colonized = hoststuff.split(':')

    # Length check - at most three entries
    if len(colonized)>3:
        raise RuntimeError, "{0}: invalid 'host:port:dataip' part".format(uri_org)

    # Because we have the ":"'s separating the entries we only need to
    # verify if they exist at all
    rv.controlIP   = resolve_ip(OPTARG(colonized, 0, "localhost"))
    rv.controlPort = OPTARG(colonized, 1, controlport)
    if rv.controlPort:
        rv.controlPort = int(rv.controlPort)

    # Only dst-type URI's parse the data ip;
    # so we only set the value if the URI object _has_ that
    # attribute
    dataip = OPTARG(colonized, 2)
    if dataip:
        if hasattr(rv, 'dataIP'):
            rv.dataIP = resolve_ip(dataip)
        else:
            raise RuntimeError, "{0} does support setting of dataip ({1})".format(uri_org, src_or_dst)

    # Save the start/end byte number parsing for last such that the URI is filled in
    rv.parseStartEndByte( OPTARG(p_split, 1), OPTARG(p_split, 2) )
    return rv


## Supported:  (the leading "file:" has already been stripped)
##  file://[host][:port][:dataip]/path/to/file[:[<start>][:<end>|+<amount>]]
# note that "[:dataip]" is only supported on source URIs
# also not that for file URI's the start/end byte numbers should really
# only be numbers. This is enforced
def parseFile(uri_org, src_or_dst):
    uri = re.sub("^file:", "", uri_org)
    rv = URI.makeURI(src_or_dst, media_type.FILE)

    # the host/port/dataip is between the leading double slash and the third
    # slash
    mo = re.match(r"//([^/]*)/", uri)
    if not mo:
        raise RuntimeError, "{0}: invalid - does not match //.../".format(uri_org)
    hoststuff = mo.group(1)

    # now that we have matched the hoststuff out of it, we can take it out
    # of the URI
    p = re.sub(r"^//[^/]*", "", uri)

    # Did anyone mention start/end byte?
    p_split = p.split(':')
    rv.path = p_split[0]  # path is always the first bit - start/end is last (below)

    # On source file name we MUST have a filename
    if rv.direction==uri_type.SRC:
        if len(rv.path)<=1:
            raise RuntimeError, "{0}: source URI MUST have a file/path".format(uri_org)

    # Now parse the host/port stuff
    colonized = hoststuff.split(':')

    # Length check - at most three entries
    if len(colonized)>3:
        raise RuntimeError, "{0}: invalid 'host:port:dataip' part".format(uri_org)

    # Because we have the ":"'s separating the entries we only need to
    # verify if they exist at all
    rv.controlIP   = resolve_ip(OPTARG(colonized, 0, "localhost"))
    rv.controlPort = OPTARG(colonized, 1, controlport)
    if rv.controlPort:
        rv.controlPort = int(rv.controlPort)

    # Only source-type URI's parse the data ip;
    # so we only set the value if the URI object _has_ that
    # attribute
    dataip = OPTARG(colonized, 2)
    if dataip:
        if hasattr(rv, 'dataIP'):
            rv.dataIP = resolve_ip(dataip)
        else:
            raise RuntimeError, "{0} does not support setting of dataip ({1})".format(uri_org, src_or_dst)

    # Save the start/end byte number parsing for last such that the URI is filled in
    rv.parseStartEndByte( OPTARG(p_split, 1), OPTARG(p_split, 2), strict=True)
    return rv

# 'vbs' is a vlbi-streamer recording on a flexbuff
#  at the moment this one does *not* support 'slicing', i.e.
#  no start/end byte specification. (not anymore true since 2.6.1)
#
#
#   vbs://[host][:port][:dataip]/recording
#   
#   since 2.6.1
#     vbs://..../recording[:[start][:[end]]]
#
#   since 2.6.0:
#     [vbs|mk6]://[host][:port][:dataip]/[disks/]recording
#
#   with "disks" a "," separated list of patterns for jive5ab's built-in
#   "set_disks" command.
#     Useful shortcuts:
#          "flexbuf" => /mnt/disk[0-9]+         (FlexBuff disks)
#          "[1234]+" => /mnt/disks/<num>/[0-7]  (Mark6 disks)
#                       Can also be "MSN" for Mark6
#          "^pattern$" => hand-crafted regex
#
# note that "[:dataip]" is only supported on source URIs
def parseVBS(uri_org, src_or_dst):
    tp  = rxVBS.match(uri_org).group('type')
    uri = re.sub("^(vbs|mk6):", "", uri_org)
    rv  = URI.makeURI(src_or_dst, media_type.VBS if tp=="vbs" else media_type.MK6)

    # Was this a mk6:// ... / ?
    if tp=="mk6":
        # Set the 'mark6' attribute
        rv.mark6 = True

    # the host/port/dataip is between the leading double slash and the third
    # slash
    mo = re.match(r"//([^/]*)/", uri)
    if not mo:
        raise RuntimeError, "{0}: invalid - does not match //.../".format(uri_org)
    hoststuff = mo.group(1)

    # now that we have matched the hoststuff out of it, we can take it out
    # of the URI
    rv.path = re.sub(r"^//[^/]*/", "", uri)

    # Did anyone mention start/end byte?
    p_split = rv.path.split(':')
    rv.path = p_split[0]  # path is always the first bit - start/end is last (below)

    # On source vbs we MUST have a recording name
    if rv.direction==uri_type.SRC:
        if not rv.path:
            raise RuntimeError, "{0}: source URI MUST have a recording name".format(uri_org)

    # find the last slash - if any. If there are any non-zero parts left
    # they're the DISKS selection and the recording name
    lastslash = rv.path.rfind('/')
    if lastslash!=-1:
        # only set disks attribute IF there are any disks to be set
        disks   = rv.path[0:lastslash]
        if disks:
            rv.disks = disks
        rv.path = rv.path[lastslash+1:]

    # Now parse the host/port stuff
    colonized = hoststuff.split(':')

    # Length check - at most three entries
    if len(colonized)>3:
        raise RuntimeError, "{0}: invalid 'host:port:dataip' part".format(uri_org)

    # Because we have the ":"'s separating the entries we only need to
    # verify if they exist at all
    rv.controlIP   = resolve_ip(OPTARG(colonized, 0, "localhost"))
    rv.controlPort = OPTARG(colonized, 1, controlport)
    if rv.controlPort:
        rv.controlPort = int(rv.controlPort)

    # Only source-type URI's parse the data ip;
    # so we only set the value if the URI object _has_ that
    # attribute
    dataip = OPTARG(colonized, 2)
    if dataip:
        if hasattr(rv, 'dataIP'):
            rv.dataIP = resolve_ip(dataip)
        else:
            raise RuntimeError, "{0} does not support setting of dataip ({1})".format(uri_org, src_or_dst)

    # Save the start/end byte number parsing for last such that the URI is filled in
    rv.parseStartEndByte(OPTARG(p_split, 1), OPTARG(p_split, 2))
    return rv


# 'in'  is the I/O board on Mark5A/B or C
#       this one is only supported as SRC uri
# 'mem' is reading data from the memory buffer
#       that is in jive5ab. We do not know
#       who put it there but we can read it!
#
# Because 'in' and 'mem' are basically identical in usage, we 
# parse them both in one method
#
#   (in|mem)://[host][:port][:dataip]/[[0-9]+[kMGs]]
#      the optional <number>[kMGs] is the amount of bytes (kMG) or
#      seconds (s) to transfer.
#      No unit implies 'just bytes'
#      If amount is in bytes, it will be an approximation; an attempt
#      will be made to retrieve the specified amount of bytes.
#      Default is to transfer indefinitely - can be stopped using ^C
rxAmount = re.compile(r"^(?P<amount>[0-9]+)(?P<unit>[kMGs])?$")
def parseINorMEM(uri_org, src_or_dst):
    if src_or_dst==uri_type.DST:
        raise RuntimeError, "{0} can only be used as SRC".format(uri_org)

    # Before removing the prefix, capture what it was!
    tp  = rxINorMEM.match(uri_org).group('type')
    uri = re.sub("^(in|mem):", "", uri_org)

    if tp=='in':
        rv  = URI.makeURI(src_or_dst, media_type.IN)
    elif tp=='mem':
        rv  = URI.makeURI(src_or_dst, media_type.MEM)

    # the host/port/dataip is between the leading double slash and the third
    # slash
    mo = re.match(r"//([^/]*)/", uri)
    if not mo:
        raise RuntimeError, "{0}: invalid - does not match //.../".format(uri_org)
    hoststuff = mo.group(1)

    # now that we have matched the hoststuff out of it, we can take it out
    # of the URI
    rv.path = re.sub(r"^//[^/]*/", "", uri)

    # Was there an amount of bytes/time specified?
    # (i.e. something left after taking out the initial part of the uri)
    # Note: at this point we only _verify_ that the 'path' matches.
    #       interpretation of the string will be done in the actual
    #       reading function
    if rv.path:
        if not rxAmount.match(rv.path):
            raise RuntimeError, "{0} - invalid amount of bytes/seconds specified".format(uri_org)

    # Now parse the host/port stuff
    colonized = hoststuff.split(':')

    # Length check - at most three entries
    if len(colonized)>3:
        raise RuntimeError, "{0}: invalid 'host:port:dataip' part".format(uri_org)

    # Because we have the ":"'s separating the entries we only need to
    # verify if they exist at all
    rv.controlIP   = resolve_ip(OPTARG(colonized, 0, "localhost"))
    rv.controlPort = OPTARG(colonized, 1, controlport)
    if rv.controlPort:
        rv.controlPort = int(rv.controlPort)

    # Only source-type URI's parse the data ip;
    # so we only set the value if the URI object _has_ that
    # attribute
    dataip = OPTARG(colonized, 2)
    if dataip:
        if hasattr(rv, 'dataIP'):
            rv.dataIP = resolve_ip(dataip)
        else:
            raise RuntimeError, "{0} does not support setting of dataip ({1})".format(uri_org, src_or_dst)
    return rv

###########################################
#              cornerturning support
###########################################


# Get nr of bits per sample out of the canonical mode
#  MKIVx_y-datarate-nchannel-bitpersample
#  VLBAx_y-datarate-nchannel-bitpersample
#  MARK5B-datarate-nchannel-bitpersample
rxMode = re.compile(r"^(((?P<mk4vlba>MKIV|VLBA)(?P<fanout1>\d)_(?P<fanout2>\d))|MARK5B)-(?P<rate>\d+)-\d+-(?P<bps>\d+)$", re.I)

# Split the VDIF params into an object with attributes
#   -vdif station:framesize[:[threads][:bpsample]]
def vdif_props(v):
    return reduce(lambda acc, ((at, fn), v): setattr(acc, at, fn(v)) or acc,
                  zip([("station", lambda x:x), ("framesize", int), ("threads", lambda x:x), ("bitspersample",int)], v.split(':')),
                  type('', (), {})())

# predefined modes => cornerturning setups
known_modes = {
        'MKIV1_2-256-8-2':  "8Ch2bit1to2_hv",
        'MKIV1_2-512-8-2':  "8Ch2bit1to2_hv",               # 32 tracks 1:2 fanout
        'MKIV1_2-512-16-2':  "32bitx2 + 8Ch2bit1to2_hv*1",    # 64 tracks 1:2 fanout
        'MKIV1_2-1024-16-2':  "32bitx2 + 8Ch2bit1to2_hv*1",    # 64 tracks 1:2 fanout
        'MKIV1_4-1024-16-2':"32bitx2 + 8Ch2bit1to4_hv",   # 64 tracks 1:4 fanout
        'MARK5B-1024-16-2': "16bitx2 + 8Ch2bit_hv*4",# 1024Mbps 16ch Mk5B
        'MARK5B-512-8-2':   "8Ch2bit_hv",          # 512Mbps  8ch  Mk5B
        'MARK5B-512-16-2':   "16bitx2 + 8Ch2bit_hv*4",# 512Mbps  16ch  Mk5B
}

do_corner   = False
mode        = None     # set from cmdline
vdif        = None     # set from cmdline
cornerturn  = None     # maybe set from cmdline

# Return list of commands + cornerturn recipe + vdif properties + output data format
# In case we do cornerturning, there is a format translation
# and as such, the output format of the data does not match
# the input format anymore

def ct_setup_commands(ct_cmd):
    # if cornerturn recipe not given, check if it is one of the known ones
    m          = mode.upper()
    ct_method  = (known_modes[m] if m in known_modes else None) if cornerturn is None else cornerturn
    if ct_method is None:
        raise RuntimeError, "No cornerturning known for {0}, specify '-ct ...' to run".format(mode)
    vd_props   = vdif_props(vdif)
    if not hasattr(vd_props, 'threads'):
        vd_props.threads = "0-15"
        print "cornerturn setup: no VDIF thread selection given, defaulting to {0}".format(vd_props.threads)

    # check fanout and bits-per-sample
    mo = rxMode.match(m)
    if not mo:
        raise RuntimeError, "Mode {0} is not like  <FORMAT>-<RATE>-<N_CHANNEL>-<BITSPERSAMPLE>".format(mode)
    # bits per channel is not necessarily == bits per sample; especially during fan-out
    # (with fan-out 1:2, there are twice as many bits for each sample as one would expect)
    # Mode (MarkIV|VLBA)<fanout1>_<fanout2>-....
    bps = int(mo.group('bps'))
    if mo.group('mk4vlba'):
        fo1 = int(mo.group('fanout1'))
        fo2 = int(mo.group('fanout2'))
    else:
        fo1 = fo2 = 1
    bpc = bps
    if fo2>fo1:
        bpc = bpc * (fo2 / fo1)
    # the output data format will always be legacy vdif, fully cornerturned (i.e. one channel per frame)
    oFmt = "VDIFL_{framesize}-{rate}-1-{bps}".format(framesize=vd_props.framesize, rate=mo.group('rate'), bps=bps)
    return  (
        [
            "mode={0}".format(mode),
            "{0}=bitspersample:{1}".format(ct_cmd, bps),
            "{0}=bitsperchannel:{1}".format(ct_cmd, bpc),
            "{0}=station:{1}".format(ct_cmd, vd_props.station),
            "{0}=vdifsize:{1}".format(ct_cmd, vd_props.framesize)
        ],
        ct_method, vd_props, oFmt )
    

###########################
# VSI-S command/reply stuff
###########################

def split_reply(reply):
    end_index = reply.rfind(';')
    if end_index != -1:
        reply = reply[:end_index]
    separator_index = reply.find('=')
    if separator_index == -1:
        separator_index = reply.find('?')
        if separator_index == -1:
            return [reply]

    return map(lambda x: x.strip(), [reply[0:separator_index]] + reply[separator_index+1:].split(':'))

## Facilitate communication with a Mark5
class Mark5(object):
    anyReturn = range(0,9)

    def __init__(self, address, port, timeout=5):
        self.version_s     = None
        self.timeout       = timeout
        self.connect_point = (address, port)
        self.socket        = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        self.socket.settimeout(self.timeout)
        try:
            self.socket.connect(self.connect_point)
        except:
            raise RuntimeError, "Failed to connect to {0}".format(self.connect_point)
   
    def get_type(self):
        return self.send_query("dts_id?")[2]

    def get_program(self):
        self.get_version_s()
        return self.version_s[2]

    def get_version(self):
        self.get_version_s()
        return self.version_s[3]

    def get_version_s(self):
        if self.version_s is None:
            # this query should only return "0", not even "1"!
            self.version_s = self.send_query("version?", [0])

    def send_query(self, query, acceptable_codes=[0,1], timeout=None):
        if queries:
            print datetime.datetime.now(),self.connect_point,"Qry:",query

        # decide on the timeout to use
        toInternal = self.timeout if timeout is None else timeout
        toGlobal   = toInternal if timeOut is None else max(timeOut, toInternal)
        self.socket.settimeout(toGlobal)
        self.socket.send(query + (";" if query[-1]!=';' else "") + "\n\r")
        try:
            orgreply = self.socket.recv(1024).strip()
        except socket.timeout:
            # uh-oh
            raise RuntimeError, "Socket timeout after {0}s waiting for reply to: {1}".format(toGlobal, query)
        if queries:
            print datetime.datetime.now(),self.connect_point,"Reply:",orgreply
        reply = split_reply(orgreply)
        if not int(reply[1]) in acceptable_codes:
            raise RuntimeError, "Unacceptable return code {0} from query '{1}' - {2} [acceptable: {3}]".format(int(reply[1]), query, orgreply, acceptable_codes)
        return reply

    def location(self):
        return ":".join(map(str, self.connect_point))

    ## attempt to switch to bank 'bank' on the Mark5
    ## indicated by 'ctrl', assumed to be a 'Mark5' object
    def switch_bank(self, bank):
        bank    = bank.upper()
        actbank = self.send_query("bank_info?")[2].upper()
        if actbank!=bank:
            # issue the bank switch command
            reply = self.send_query("bank_set={0}".format(bank), [1])
            # wait for it to complete
            while True:
                time.sleep(1)
                reply = self.send_query("bank_set?", [0, 6])
                if reply[1]=="0":
                    break
            # verify it's a different bank than we started with
            if actbank==reply[2].upper():
                reply = self.send_query("error?")
                raise RuntimeError, "{0} could not switch to bank {1} [{2}]".format(self.location(), bank, ":".join(reply[3:]))
        return actbank

    # Attempt to switch to the bank containing the indicated VSN
    def switch_vsn(self, vsn):
        vsn = vsn.upper()

        # query which VSNs are currently loaded
        #  0          1   2       3         4       5
        #  !bank_set? 0 : [AB-] : <vsn>|- : [BA-] : <vsn>|- ;
        # Create a mapping of VSN => bank
        reply = self.send_query("bank_set?", [0])
        def proc_entry(acc, idx):
            # extract [<bank>, <vsn>]
            sel = reply[idx:idx+2]
            # if bank or vsn == '-': 
            #     'inactive bank' or 'no module loaded'
            if not "-" in sel:
                # Note: <vsn> is typically  <vsn>/<capacity>/<speed>
                acc[ sel[1].upper().split('/')[0] ] = sel[0].upper()
            return acc
        vsnbankmap = reduce(proc_entry, [2,4], {})
        if not vsn in vsnbankmap:
            raise RuntimeError, "{0} VSN {1} not found on this machine".format(self.location(), vsn)
        return self.switch_bank(vsnbankmap[vsn])

# default configuration for jive5ab for m5copy - separate it from direct
# Mark5 control class
class Jive5AB(Mark5):
    def __init__(self, address, port, timeout=5, runtime=None, bs="2M", modeless=True):
        super(Jive5AB, self).__init__(address, port, timeout)

        # do we have jive5* running on that connection?
        self.program = self.get_program()
        if not re.search("^jive5", self.program):
            raise RuntimeError, "{0}:{1} is not running a version of jive5a(b(c))".format(address, port)

        # get the version of jive5ab
        self.version_num= parse_version( self.get_version() )

        # Save the values of things that we're going to overwrite
        # Note: we set the ipd on both ends, even though it is
        #       only useful for the sender, and then only when UDT
        #       is used
        self.runtime    = copy.deepcopy(runtime)
        self.oldRuntime = None
        self.prevState  = {}

        # If we're going to create a new runtime there's no
        # point in saving the state anyway ....
        if self.runtime:
            # newer versions of jive5ab allow transient runtimes - they get
            # auto-cleared if the control connection goes.
            rtmode = "transient" if self.version_num>=supportsTransient else "new"

            self.oldRuntime = self.send_query("runtime?", [0])[2]
            self.send_query("runtime={0}:{1}".format(runtime, rtmode), [0])
        else:
            self.save( ["net_protocol", "mtu", "ipd", "net_port"] )

        if modeless:
            self.send_query("mode=none", [0])
        self.send_query("net_protocol={0:s}:{2}:{1}".format(protocol, bs, socbuf), [0])
        self.send_query("mtu={0:d}".format(mtu), [0])
        self.send_query("ipd={0}ns".format(ipd))
        self.send_query("net_port={0:d}".format(dataport), [0])

    def version(self):
        return self.version_num

    def save(self, cmdlist):
        self.prevState = dict(zip(cmdlist, map(lambda x: self.send_query(x+"?", [0]), cmdlist)))

    def restore(self):
        for (k,v) in self.prevState.iteritems():
            self.send_query(k+"="+":".join(v[2:]))
        if self.oldRuntime:
            self.send_query("runtime={0}:delete".format(self.runtime))
            self.send_query("runtime={0}".format(self.oldRuntime))

    def echo_on(self):
        # only do this when talking to jive5ab which properly
        # supports it
        if self.version_num >= supportsEcho:
            # accept 'succes' or 'no such command'
            self.send_query("echo=on", [0])

    def echo_off(self):
        # see comment under "echo_on(self)"
        if self.version_num >= supportsEcho:
            # accept 'succes' or 'no such command'
            self.send_query("echo=off", [0])

####################################################################
##
##    For many transfers it's necessary to know the format
##    of the data being transferred.
##    This code allows for automatic format detection 
##    by parsing the output of "scan_check?" or "file_check?"
##
####################################################################


# method 1. "scan_set=..." followed by "scan_check?"
# method 2. "file_check?"
# method 3. "mode?"  (for when taking data from the 'scope directly)
# Input to both methods is the jive5ab we're talking to and the 
# scan name (ignored for "mode?")

def scan_check(jive5ab, scan):
    # force succesful scan_set=, scan_check?
    jive5ab.send_query("scan_set={0}".format(scan.name()), [0])
    # !scan_check = 0 : <scan #> : <scan name> : <interesting gunk>
    # 0             1   2          3             4 
    reply = jive5ab.send_query("scan_check?", [0])
    if reply[3]!=scan.name():
        raise RuntimeError, "After scan_set={0}, scan_check? reports {1}".format(scan.name(), reply[3])
    # strip all the non-interesting bits from the reply
    return reply[4:]

def file_check(jive5ab, scan):
    # !file_check? = 0 : <interesting gunk>
    # 0              1   2
    # Only return <interesting gunk> to caller
    return jive5ab.send_query("file_check ? : : {0}".format(scan.name()), [0])[2:]

def mode_check(jive5ab, scan):
    # As we're apparently taking data directly from the hardware
    # we can extract the format from the "mode?" parameter
    # We must be sure to direct our query to runtime 0; the only one
    # having the real hardware settings

    # save current runtime
    # !runtime? 0 : <current> [: <more gunk>]
    # 0         1   2
    runtime = jive5ab.send_query("runtime?", [0])[2]
    # switch to 0 and query
    jive5ab.send_query("runtime=0", [0])
    mode    = jive5ab.send_query("mode?", [0])
    # before throwing exceptions &cet, go back to original runtime
    jive5ab.send_query("runtime={0}".format(runtime), [0])

    # if we get:
    # !mode? 0 : <one string>
    # 0      1   2
    # the system was configured using 'magic mode'
    if len(mode)==3:
        return [mode[2]]

    # !mode? 0 : <data mode> : <data submode> [ : <decimation (on Mk5B)> ]
    # 0      1   2             3                  4
    # on mark5b we need clock_set? to get the track bit rate, otherwise
    # we use play_rate?
    m5b     = (mode[2]=='ext') # we don't support Mark5B modes 'tvg' and 'ramp'
    m5a     = (mode[2] in ['mark4', 'vlba'] or 'mark5a+' in mode[2]) # we don't support 5a modes 'st', 'tvg'
    if m5b:
        # !clock_set? 0 : <freq> : <src> : <genfreq>
        cs = jive5ab.send_query("clock_set?", [0])
        # should we take decimation into account? On Mark5B:
        # !mode? 0 : ext : <mask> : <decimation>
        # 0      1   2     3        4
        dcm     = int(mode[4])
        trkrate = int( float(cs[2])/dcm )
        # translate bit stream mask to #-of-tracks
        ntrk    = "{0}".format( bin(int(mode[3])).count("1") )
    elif m5a:
        # !play_rate? 0 : <track bit rate> : <track clock rate> : <clockgen freq>
        # 0           1   2
        pr      = jive5ab.send_query("play_rate?", [0])
        trkrate = int( pr[2] )
        ntrk    = mode[3]
    else:
        raise RuntimeError, "The code does not support mode '{0}'".format(" ".join(mode))

    # let's make a reply that is similar to file_check/scan_check (faking/not filling in some of the
    # fields we know the caller won't be using anyway):
    #  <data mode> : <data submode> : <start time> : <scan length> : <track data rate> : <missing bytes>
    return [mode[2], ntrk, "", "", "{0}Mbps".format(trkrate), "0"]

# method must be one of 'scan_check', 'file_check' or 'mode_check'. All methods
# do some pre-processing on the reply to make sure 'detect_mode' only
# receives the relevant bits of information.
# (the output of file_check?, scan_check? and mode? differ slightly
hw_mode_map = { 'mark4': 'MKIV1_1', 
        'vlba': 'VLBA1_1',
        'ext' : 'MARK5B',
        # Mark5B format detected by Mark5B/DIM
        '-': 'MARK5B',
        # mark5b playback on Mk5A
        'mark5a+0': 'MARK5B',
        'mark5a+1': 'MARK5B',
        'mark5a+2': 'MARK5B' }

rxTrackRate = re.compile(r"^(?P<rate>\d+)(Mbps)?$")

def print_retval(func):
    def do_it(*args, **kwargs):
        rv = func(*args, **kwargs)
        print "RETURNVALUE:",rv
        return rv
    return do_it

def detect_mode(jive5ab, scan, method):
    # get the reply from the jive5ab for the given scan using the given
    # method
    mode = method(jive5ab, scan)
    if queries:
        print "detect_mode(..,{0},..) = {1}".format(scan.name(), mode) 

    # reply from scan_check/file_check/mode_check is:
    #  [<data mode> , <data submode> , <start time> , <scan length> , <track data rate> , <missing bytes> {,<vdif frame sz>}]
    #   0             1                2              3               4                   5                 6
    # or:
    #  [<magic mode>]

    # if mode only gave one word, the system is in 'magic' mode - cf.
    # W.Brisken libmk5access one-string-sets-all format
    # so we're done quickly in that case.
    # It could also be that file_check/scan_check failed to detect the format,
    # in which case it would return a single '?'
    if len(mode)==1:
        if mode[0]=='?':
            raise RuntimeError, "{0}: the data format could not be deduced".format(scan)
        return mode[0]

    # first parameter typically encodes the format
    fmt  = mode[0].lower()

    # if fmt == 'st' ('straight through') we don't support that
    if fmt in ['st', 'ss', 'ramp', 'tvg' ] or 'tvg' in fmt:
        raise RuntimeError, "{0}: unsupported data format {1}".format(scan, fmt)

    # ok, 2nd parameter is #-of-tracks ...
    # Mark5B/DIM scan_check? returns '-' for Mark5B data and does not return #-of-tracks
    # it should return the total recording rate though
    if fmt=='-':
        ntrk    = 32
        trkrate = int(rxTrackRate.match( mode[4] ).group('rate'))/ntrk
    else:
        ntrk    = int( mode[1] ) if (mode[1] and mode[1]!='?') else 1
        trkrate = int(rxTrackRate.match( mode[4] ).group('rate'))

    # hardware mark4/mark5b modes are 'mark4', 'vlba', 'ext', '-' [we don't do
    # 'tvg', 'ss', test pattern &cet], typically as returned by 'mode?'
    if fmt in hw_mode_map:
        fmt     = hw_mode_map[fmt]
        # There must be some way of figuring out fan-in/fan-out on Mk4/VLBA formats?
        # the most important information is the number of
        return "{0}-{1}-{2}-2".format(fmt, ntrk*trkrate, (ntrk/2))
   
    # if we have VDIF, the only two interesting bits of information are:
    #  1. is it legacy vdif or not?
    #  2. what is the data array size?
    if 'vdif' in fmt:
        # if scan_check/file_check have detected VDIF, jive5ab 2.6.1 and up
        # append the vdif frame size to the output. Without that info we 
        # cannot autodetect ...
        if len(mode)<7:
            raise RuntimeError, "The source jive5ab is too old for correct VDIF frame size detection. Upgrade to {0} (or later) or specify the format manually via '-mode ...'".format( supportsResumeVersion )
        return "VDIF{0}_{1}-{2}-{3}-2".format("L" if 'legacy' in fmt else "", int(mode[6]) - (16 if 'legacy' in fmt else 32), ntrk*trkrate, ntrk/2)

    if fmt=='mark5b':
        return "MARK5B-{0}-{1}-2".format(ntrk*trkrate, ntrk/2)

    raise RuntimeError, "{0}: automatic format detection failed (was: {0})".format(" ".join(mode))

    
####################################################################
##
##  The model is:
##    a Source or Dest URI is passed to a DataSource or DataSink
##    the DataSource yields Scans to be transferred
##    Depending on the actual transfer a Source and Dest XFER
##    are created such that we can easily couple different
##    sources and destinations
##
####################################################################

class Scan(object):
    # no 'constructor', the only interesting bit is the interface
    # I know that in Python we could use 'duck typing' such that
    # the different objects only need to adhere to the same interface
    # but in my book that's called inheritance :D
    def name(self):
        raise RuntimeError,"Not implemented"

class DiskScan(Scan):
    def __init__(self, (num, name), **kwargs):
        self.scanId = (num, name)
        # set optianal extra attribute(s)
        self.__dict__.update( kwargs )

    def name( self ):
        return self.scanId[1]

class FileScan(Scan):
    def __init__(self, name):
        self.scanId = name

    def name( self ):
        return self.scanId


#####################################################################
##
## base classes for a xfer
##
##  DataSources must allow iteration over themselves; each iteration
##    step should yield the name of a transferrable unit. So even if
##    the URI addressed only a single unit, it should iterator over
##    a list of length one.
##
##  DataSinks:
## 
##    * must support computing an output name, given an input
##    name. Each data sink must be able to tell wether it allows
##    multiple names to be computed. E.g. the FileDest only allows
##    computation of multiple names IF it addresses a directory. If a 
##    specific name was given "/dir/file[.ext]" then obviously it
##    cannot compute >1 name. 
##    For the DiskDest this is similar; if an output scan name was
##    explicitly given, no more scan names can be computed
##
##    * must be able to tell wether they can compute multiple output
##    names such that the s/w can verify if the user has made an error
##    by specifying >1 input transferrable units and one specific output
##    name
##
##    * must be able to tell the dataIP to which the data must be sent
##
#####################################################################


class DataSource(Jive5AB):
    def __init__(self, src, runtime=None, modeless=True):
        self.source  = src
        super(DataSource, self).__init__(self.source.controlIP, self.source.controlPort, runtime=runtime, modeless=modeless)

    # must return a list of source paths
    def __iter__(self):
        raise RuntimeError, "Someone forgot to implement this one"
    def __next__(self):
        raise RuntimeError, "Someone forgot to implement this one"

    def cleanup(self):
        raise RuntimeError, "Someone forgot to implement this one"

    def startByte(self):
        return self.source.startByte

    def endByte(self):
        return self.source.endByte

    def location(self):
        return self.source.controlIP+"::"

class DataSink(Jive5AB):
    def __init__(self, dst, runtime=None):
        self.destination = dst
        super(DataSink, self).__init__(self.destination.controlIP, self.destination.controlPort, runtime=runtime)

    # Is the DataSink configured to support >1 output names?
    def multiple_outputs(self):
        raise RuntimeError, "Someone forgot to implement this one!"

    # Compute the output name of the given input
    def compute_outputname(self, input):
        raise RuntimeError, "Someone forgot to implement this one!"

    def cleanup(self):
        raise RuntimeError, "Someone forgot to implement this one"

    def dataIP(self):
        DST = self.destination
        return DST.dataIP if hasattr(DST, 'dataIP') and DST.dataIP is not None else DST.controlIP

    def location(self):
        return self.destination.controlIP+"::"


#########################################
##
##   Concrete derivatives of 
##        the base classes 
##
##########################################


#################### the sources ############################

## Mark5 disk pack as source
class DiskSource(DataSource):
    def __init__(self, location):
        super(DiskSource, self).__init__(location)

        SRC  = self.source

        # Select the requested bank or VSN, if one was given.
        # Note: bank and VSN are mutually exclusive at most one
        #       of them is actually set
        if SRC.bank:
            self.switch_bank(SRC.bank)
        if SRC.VSN:
            self.switch_vsn(SRC.VSN)

        # Look at the location - if it's made out of numbers, dashes and commas
        # it's a list of scan numbers, otherwise a scan name(s)
        rxNums = re.compile(r"^([0-9]+(-[0-9]+)?)(,([0-9]+(-[0-9]+)?))*$")

        filter_f = None
        if SRC.path=="*":
            # Short circuit for all scans
            filter_f = lambda x : True
        elif rxNums.match(SRC.path):
            scanids = set(expand_string_range(SRC.path, '-'))
            filter_f = lambda (num, name): num in scanids
        else:
            # replace "*" by ".*" and "?" by "."
            path     = sub(SRC.path, [("\.","\."), ("\*", ".*"), ("\+", "\+"), ("\?",".")])
            scanname = re.compile(r"^"+path+"$")
            filter_f = lambda (num, name): scanname.match(name)

        # Get the list of scans and immediately filter them
        nscan    = int(self.send_query("dir_info?", [0])[2])

        def get_scan(i):
            self.send_query("scan_set={0:d}".format(i), [0])
            r = self.send_query("scan_set?", [0])
            if int(r[2])!=i:
                raise RuntimeError, "Scan {0} failed to set".format(i)
            return (i, r[3])

        self.scanList = map(lambda x: DiskScan(x), \
                            filter(filter_f, map(get_scan, xrange(1, nscan+1))))

        # Check for duplicate names - if there are, either fix them or
        # fail with an error + hint as to what the user should do to fix
        # this
        names = set(map(lambda x: x.name(), self.scanList))
        if len(names)<len(self.scanList):
            # uh-oh. duplicate names!
            if not duplicates:
                raise RuntimeError, "Duplicate scan names found in your scan " + \
                                    "selection. Re-run with '-a' flag " + \
                                    "(see help) to have m5copy rename them " + \
                                    "on the output"
            # Step 1. figure out the names of the scans that have duplicates
            def countert(acc, scan):
                acc[scan.name()] = acc.get(scan.name(), 0) + 1
                return acc
            dupnames = map(lambda (k, v): k, filter(lambda (k,v): v>1, reduce(countert, self.scanList, {}).iteritems()))
            # Step 2. rename scans that have duplicate names
            def renamert( diskscan ):
                (num, name) = diskscan.scanId
                if name in dupnames:
                    return DiskScan( (num, name+uniqSuffix(num)), duplicate=True )
                else:
                    return diskscan
            self.scanList = map(renamert, self.scanList)

    # implement the DataSource part
    def __iter__(self):
        return iter(self.scanList)

    def __len__(self):
        return len(self.scanList)

    def location(self):
        SRC = self.source
        return super(DiskSource, self).location() + (SRC.bank+"/" if SRC.bank else (SRC.VSN+"/" if SRC.VSN else ""))

    def cleanup(self):
        self.restore()


class FileSource(DataSource):
    def __init__(self, location):
        # file transfers are done in a different runtime
        super(FileSource, self).__init__(location, runtime=random_word(8))

        # we cannot retrieve the list of files remotely
        # but only locally
        SRC  = self.source
        self.pathList         = [SRC.path]
        (self.dir, self.file) = os.path.split(SRC.path)

        # do we need to do wildcard processing?
        if '*' in SRC.path or '?' in SRC.path:
            if SRC.controlIP != '127.0.0.1':
                raise RuntimeError, "Unfortunately we do not support wildcards in file names on remote systems"
            # Check if path contains wildcards. Only allow those
            # in the file name part
            (dir, file) = os.path.split( SRC.path )
            if '*' in dir or '?' in dir:
                raise RuntimeError, "Wildcards not allowed in directory names"
            # we now know that the wildcard, if present, must reside in the file part
            # replace "*" by ".*" and "?" by "." in the file name
            # (also escape regex special chars)
            file     = sub(file, [("\.", "\."), ("\*", ".*"), ("\+", "\+"), ("\?",".")])
            filename = re.compile(r"^"+file+"$")
            # Only consider files located in 'dir'
            self.pathList = []
            for (root, dirs, files) in os.walk(dir):
                if root!=dir:
                    dirs = []
                    continue
                # use the reduce structure such that we do not _overwrite_ self.pathList
                # but append to it
                self.pathList = reduce( \
                    lambda acc, p: acc+[os.path.join(root,p)] if filename.match(p) else acc, \
                    files, self.pathList )

        self.pathList = map(lambda x: FileScan(x), self.pathList)

    def __iter__(self):
        return iter(self.pathList)

    def __len__(self):
        return len(self.pathList)

    def location(self):
        return super(FileSource, self).location()

    def cleanup(self):
        self.restore()


class VBSSource(DataSource):
    def __init__(self, location):
        # We can support >1 vbs synchronization / FlexBuff
        # by doing it in multiple runtimes
        super(VBSSource, self).__init__(location, runtime=random_word(8))

        SRC  = self.source
        self.pathList = [SRC.path]

        # do we need to do wildcard processing?
        if '*' in SRC.path or '?' in SRC.path:
            if SRC.controlIP != '127.0.0.1':
                raise RuntimeError, "Unfortunately we do not support wildcards in file names on remote systems"
            # Note: the parseVBS has already guaranteed that the path
            # contains no slashes. Do regex special char escaping as well
            # as translating "*" into ".*" and "?" into "."
            path     = copy.copy(SRC.path)
            path     = sub(path, [("\.", "\."), ("\*", ".*"), ("\+", "\+"), ("\?",".")])
            rxRecord = re.compile(r"^"+path+"$")
            rxDisk   = re.compile(r"^disk[0-9]+$")
            rxRecDir = re.compile(r"^/mnt/disk[0-9]+$")
            rxPath   = re.compile(r"^/mnt/disk[0-9]+/(?P<recording>"+path+")$")
            rxFile   = re.compile(r"^"+path+"\.[0-9]{8}$")

            # On the FlexBuff all recordings reside under 
            # /mnt/disk[0-9]+/<recording>
            # Maybe we should filter out only the recordings (1) matching
            # the pattern (d'oh) but also those that actually contain
            # *data*!
            # vlbi_streamer data files are found:
            #   /mnt/disk[0-9]+/<recording>/<recording>.[0-9]{8} 
            #  i.e. files with basename <recording> and an 8-digit sequence
            #  number
            recordingset  = set()
            for (root, dirs, files) in os.walk("/mnt"):
                # in "/mnt" we only consider the "dirs" that match the
                # "disk[0-9]+"
                if root=="/mnt":
                    dirs = filter(lambda x: rxDisk.match(x), dirs)
                    continue
                # In <root>'s matching "/mnt/disk[0-9]+", we only 
                # consider "dirs" that match the recording
                if rxRecDir.match(root):
                    dirs = filter(lambda x: rxRecord.match(x), dirs)
                    continue
                # In <root>'s actually matching
                # /mnt/disk[0-]+/<recording>/ we look for
                # files matching "<recording>.[0-9]{8}"
                mo = rxPath.match(root)
                if mo:
                    # if we find any files matching, the recording
                    # can be added
                    if len(filter(lambda x: rxFile.match(x), files)):
                        recordingset.add( mo.group('recording') )
            self.pathList = list(recordingset)
        self.pathList = map(lambda x: FileScan(x), self.pathList)

    def __iter__(self):
        return iter(self.pathList)

    def __len__(self):
        return len(self.pathList)

    def location(self):
        return super(VBSSource, self).location()

    def cleanup(self):
        self.restore()

## Mark5 I/O board as data source
class InSource(DataSource):
    def __init__(self, location):
        # we do *NOT* want to run 'modeless' (i.e. "mode=none")
        super(InSource, self).__init__(location, modeless=False)

        # we must verify that the jive5ab we're talking to
        # actually HAS an I/O board
        dtsid = self.send_query("dts_id?")
        if not ("mark5" in dtsid[2].lower()):
            raise RuntimeError, "Data Source is not Mark5 - does not have an I/O board"

        # we have only one 'scan'
        # let's generate a scan name that makes some sense
        # like "<date>-<mode>
        self.scanList = [ FileScan('_'.join( [timestampNow()] + self.send_query("mode?")[2:])) ]

    # implement the DataSource part
    def __iter__(self):
        return iter(self.scanList)

    def __len__(self):
        return len(self.scanList)

    def location(self):
        return super(InSource, self).location()

    def cleanup(self):
        self.restore()

## jive5ab interchainqueue as source
class MemSource(DataSource):
    def __init__(self, location):
        # we *DO* want to run 'modeless' (i.e. "mode=none")
        super(MemSource, self).__init__(location, modeless=True, runtime=random_word(9))

        # we have only one 'scan'
        # let's generate a scan name that makes some sense
        # like "<date>-<mode>
        self.scanList = [ FileScan('_'.join( ["mem", timestampNow()])) ]

    # implement the DataSource part
    def __iter__(self):
        return iter(self.scanList)

    def __len__(self):
        return len(self.scanList)

    def location(self):
        return super(MemSource, self).location()

    def cleanup(self):
        self.restore()

#################### the destinations ############################

class FileDest(DataSink):
    def __init__(self, location):
        # Do the transfer in a different runtime
        super(FileDest, self).__init__(location, runtime=random_word(8))
        
        # Split the destination into path/file
        DST                   = self.destination
        (self.dir, self.file) = os.path.split(DST.path)

    def location(self):
        return super(FileDest, self).location()

    # Is the DataSink configured to support >1 output names?
    def multiple_outputs(self):
        # Yes we are if the "self.file" part is null/empty
        return not self.file

    # Compute the output name of the given input.

    # If we were constructed with an explicit file as path, then we return
    # the path we were created with, otherwise the concatenation of self.dir
    # + the input name. Append extension ".m5a" if necessary
    def compute_outputname(self, input):
        if self.file:
            return self.destination.path
        else:
            # have to split input into path/file before appending to *our* dir
            (_dir, file) = os.path.split(input.name())
            # check if the the input has an extension. If not, append it
            (base, ext)  = os.path.splitext(file)
            if not ext:
                ext = ".m5a"
            return os.path.join(self.dir, base+ext)

    def cleanup(self):
        self.restore()

class DiskDest(DataSink):
    def __init__(self, location):
        super(DiskDest, self).__init__(location)

        DST  = self.destination

        # Select the requested bank or VSN, if one was given.
        # Note: bank and VSN are mutually exclusive at most one
        #       of them is actually set
        if DST.bank:
            self.switch_bank(DST.bank)
        if DST.VSN:
            self.switch_vsn(DST.VSN)

    def location(self):
        DST = self.destination
        return super(DiskDest, self).location() + (DST.bank+"/" if DST.bank else (DST.VSN+"/" if DST.VSN else ""))

    # Is the DataSink configured to support >1 output names?
    def multiple_outputs(self):
        # Yes we are if no specific scan (==path) was configured when we
        # were created
        return not self.destination.path

    # Compute the output name of the given input.

    # If we were constructed with an explicit path, then we return the path
    # we were created with, otherwise it will be the basename of the input
    # with extension removed.
    # This means it works for "/full/path/to/file.m5a" as well as "gr036_ef_no0001"
    def compute_outputname(self, input):
        if self.destination.path:
            return self.destination.path
        else:
            # ok, first split into (dir, file)
            (_dir, file) = os.path.split(input.name())
            # strip extension
            return os.path.splitext(file)[0]

    def cleanup(self):
        self.restore()

class VBSDest(DataSink):
    def __init__(self, location):
        # Do the transfer in a different runtime
        super(VBSDest, self).__init__(location, runtime=random_word(8))

    def location(self):
        return super(VBSDest, self).location()

    # Is the DataSink configured to support >1 output names?
    def multiple_outputs(self):
        # Yes we are if no specific scan (==path) was configured when we
        # were created OR if the path was '/dev/null'!
        return not self.destination.path or self.destination.path=='/dev/null'

    # Compute the output name of the given input.

    # If we were constructed with an explicit path, then we return the path
    # we were created with, otherwise it will be the basename of the input
    # with extension removed.
    # This means it works for "/full/path/to/file.m5a" as well as "gr036_ef_no0001"
    def compute_outputname(self, input):
        if self.destination.path:
            return self.destination.path
        else:
            # ok, first split into (dir, file)
            (_dir, file) = os.path.split(input.name())
            # strip extension
            return os.path.splitext(file)[0]

    def cleanup(self):
        self.restore()


#####################################################################################
##
##
##                  The actual transfers
##
##
#####################################################################################


class SourceXFER(object):
    # interface for source xfers
    def __init__(self, source):
        self.DataSource = source

    # start transferring data from scan 'scan' to the destination 'dataip'
    def start(self, scan, dataip, **kwargs):
        raise RuntimeError, "Someone forgot to implement SourceXFER::start()"

    # In case the source did something to the data, sending out a different
    # flavour than taking in, we must be able to tell what it is outputting
    def outputFormat(self, *args):
        raise RuntimeError, "Someone forgot to implement SourceXFER::outputFormat()"

    # return tuple with (start, current, end) if xfer still running,
    # None if transfer is finished
    def progress(self):
        raise RuntimeError, "Someone forgot to implement SourceXFER::progress()"

    # must be cancellable
    def cancel(self):
        raise RuntimeError, "Someone forgot to implement SourceXFER::cancel()"

class DestXFER(object):
    def __init__(self, sink):
        self.DataSink = sink

    # open output for accepting output into 'output'
    def open(self, output):
        raise RuntimeError, "Someone forgot to implement DestXFER::open()"

    # we must be able to take in a different format than was origianally
    # read - a format translation may have taken place
    def setInputFormat(self, fmt):
        raise RuntimeError, "Someone forgot to implement DestXFER::setInputFormat()"

    # return received byte count. Typically the transfer will
    # wait until this number has stabilized, so be sure to return
    # the same number if the transfer is inactive or has finished
    # (in case you can tell)
    def rcv_bytecount(self):
        raise RuntimeError, "Someone forgot to implement DestXFER::rcv_bytecount()"

    # must be cancellable
    def cancel(self):
        raise RuntimeError, "Someone forgot to implement DestXFER::cancel()"

    # we force every destination xfer to indicate wether or not they 
    # need to know the data format
    def needFormat(self):
        raise RuntimeError, "Someone forgot to implement DestXFER::needFormat()"


####### Actual concrete transfers

# A disk2file is both ... we must introduce a class variable
# to let the destination part and source path communicate with
# each other
class disk2file(SourceXFER, DestXFER):
    outputFileName = None

    def __init__(self, src_or_dst):
        # look at what flavour we were initialized with to decide
        # which of our base classes should be initialized
        if isinstance(src_or_dst, DataSource):
            self.isSource = True
            SourceXFER.__init__(self, src_or_dst)
        else:
            self.isSource = False
            DestXFER.__init__(self, src_or_dst)

    #### Both types (SourceXFER and DestXFER) should be 
    #### cancellable
    def cancel(self):
        if self.isSource:
            self.DataSource.send_query("reset=abort", Mark5.anyReturn)
        else:
            disk2file.outputFileName = None

    #### This is the SourceXFER part of the transfer
    def outputFormat(self, *args):
        # no need to detect the data format; disk2file is local
        return None

    def start(self, scan, dataip, **kwargs):
        # shorthand to the control interface
        CTRL = self.DataSource

        # complain if resume is requested but can't be honoured
        if doResume and CTRL.version()<supportsResume:
            loc = re.sub(":", "", CTRL.location())
            raise RuntimeError, "Resume requested but the jive5ab at {0} is too old (<{1})".format( loc, supportsResumeVersion )

        # disk2file transfer is always coming from a DiskSource
        # (in case it isn't this is an error) so the "scanIds" that
        # are passed into us are really tuples, "(scan number, scan name)"
        (scanNum, scanName) = scan.scanId

        # resuming disk2file is handled differently from disk2net+net2*
        # must be a special mode, see below.
        se = seByte2file(CTRL.startByte(), CTRL.endByte())

        # Attempt to set the correct scan and verify it did set.
        CTRL.send_query("scan_set={0:d}:{1}:{2}".format(scanNum, seString(se.scan_set.startByte),
                                                        seString(se.scan_set.endByte)), [0])
        reply = CTRL.send_query("scan_set?", [0])
        # If the current disk scan was marked as duplicate, it means
        # that some unique suffix has been appended. We must strip
        # that name to do our consistency checking
        if hasattr(scan, 'duplicate'):
            suffix = uniqSuffix(scanNum)
            if scanName.endswith(suffix):
                # Ok, modify scan name
                # Find the right-most uniqSuffix(). Suppose that by chance
                # the scan with name "name.scan.2" would end up in scan
                # postions #1 and  #2 (duplicated) on the disk pack.
                # then the 2nd uniquefied scan name would be:
                #    "name.scan.2.scan.2"
                # if we then do string.sub(".scan.2", "") it would replace 
                # *both* instances instead of only the last one
                # making our test for the scan's existence on the disk pack
                # fail!
                sidx = scanName.rfind(suffix)
                if sidx<0:
                    raise RuntimeError, "Could not find unique suffix whilst it should be there?!"
                scanName = scanName[0:sidx]
            else:
                raise RuntimeError, \
                        "Scan #{0} ({1}) was marked as duplicate but does not end with expected suffix '{2}'".format( \
                            scanNum, scanName, suffix)
        if not (int(reply[2])==scanNum and reply[3]==scanName):
            raise RuntimeError, "Scan #{0} ({1}) is not that anymore, it is now #{2} ({3})".format( \
                                 scanNum, scanName, int(reply[2]), reply[3])
        
        CTRL.send_query("disk2file={0}:{1}:{2}:{3}".format( disk2file.outputFileName,
                seString(se.disk2file.startByte), seString(se.disk2file.endByte), 
                'w' if (disk2file.outputFileName=="/dev/null" or allowOverwrite) else ('resume' if doResume else 'n')), [1])

    def progress(self):
        r = self.DataSource.send_query("disk2file?")
        return None if r[2]=="inactive" else (int(r[5]), int(r[4]), int(r[6]))

    #### This is the DestXFER part of the interface
    
    # The "open()" method in this local xfer stores the output file name
    def open(self, output):
        disk2file.outputFileName = output

    def setInputFormat(self, fmt):
        pass

    def rcv_bytecount(self):
        return 0

    # no need to detect the data format; disk2file is local
    def needFormat(self):
        return False

# This is the Mk5 style disk2file but then on FlexBuff/Mark6
class disk2file_vbs(SourceXFER, DestXFER):
    outputFileName = None

    def __init__(self, src_or_dst):
        # look at what flavour we were initialized with to decide
        # which of our base classes should be initialized
        if isinstance(src_or_dst, DataSource):
            self.isSource = True
            SourceXFER.__init__(self, src_or_dst)
        else:
            self.isSource = False
            DestXFER.__init__(self, src_or_dst)

    #### Both types (SourceXFER and DestXFER) should be 
    #### cancellable
    def cancel(self):
        if self.isSource:
            self.DataSource.send_query("reset=abort", Mark5.anyReturn)
        else:
            disk2file.outputFileName = None

    #### This is the SourceXFER part of the transfer
    def outputFormat(self, *args):
        # no need to determine data format, disk2file(for vbs) is a local transfer
        return None

    def start(self, scan, dataip, **kwargs):
        # shorthand to the control interface
        CTRL  = self.DataSource
        mark6 = hasattr(CTRL.source, 'mark6')
        disks = hasattr(CTRL.source, 'disks')

        # disk2file for FlexBuff/Mark6 only appeared in 2.6.1
        loc = re.sub(":", "", CTRL.location())
        if CTRL.version()<supportsResume:
            raise RuntimeError, "Remote jive5ab at {0} [{1}] does not support FlexBuff/Mark6 disk2file, need >={2}".format(
                    loc, CTRL.get_version(), supportsResumeVersion )
        
        if doResume and CTRL.version()<supportsResume:
            raise RuntimeError, "Resume requested but the jive5ab at {0} is too old (<{1})".format( loc, supportsResumeVersion )

        supports6 = (CTRL.version()>=supportsMk6)

        # better be talking to a version of jive5ab who speaks '6 or
        # supports selecting of disks, in case either is needed
        if mark6 and not supports6:
            raise RuntimeError, "Remote jive5ab [{0}] does not support Mark6, need >=2.6.0".format( CTRL.get_version() )
        if disks and not supports6:
            raise RuntimeError, "Remote jive5ab [{0}] does not support selecting disks/MSNs, need >=2.6.0".format( CTRL.get_version() )

        # resuming disk2file is handled differently from disk2net+net2*
        # must be a special mode, see below.
        # First parse the start/end byte and put them in scan_set or disk2file
        se = seByte2file(CTRL.startByte(), CTRL.endByte())

        # before setting scan, we must set the disks, if the user gave any
        if disks:
            dsk    = CTRL.source.disks.replace(",", ":")
            reply  = CTRL.send_query("set_disks="+dsk, [0])
    
        # Always set the recording format 
        CTRL.send_query("record=mk6:{0}".format(1 if mark6 else 0))

        # Attempt to set the correct scan 
        CTRL.send_query("scan_set={0}:{1}:{2}".format(scan.name(), seString(se.scan_set.startByte), 
                                                        seString(se.scan_set.endByte)),
                                                        [0], timeout=600)

        CTRL.send_query("disk2file={0}:{1}:{2}:{3}".format( disk2file.outputFileName,
                seString(se.disk2file.startByte), seString(se.disk2file.endByte),
                'w' if (disk2file.outputFileName=="/dev/null" or allowOverwrite) else ('resume' if doResume else 'n')),
                [1], timeout=100,
                )

    def progress(self):
        r = self.DataSource.send_query("disk2file?", timeout=100)
        return None if r[2]=="inactive" else (int(r[5]), int(r[4]), int(r[6]))

    #### This is the DestXFER part of the interface
    
    # The "open()" method in this local xfer stores the output file name
    def open(self, output):
        disk2file.outputFileName = output

    def setInputFormat(self, fmt):
        pass

    def rcv_bytecount(self):
        return 0

    # no need to detect the data format; disk2file is local
    def needFormat(self):
        return False
        
# file2disk is, like disk2file, both
class file2disk(SourceXFER, DestXFER):
    outputScanName = None
    inputRuntime   = None

    def __init__(self, src_or_dst):
        # look at what flavour we were initialized with to decide
        # which of our base classes should be initialized
        if isinstance(src_or_dst, DataSource):
            self.isSource = True
            SourceXFER.__init__(self, src_or_dst)
            # we must change from arbitrary runtime to
            # runtime
            r = self.DataSource.send_query("runtime?", [0])
            file2disk.inputRuntime = r[2]
            self.DataSource.send_query("runtime=0", [0])
        else:
            self.isSource = False
            DestXFER.__init__(self, src_or_dst)

    #### Both types (SourceXFER and DestXFER) should be 
    #### cancellable
    def cancel(self):
        if self.isSource:
            self.DataSource.send_query("reset=abort", Mark5.anyReturn)
            self.DataSource.send_query("runtime={0}".format(file2disk.inputRuntime), [0])
            file2disk.inputRuntime = None
        else:
            file2disk.outputFileName = None

    #### This is the SourceXFER part of the transfer
    def outputFormat(self, *args):
        # no need to determine data format for local transfer
        return None

    def start(self, scan, dataip, **kwargs):
        CTRL = self.DataSource
        startByte = CTRL.startByte()
        endByte   = CTRL.endByte()
        CTRL.send_query("file2disk={0}:{1}:{2}:{3}".format(scan.name(), \
                (startByte if startByte else ""), (endByte if endByte else ""), \
                            file2disk.outputScanName), [1])

    def progress(self):
        r = self.DataSource.send_query("file2disk?")
        return None if r[2]=="inactive" else (int(r[5]), int(r[4]), int(r[6]))

    #### This is the DestXFER part of the interface

    # The "open()" method in this local xfer creates the 
    # function that will run the actual command, apart from
    # two arguments the ".start()" will supply - the input
    # file name and the actual control interface
    def open(self, outputScanName):
        file2disk.outputScanName = outputScanName

    def setOutputFormat(self, fmt):
        pass

    def rcv_bytecount(self):
        return 0

    # no need to detect the data format; disk2file is local
    def needFormat(self):
        return False

#### Local cornerturn operations
class spid2file(SourceXFER, DestXFER):
    outputFileName = None

    def __init__(self, src_or_dst):
        # look at what flavour we were initialized with to decide
        # which of our base classes should be initialized
        if isinstance(src_or_dst, DataSource):
            self.isSource = True
            SourceXFER.__init__(self, src_or_dst)

            # Analyze the cornerturning setup. In this case, because there is no
            # receiver, we can forget about the output format
            (self.ct_setup, self.ct_recipe, self.vdif_props, dummy) = ct_setup_commands("spid2file")
            # We can already program the VDIF setup
            map(lambda cmd: self.DataSource.send_query(cmd, [0]), self.ct_setup)
        else:
            self.isSource = False
            DestXFER.__init__(self, src_or_dst)

    #### Both types (SourceXFER and DestXFER) should be 
    #### cancellable
    def cancel(self):
        if self.isSource:
            self.DataSource.send_query("spid2file=disconnect", Mark5.anyReturn)
        else:
            spid2file.outputFileName = None

    #### This is the SourceXFER part of the transfer

    # For cornerturning, we cannot ignore the data format
    def outputFormat(self, *args):
        return None

    def start(self, scan, dataip, **kwargs):
        # shorthand to the control interface
        CTRL = self.DataSource

        # disk2file transfer is always coming from a DiskSource
        # (in case it isn't this is an error) so the "scanIds" that
        # are passed into us are really tuples, "(scan number, scan name)"
        (scanNum, scanName) = scan.scanId

        # This transfer cannot be resumed. Complain if resume would
        # actually be required. Silently ignore in case it wouldn't be
        # needed anyway
        alreadyHave = kwargs.get("haveBytes", None)

        if doResume and alreadyHave:
            raise RuntimeError, "Resume requested and needed, but this transfer cannot be resumed"

        # process the start/end byte and in which phase of the
        # scan_set/spid2file they'd belong
        se  = seByte2file(CTRL.startByte(), CTRL.endByte())

        CTRL.send_query("scan_set={0:d}:{1}:{2}".format(scanNum), seString(se.scan_set.startByte),
                        seString(se.scan_set.endByte), [0])

        reply = CTRL.send_query("scan_set?", [0])
        # If the current disk scan was marked as duplicate, it means
        # that some unique suffix has been appended. We must strip
        # that name to do our consistency checking
        if hasattr(scan, 'duplicate'):
            suffix = uniqSuffix(scanNum)
            if scanName.endswith(suffix):
                # Ok, modify scan name
                # Find the right-most uniqSuffix(). Suppose that by chance
                # the scan with name "name.scan.2" would end up in scan
                # postions #1 and  #2 (duplicated) on the disk pack.
                # then the 2nd uniquefied scan name would be:
                #    "name.scan.2.scan.2"
                # if we then do string.sub(".scan.2", "") it would replace 
                # *both* instances instead of only the last one
                # making our test for the scan's existence on the disk pack
                # fail!
                sidx = scanName.rfind(suffix)
                if sidx<0:
                    raise RuntimeError, "Could not find unique suffix whilst it should be there?!"
                scanName = scanName[0:sidx]
            else:
                raise RuntimeError, \
                        "Scan #{0} ({1}) was marked as duplicate but does not end with expected suffix '{2}'".format( \
                            scanNum, scanName, suffix)
        if not (int(reply[2])==scanNum and reply[3]==scanName):
            raise RuntimeError, "Scan #{0} ({1}) is not that anymore, it is now #{2} ({3})".format( \
                                 scanNum, scanName, int(reply[2]), reply[3])
        
        # Scan is selected, only thing left is to turn the whole thing on
        CTRL.send_query("spid2file=connect:{0}:{1}={2},{3}".format(
                                    self.ct_recipe, self.vdif_props.threads,
                                    spid2file.outputFileName,
                                    'w' if (spid2file.outputFileName=="/dev/null" or allowOverwrite) else 'n'
                                    ), [0])
        CTRL.send_query("spid2file=on:{0}:{1}".format(seString(se.disk2file.startByte),
                        seString(se.disk2file.endByte)), [0])

    def progress(self):
        r = self.DataSource.send_query("spid2file?")
        #  !spid2file? 0 : active : <start> : <current> : <end>
        #  0           1   2        3         4           5
        # spid2file never terminates automatically so we'll have to
        # go by the numbers ourselves
        (c, s, e) = (int(r[4]), int(r[3]), int(r[5])) if r[2]=="active" else (0, 0, 0)
        return None if c>=e else (c, s, e)

    #### This is the DestXFER part of the interface
    
    # The "open()" method in this local xfer stores the output file name
    def open(self, output):
        spid2file.outputFileName = output

    def setInputFormat(self, fmt):
        pass

    def rcv_bytecount(self):
        return 0

    # local cornerturning operation doesn't need a format
    def needFormat(self):
        return False


class spif2file(SourceXFER, DestXFER):
    outputFileName = None

    def __init__(self, src_or_dst):
        # look at what flavour we were initialized with to decide
        # which of our base classes should be initialized
        if isinstance(src_or_dst, DataSource):
            self.isSource = True
            SourceXFER.__init__(self, src_or_dst)

            # Analyze the cornerturning setup, forget about the output format; 
            # we don't have to set it because there is no receiving jive5ab
            (self.ct_setup, self.ct_recipe, self.vdif_props, dummy) = ct_setup_commands("spif2file")
            # We can already program the VDIF setup
            map(lambda cmd: self.DataSource.send_query(cmd, [0]), self.ct_setup)
        else:
            self.isSource = False
            DestXFER.__init__(self, src_or_dst)

    #### Both types (SourceXFER and DestXFER) should be 
    #### cancellable
    def cancel(self):
        if self.isSource:
            self.DataSource.send_query("spif2file=disconnect", Mark5.anyReturn)
        else:
            spid2file.outputFileName = None

    #### This is the SourceXFER part of the transfer
    # note: for a local format translation, we can still ignore the output format
    def outputFormat(self, *args):
        return None

    def start(self, scan, dataip, **kwargs):
        # shorthand to the control interface
        CTRL = self.DataSource

        # if the remote end indicates they already have some 
        # bytes, we don't have to start from the beginning
        # remember to deal with None as possible value passed in for
        # 'haveBytes'
        startByte   = CTRL.startByte()
        endByte     = CTRL.endByte()

        # Scan is selected, only thing left is to turn the whole thing on
        CTRL.send_query("spif2file=connect:{4}:{0}:{1}={2},{3}".format(
                                    self.ct_recipe, self.vdif_props.threads,
                                    spif2file.outputFileName,
                                    'w' if (spif2file.outputFileName=="/dev/null" or allowOverwrite) else 'n',
                                    scan.name()
                                    ), [0])
        CTRL.send_query("spif2file=on:{0}:{1}".format(startByte if startByte else "", endByte if endByte else ""))

    def progress(self):
        r = self.DataSource.send_query("spif2file?")
        #  !spid2file? 0 : active : <start> : <current> : <end>
        #  0           1   2        3         4           5
        # spid2file never terminates automatically so we'll have to
        # go by the numbers ourselves
        (c, s, e) = (int(r[4]), int(r[3]), int(r[5])) if r[2]=="active" else (0, 0, 0)
        return None if c>=e else (c, s, e)

    #### This is the DestXFER part of the interface
    
    # The "open()" method in this local xfer stores the output file name
    def open(self, output):
        spif2file.outputFileName = output

    def setInputFormat(self, fmt):
        pass

    def rcv_bytecount(self):
        return 0

    # local cornerturning operation doesn't need in inputformat
    def needFormat(self):
        return False

#### Some helper functions for dealing with IN/MEM style
#### 'paths' - the path can be a runtime in seconds or
#### a runtime in amount of bytes
def mk_tstat_cmp(l, h, fn):
    def act_tstat_cmp(tsnew, tsold):
        if queries:
            print "act_tstat_cmp/tsnew=",tsnew
            print "              tsold=",tsold
        if len(tsnew)<5 or len(tsold)<5:
            return None
        cur = fn(tsnew, tsold)
        if queries:
            print "              cur  =",cur
        return (cur, l, h) if cur<h else None
    return act_tstat_cmp

## Parse the path for runtime by time, bytes or indefinite
## we'll add a function
def add_done_yet(obj, path):
    # Set up a function that detects wether we're done or not
    # if there is no 'path', we run 'indefinitely'.
    # If there is a 'path' it's either an amount of bytes
    # or an amount of seconds that we should transfer
    # Progress is measured by comparing different fields 
    # from "tstat=" command (so the values come from 
    # jive5ab, not from us)
    #    !tstat = 0 : <transfer> : <time> : <step1> : <count1> : ...
    #    0        1   2            3        4         5
    if path:
        mo   = rxAmount.match( path )
        amt  = int(mo.group('amount'))
        unit = mo.group('unit')
        if unit=='s':
            # runtime in seconds
            obj.done_yet = mk_tstat_cmp(0, amt, lambda n, o: float(n[2]) - float(o[2]))
        else:
            # runtime in bytes
            obj.done_yet = mk_tstat_cmp(0, amt*scaleTableBinary[unit], lambda n, o: int(n[5]) - int(o[5]))
    else:
        # run indefinitely (well, until 2**63 bytes have been
        # transferred)
        obj.done_yet = mk_tstat_cmp(0, 2**63, lambda n, o: int(n[5]) - int(o[5]))
    

# in2file is also a simple, local transfer, which is both SRC and DST
class in2file(SourceXFER, DestXFER):
    outputFileName = None
    inputRuntime   = None

    def __init__(self, src_or_dst):
        # look at what flavour we were initialized with to decide
        # which of our base classes should be initialized
        if isinstance(src_or_dst, DataSource):
            self.isSource = True
            SourceXFER.__init__(self, src_or_dst)
            # we must change from arbitrary runtime to
            # runtime '0', because that one has access to the h/w
            r = self.DataSource.send_query("runtime?", [0])
            in2file.inputRuntime = r[2]
            self.DataSource.send_query("runtime=0", [0])
            add_done_yet(self, self.DataSource.source.path)
        else:
            self.isSource = False
            DestXFER.__init__(self, src_or_dst)

    #### Both types (SourceXFER and DestXFER) should be 
    #### cancellable
    def cancel(self):
        if self.isSource:
            self.DataSource.send_query("in2file=disconnect", Mark5.anyReturn)
            self.DataSource.send_query("runtime={0}".format(in2file.inputRuntime), [0])
            in2file.inputRuntime = None
        else:
            in2file.outputFileName = None

    #### This is the SourceXFER part of the transfer
    # for a local transfer, the output data format is irrelevant
    def outputFormat(self, *args):
        return None

    def start(self, scan, dataip, **kwargs):
        CTRL      = self.DataSource
        CTRL.send_query("in2file=connect:{0}".format(in2file.outputFileName, [1]))
        CTRL.send_query("in2file=on")
        self.oldtstat = CTRL.send_query("tstat=")

    def progress(self):
        return self.done_yet(self.DataSource.send_query("tstat="), self.oldtstat)

    #### This is the DestXFER part of the interface

    # The "open()" method in this local xfer creates the 
    # function that will run the actual command, apart from
    # two arguments the ".start()" will supply - the input
    # file name and the actual control interface
    def open(self, outputScanName):
        in2file.outputFileName = outputScanName

    def setInputFormat(self, fmt):
        pass

    def rcv_bytecount(self):
        return 0

    # local recording doesn't need to be aware of data format
    def needFormat(self):
        return False

### in2disk is basically "record=on:scan"
class in2disk(SourceXFER, DestXFER):
    outputScanName = None
    inputRuntime   = None

    def __init__(self, src_or_dst):
        # look at what flavour we were initialized with to decide
        # which of our base classes should be initialized
        if isinstance(src_or_dst, DataSource):
            self.isSource = True
            SourceXFER.__init__(self, src_or_dst)
            # we must change from arbitrary runtime to
            # runtime '0', because that one has access to the h/w
            r = self.DataSource.send_query("runtime?", [0])
            in2disk.inputRuntime = r[2]
            self.DataSource.send_query("runtime=0", [0])
            add_done_yet(self, self.DataSource.source.path)
        else:
            self.isSource = False
            DestXFER.__init__(self, src_or_dst)

    #### Both types (SourceXFER and DestXFER) should be 
    #### cancellable
    def cancel(self):
        if self.isSource:
            self.DataSource.send_query("record=off", Mark5.anyReturn)
            self.DataSource.send_query("runtime={0}".format(in2file.inputRuntime), [0])
            in2disk.inputRuntime = None
        else:
            in2disk.outputScanName = None

    #### This is the SourceXFER part of the transfer
    # local transfer thus output format is irrelevant
    def outputFormat(self, *args):
        return None

    def start(self, scan, dataip, **kwargs):
        CTRL      = self.DataSource
        CTRL.send_query("record=on:{0}".format(in2disk.outputScanName))
        self.oldtstat = CTRL.send_query("tstat=")

    def progress(self):
        return self.done_yet(self.DataSource.send_query("tstat="), self.oldtstat)

    #### This is the DestXFER part of the interface

    # The "open()" method in this local xfer creates the 
    # function that will run the actual command, apart from
    # two arguments the ".start()" will supply - the input
    # file name and the actual control interface
    def open(self, outputScanName):
        in2disk.outputScanName = outputScanName

    def setInputFormat(self, fmt):
        pass

    def rcv_bytecount(self):
        return 0

    # local recording doesn't need to be aware of data format
    def needFormat(self):
        return False

## split input (corner turn directly from telescope)
class spin2file(SourceXFER, DestXFER):
    outputFileName = None

    def __init__(self, src_or_dst):
        # look at what flavour we were initialized with to decide
        # which of our base classes should be initialized
        if isinstance(src_or_dst, DataSource):
            self.isSource = True
            SourceXFER.__init__(self, src_or_dst)

            # we must change from arbitrary runtime to
            # runtime '0', because that one has access to the h/w
            r = self.DataSource.send_query("runtime?", [0])
            spin2file.inputRuntime = r[2]
            self.DataSource.send_query("runtime=0", [0])

            # Analyze the "in://path" 'path' and form
            # a termination condition
            add_done_yet(self, self.DataSource.source.path)

            # Analyze the cornerturning setup, forget about the output format;
            # we don't have to set it because there is no receiving program
            (self.ct_setup, self.ct_recipe, self.vdif_props, dummy) = ct_setup_commands("spin2file")
            # We can already program the VDIF setup
            map(lambda cmd: self.DataSource.send_query(cmd, [0]), self.ct_setup)
        else:
            self.isSource = False
            DestXFER.__init__(self, src_or_dst)

    #### Both types (SourceXFER and DestXFER) should be 
    #### cancellable
    def cancel(self):
        if self.isSource:
            self.DataSource.send_query("spin2file=disconnect", Mark5.anyReturn)
            self.DataSource.send_query("runtime={0}".format(spin2file.inputRuntime), [0])
        else:
            spin2file.outputFileName = None

    #### This is the SourceXFER part of the transfer

    # note: for a local format translation, we can still ignore the output format
    def outputFormat(self, *args):
        return None

    def start(self, scan, dataip, **kwargs):
       # shorthand to the control interface
        CTRL = self.DataSource
        # Scan is selected, only thing left is to turn the whole thing on
        CTRL.send_query("spin2file=connect:{0}:{1}={2},{3}".format(
            self.ct_recipe, self.vdif_props.threads,
            spin2file.outputFileName,
            'w' if (spin2file.outputFileName=="/dev/null" or allowOverwrite) else 'n'
            ), [0])
        CTRL.send_query("spin2file=on")
        self.oldtstat = CTRL.send_query("tstat=")

    def progress(self):
        return self.done_yet(self.DataSource.send_query("tstat="), self.oldtstat)

    #### This is the DestXFER part of the interface

    # The "open()" method in this local xfer stores the output file name
    def open(self, output):
        spin2file.outputFileName = output

    def setInputFormat(self, fmt):
        pass

    def rcv_bytecount(self):
        return 0

    # local recording doesn't need to be aware of data format
    def needFormat(self):
        return False


# likewise for mem2file. it is also a simple, local transfer, which is both SRC and DST
class mem2file(SourceXFER, DestXFER):
    outputScanName = None

    def __init__(self, src_or_dst):
        # look at what flavour we were initialized with to decide
        # which of our base classes should be initialized
        if isinstance(src_or_dst, DataSource):
            self.isSource = True
            SourceXFER.__init__(self, src_or_dst)
            add_done_yet(self, self.DataSource.source.path)
        else:
            self.isSource = False
            DestXFER.__init__(self, src_or_dst)

    #### Both types (SourceXFER and DestXFER) should be 
    #### cancellable
    def cancel(self):
        if self.isSource:
            self.DataSource.send_query("mem2file=close", Mark5.anyReturn)
            file2disk.inputRuntime = None
        else:
            file2disk.outputFileName = None

    #### This is the SourceXFER part of the transfer
    # for local transfer, output data format is irrelevant
    def outputFormat(self, *args):
        return None

    def start(self, scan, dataip, **kwargs):
        CTRL      = self.DataSource
        CTRL.send_query("mem2file=on:{0}".format(mem2file.outputScanName, [1]))
        self.oldtstat = CTRL.send_query("tstat=")

    def progress(self):
        return self.done_yet(self.DataSource.send_query("tstat="), self.oldtstat)

    #### This is the DestXFER part of the interface

    # The "open()" method in this local xfer creates the 
    # function that will run the actual command, apart from
    # two arguments the ".start()" will supply - the input
    # file name and the actual control interface
    def open(self, outputScanName):
        mem2file.outputScanName = outputScanName

    def setInputFormat(self, fmt):
        pass

    def rcv_bytecount(self):
        return 0

    # local transfer doesn't need data format
    def needFormat(self):
        return False


def parse_stuff2net_reply(r):
    if len(r)<3:
        raise RuntimeError, "The reply was too short, cannot check for (in)active"
    # if we get 7 fields or more, it always inclused start, current and end
    # (new style replies yield the byte counts of the last transfer in case
    # of inactive)
    (start, current, end) = map(int, r[4:7]) if len(r)>=7 else [None]*3
    if r[2]=="inactive":
        # new style reply sends numbers
        if start is not None:
            # new style jive5ab - we can check if succesful finish
            # and return number of bytes that *should've* been
            # transferred in that case. Otherwise cry out loud
            if current==end:
                return [end-start]
            raise RuntimeError,"Transfer did not finish correctly"
        # old style finish
        return None
    # must've been 'active', return the parsed numbers
    return (current, start, end)

## disk2net

class disk2net(SourceXFER):
    def __init__(self, datasource):
        super(disk2net, self).__init__( datasource )

    # return the mode that was input by the user, if any
    def outputFormat(self, scan):
        # if user gave external mode, accept that
        if mode is not None:
            return mode
        # ok use autodetection
        return detect_mode(self.DataSource, scan, scan_check)

    def start(self, scan, dataip, **kwargs):
        # shorthand to the control interface
        CTRL = self.DataSource

        # disk2net transfer is always coming from a DiskSource
        # (in case it isn't this is an error) so the "scanIds" that
        # are passed into us are really tuples, "(scan number, scan name)"
        (scanNum, scanName) = scan.scanId

        # Make sure to switch off resuming if not needed
        alreadyHave = kwargs.get("haveBytes", None) if doResume else None

        if doResume and alreadyHave is not None and CTRL.version()<supportsResume:
            loc = re.sub(":", "", CTRL.location())
            raise RuntimeError, "Resume requested and file does exist remotely but "+ \
                                "the source jive5ab at {0} does not support resuming. ".format( loc ) +\
                                "Please rerun with --allow_overwrite, --ignore_existing " +\
                                "or upgrade the source jive5ab to at least {0}.".format( supportsResumeVersion )

        # Process byte numbers to put them in the commands
        # they should be in: scan_set or disk2net
        se     = seByte2net(CTRL.startByte(), CTRL.endByte(), alreadyHave)

        # Attempt to set the correct scan and verify it did set.
        CTRL.send_query("scan_set={0:d}:{1}:{2}".format(scanNum, seString(se.scan_set.startByte),
                                                        seString(se.scan_set.endByte)), [0])

        reply = CTRL.send_query("scan_set?", [0])
        if hasattr(scan, 'duplicate'):
            suffix = uniqSuffix(scanNum)
            if scanName.endswith(suffix):
                # Ok, modify scan name
                # Find the right-most uniqSuffix(). Suppose that by chance
                # the scan with name "name.scan.2" would end up in scan
                # postions #1 and  #2 (duplicated) on the disk pack.
                # then the 2nd uniquefied scan name would be:
                #    "name.scan.2.scan.2"
                # if we then do string.sub(".scan.2", "") it would replace 
                # *both* instances instead of only the last one
                # making our test for the scan's existence on the disk pack
                # fail!
                sidx = scanName.rfind(suffix)
                if sidx<0:
                    raise RuntimeError, "Could not find unique suffix whilst it should be there?!"
                scanName = scanName[0:sidx]
            else:
                raise RuntimeError, \
                        "Scan #{0} ({1}) was marked as duplicate but does not end with expected suffix '{2}'".format( \
                            scanNum, scanName, suffix)
        if not (int(reply[2])==scanNum and reply[3]==scanName):
            raise RuntimeError, "Scan #{0} ({1}) is not that anymore, it is now #{2} ({3})".format( \
                                 scanNum, scanName, int(reply[2]), reply[3])

        # Attempt to connect to remote side
        CTRL.send_query("disk2net=connect:{0:s}".format(dataip), [0,1])

        # And let it flow!
        # HV: 9 dec 2014  Roger H. finds that, sometimes, the connect
        #                 initiated by the previous command takes
        #                 so long that disk2net isn't connected
        #                 yet by the time we send it the "=on" command.
        #     4 jan 2016  BE finds that there's some race conditions; let's
        #                 fix them neatly
        r = CTRL.send_query("disk2net?", [0])
        endTime = time.time() + (max(timeOut, 10) if timeOut is not None else 10)
        while time.time()<endTime:
            if "connected" in r:
                break
            progress_print("\r>>>> Waiting for disk2net to connect")
            time.sleep(1)
            r = CTRL.send_query("disk2net?", [0])
        if "connected" not in r:
            raise RuntimeError, "Timeout connecting to {0}".format(dataip, )
        CTRL.send_query("disk2net=on:{0}:{1}".format(seString(se.disk2net.startByte), seString(se.disk2net.endByte)), [0])

        # HV: 9 dec 2014  GRRRR. Roger H. finds that, sometimes, 
        #                 "disk2net=on" takes so long that it remains
        #                 in the connected state by the time we get to the
        #                 .progress(self) method. So we must wait here
        #                 for the status to become active
        #     4 jan 2016  BE finds that status could go to inactive
        #                 if the transfer finishes (very) quickly
        while True:
            r = CTRL.send_query("disk2net?", [0])
            if "connected" not in r:
                break
            progress_print("\r>>>> Waiting for disk2net to start")
            time.sleep(1)
        if "inactive" in r:
            # Sender immediately stopped sending because everything is already there!
            raise IgnoreFile

    def progress(self):
        return parse_stuff2net_reply( self.DataSource.send_query("disk2net?") )

    def cancel(self):
        self.DataSource.send_query("disk2net=disconnect", Mark5.anyReturn)

class disk2net_vbs(SourceXFER):
    def __init__(self, datasource):
        super(disk2net_vbs, self).__init__( datasource )

    # we may couple this to a remote VBS if the type is 
    # different or it's two Mark6's?
    def outputFormat(self, scan):
        # if user gave external mode, accept that
        if mode is not None:
            return mode
        # ok use autodetection
        return detect_mode(self.DataSource, scan, scan_check)

    def start(self, scan, dataip, **kwargs):
        # shorthand to the control interface
        CTRL  = self.DataSource
        mark6 = hasattr(CTRL.source, 'mark6')
        disks = hasattr(CTRL.source, 'disks')

        # disk2net for FlexBuff/Mark6 only appeared in 2.6.1
        loc = re.sub(":", "", CTRL.location())
        if CTRL.version()<supportsResume:
            raise RuntimeError, "Remote jive5ab at {0} [{1}] does not support FlexBuff/Mark6 disk2net, need >={2}".format(
                    loc, CTRL.get_version(), supportsResumeVersion )
        
        supports6 = (CTRL.version()>=supportsMk6)

        # better be talking to a version of jive5ab who speaks '6 or
        # supports selecting of disks, in case either is needed
        if mark6 and not supports6:
            raise RuntimeError, "Remote jive5ab [{0}] does not support Mark6, need >=2.6.0".format( CTRL.get_version() )
        if disks and not supports6:
            raise RuntimeError, "Remote jive5ab [{0}] does not support selecting disks/MSNs, need >=2.6.0".format( CTRL.get_version() )

        # Make sure to switch off resuming if not needed
        alreadyHave = kwargs.get("haveBytes", None) if doResume else None

        if doResume and alreadyHave is not None and CTRL.version()<supportsResume:
            loc = re.sub(":", "", CTRL.location())
            raise RuntimeError, "Resume requested and file does exist remotely but "+ \
                                "the source jive5ab at {0} does not support resuming. ".format( loc ) +\
                                "Please rerun with --allow_overwrite, --ignore_existing " +\
                                "or upgrade the source jive5ab to at least {0}.".format( supportsResumeVersion )

        # Process byte numbers to put them in the commands
        # they should be in: scan_set or disk2net
        se     = seByte2net(CTRL.startByte(), CTRL.endByte(), alreadyHave)

        # before setting scan, we must set the disks, if the user gave any
        if disks:
            dsk    = CTRL.source.disks.replace(",", ":")
            reply  = CTRL.send_query("set_disks="+dsk, [0])
    
        # Always set the recording format 
        CTRL.send_query("record=mk6:{0}".format(1 if mark6 else 0))

        # Attempt to set the correct scan and verify it did set.
        CTRL.send_query("scan_set={0}:{1}:{2}".format(scan.name(), \
                seString(se.scan_set.startByte),
                seString(se.scan_set.endByte)), [0], timeout=600)
        reply = CTRL.send_query("scan_set?", [0])

        # Attempt to connect to remote side and wait for it to be connected
        CTRL.send_query("disk2net=connect:{0:s}".format(dataip), [0,1], timeout=10)

        r = CTRL.send_query("disk2net?", [0])
        endTime = time.time() + (max(timeOut, 10) if timeOut is not None else 10)
        while time.time()<endTime:
            if "connected" in r:
                break
            progress_print("\r>>>> Waiting for disk2net to connect")
            time.sleep(1)
            r = CTRL.send_query("disk2net?", [0])
        if "connected" not in r:
            raise RuntimeError, "Timeout connecting to {0}".format(dataip, )

        # Now the dataflow can be turned on - wait until it actually starts
        CTRL.send_query("disk2net=on:{0}:{1}".format(seString(se.disk2net.startByte), seString(se.disk2net.endByte)),
                        [0], timeout=10)

        while True:
            r = CTRL.send_query("disk2net?", [0], timeout=10)
            if "connected" not in r:
                break
            progress_print("\r>>>> Waiting for disk2net to start")
            time.sleep(1)
        if "inactive" in r:
            # sender stopped immediately because everything already there!
            raise IgnoreFile

    def progress(self):
        return parse_stuff2net_reply( self.DataSource.send_query("disk2net?", timeout=100) )

    def cancel(self):
        self.DataSource.send_query("disk2net=disconnect", Mark5.anyReturn)


class file2net(SourceXFER):
    def __init__(self, datasource):
        super(file2net, self).__init__( datasource )

    # return the mode that was input by the user, if any
    # otherwise, do autodetection
    def outputFormat(self, scan):
        if mode is not None:
            return mode
        return detect_mode(self.DataSource, scan, file_check)

    def start(self, scan, dataip, **kwargs):
        # shorthand to the control interface
        CTRL = self.DataSource

        # if the remote end indicates they already have some 
        # bytes, we don't have to start from the beginning
        # remember to deal with None as possible value passed in for
        # 'haveBytes'
        startByte   = CTRL.startByte()
        endByte     = CTRL.endByte()
        alreadyHave = kwargs.get("haveBytes", None)

        # do byte number administration here, but only if needed
        # (which is when we need to resume a transfer)
        if alreadyHave is not None and doResume:
            # file2net only supports numbers, not time based start/end
            if startByte and not rxBytenumOffset.match(startByte):
                raise RuntimeError, "start byte number is invalid; only numbers supported, not time"
            if endByte and not rxBytenumOffset.match(endByte):
                raise RuntimeError, "end byte number is invalid; only numbers supported, not time"

            # ok, resume requested and the remote thingy already has
            # data. Let's see what we can make of the byte numbers
            # We must alter start/end byte numbers in order to account
            # for the amount of bytes already present at the destination
            startByte = int(startByte) if startByte is not None else 0
            eofOffset = (startByte<0)

            # if startByte < 0, this meant offset wrt to end-of-file
            # we already have some bytes so this offset can then be lowered
            # For positive starByte or one that starts with '+' it doesn't
            # matter; the start position becomes absolute in that case
            startByte = startByte + alreadyHave
            if eofOffset and startByte>0:
                raise RuntimeError, "Destination already has more bytes than requested via start byte number"

            # Now comes the end byte number
            relativeEnd = isRelativeToStart(endByte)
            endByte     = int(endByte) if endByte is not None else 0

            # endByte < 0 implies offset wrt to end of file, does not change
            # by the fact that we already have bytes
            # endByte > 0: two cases:
            #    - just a number: absolute end byte number, unaffected by
            #      how many bytes we already have
            #    - '+'<amount> (starting with an explicit '+') means: amount
            #      of bytes wrt to start. If we already have bytes at
            #      destination, then this relative amount must be adjusted
            if endByte>0 and relativeEnd:
                endByte = endByte - alreadyHave
                # if we now end up with a negative values, something's awry
                if endByte<0:
                    raise RuntimeError, "Destination has more bytes than requested via end byte number"
                if endByte==0:
                    # file already there, nothing to do!
                    raise IgnoreFile

            # any of the byte offsets 0? Then they can be removed
            if startByte==0:
                startByte = None
            if relativeEnd:
                endByte = "+"+str(endByte)
            elif endByte==0:
                endByte = None

        CTRL.send_query("file2net=connect:{0:s}:{1:s}".format(dataip, scan.name()), [0])

        # Let's be ahead of the curve here. Wait for file2net to become connected
        r = CTRL.send_query("file2net?", [0])
        endTime = time.time() + (max(timeOut, 10) if timeOut is not None else 10)
        while time.time()<endTime:
            if "connected" in r:
                break
            progress_print("\r>>>> Waiting for file2net to connect")
            time.sleep(1)
            r = CTRL.send_query("file2net?", [0])
        if "connected" not in r:
            raise RuntimeError, "Timeout connecting to {0}".format(dataip, )

        CTRL.send_query("file2net=on:{0}:{1}".format(startByte if startByte else "", \
                                                     endByte if endByte else "", [0]))
        while True:
            r = CTRL.send_query("file2net?", [0])
            if "connected" not in r:
                break
            progress_print("\r>>>> Waiting for file2net to start")
            time.sleep(1)
        if "inactive" in r:
            # sender stopped immediately because everything already there!
            raise IgnoreFile

    def progress(self):
        return parse_stuff2net_reply( self.DataSource.send_query("file2net?") )

    def cancel(self):
        self.DataSource.send_query("file2net=disconnect", Mark5.anyReturn)

class vbs2net(SourceXFER):
    def __init__(self, datasource):
        super(vbs2net, self).__init__( datasource )
        # when configuring the number of readers/writers we make some
        # assumptions:
        #   * reading vbs disks is faster than writing (thus nDiskReader <
        #     nDiskWriter)
        # NOTE: 'nthread' is a global parameter, settable from the command
        #       line
        self.DataSource.send_query("vbs2net=nthread:{0}:{1}".format(nthread+1, nthread))

        # If someone configured disks to read from, then do support that
        disks     = hasattr(self.DataSource.source, 'disks')
        supports6 = (self.DataSource.version()>=supportsMk6)

        # better be talking to a version of jive5ab who speaks '6 or
        # supports selecting of disks, in case it's needed
        if disks and not supports6:
            raise RuntimeError, "Remote jive5ab [{0}] does not support selecting disks/MSNs, need >=2.6.0".format( self.DataSource.get_version() )

        # if the destination specified some disks to record on, do configure that now
        if disks:
            # set_disks = <pattern> [ : <pattern>...]
            # !set_disks = 0 : <nmatchingdisks>
            # 0            1   2
            dsk    = self.DataSource.source.disks.replace(",", ":")
            reply  = self.DataSource.send_query("set_disks="+dsk, [0])

    # no format translation
    def outputFormat(self, *args):
        return None

    def start(self, scan, dataip, **kwargs):
        # shorthand to the control interface
        CTRL = self.DataSource

        # On vbs -> vbs transfers we don't support start/end byte numbers
        # Take care to test for 'is not None' because an endbyte value of 0
        # would then also be considered False but we really really shouldn't support it
        if CTRL.startByte() is not None or CTRL.endByte() is not None:
            raise RuntimeError, "VBS -> VBS transfers do not support start/end byte setting"
        # Note: this can take a while because both local and remote must
        # grovel over their disks to find the pieces of the recording
        # and negotiate what needs to be sent
        CTRL.send_query("vbs2net=connect:{0}:{1}".format(scan.name(), dataip), [0], timeout=600)

    def progress(self):
        r = self.DataSource.send_query("tstat=")
        # we don't know the length of the vbs recording (yet) so let's put
        # in something such that it's always ~98%
        if r[3]!="vbs2net":
            return None
        c = int(r[5])
        return (c, 0, c + max(1, int(float(c)*0.02)))

    def cancel(self):
        self.DataSource.send_query("vbs2net=disconnect", Mark5.anyReturn)


class in2net(SourceXFER):
    def __init__(self, datasource):
        super(in2net, self).__init__( datasource )
        add_done_yet(self, self.DataSource.source.path)

    # return the mode that was input by the user
    def outputFormat(self, scan):
        # if user gave external mode, accept that
        if mode is not None:
            return mode
        # ok use autodetection
        return detect_mode(self.DataSource, scan, mode_check)

    def start(self, scan, dataip, **kwargs):
        CTRL = self.DataSource
        CTRL.send_query("in2net=connect:{0}".format(dataip), [0])
        CTRL.send_query("in2net=on", [0])
        self.oldtstat = CTRL.send_query("tstat=")

    def progress(self):
        return self.done_yet(self.DataSource.send_query("tstat="), self.oldtstat)

    def cancel(self):
        self.DataSource.send_query("in2net=disconnect", Mark5.anyReturn)

class mem2net(SourceXFER):
    def __init__(self, datasource):
        super(mem2net, self).__init__( datasource )
        add_done_yet(self, self.DataSource.source.path)

    # no format translation
    def outputFormat(self, scan):
        # if user gave external mode, accept that
        if mode is not None:
            return mode
        # ok use autodetection
        return detect_mode(self.DataSource, scan, mode_check)

    def start(self, scan, dataip, **kwargs):
        CTRL = self.DataSource
        CTRL.send_query("mem2net=connect:{0}".format(dataip), [0])
        CTRL.send_query("mem2net=on", [0])
        self.oldtstat = CTRL.send_query("tstat=")

    def progress(self):
        return self.done_yet(self.DataSource.send_query("tstat="), self.oldtstat)

    def cancel(self):
        self.DataSource.send_query("mem2net=disconnect", Mark5.anyReturn)

# would it be possible to let spif2net look at the
# 'datasource' instance and set itself up for
# spid2net, spif2net and spin2net?
class split2net(SourceXFER):
    def __init__(self, datasource):
        super(split2net, self).__init__( datasource )

        # Check our actual datasource
        if isinstance(datasource, DiskSource):
            self.ct_cmd = "spid2net"
        elif isinstance(datasource, FileSource):
            self.ct_cmd = "spif2net"
        elif isinstance(datasource, InSource):
            self.ct_cmd = "spin2net"

            # we must change from arbitrary runtime to
            # runtime '0', because that one has access to the h/w
            r = self.DataSource.send_query("runtime?", [0])
            self.inputRuntime = r[2]
            self.DataSource.send_query("runtime=0", [0])

            # Analyze the "in://path" 'path' and form
            # a termination condition
            add_done_yet(self, self.DataSource.source.path)
        else:
            raise RuntimeError, "Unsupported input data source for split2net {0}".format(datasource)

        # Analyze the cornerturning setup
        (self.ct_setup, self.ct_recipe, self.vdif_props, self.oFmt) = ct_setup_commands(self.ct_cmd)
        # We can already program the VDIF setup
        map(lambda cmd: self.DataSource.send_query(cmd, [0]), self.ct_setup)

    # data format translation!
    def outputFormat(self, *args):
        return self.oFmt

    def start(self, scan, dataip, **kwargs):
        CTRL = self.DataSource

        supportSEByte = self.ct_cmd in ["spid2net", "spif2net"]
        sByte = CTRL.startByte() if supportSEByte else None
        eByte = CTRL.endByte()   if supportSEByte else None

        # When doing transfer from disk, we have to do some more work
        if self.ct_cmd=="spid2net":
            # For transfers from disk, the "scanIds" that
            # are passed into us are really tuples, "(scan number, scan name)"
            (scanNum, scanName) = scan.scanId

            # Attempt to set the correct scan and verify it did set.
            CTRL.send_query("scan_set={0:d}".format(scanNum), [0])
            reply = CTRL.send_query("scan_set?", [0])
            # If the current disk scan was marked as duplicate, it means
            # that some unique suffix has been appended. We must strip
            # that name to do our consistency checking
            if hasattr(scan, 'duplicate'):
                suffix = uniqSuffix(scanNum)
                if scanName.endswith(suffix):
                    # Ok, modify scan name
                    # Find the right-most uniqSuffix(). Suppose that by chance
                    # the scan with name "name.scan.2" would end up in scan
                    # postions #1 and  #2 (duplicated) on the disk pack.
                    # then the 2nd uniquefied scan name would be:
                    #    "name.scan.2.scan.2"
                    # if we then do string.sub(".scan.2", "") it would replace 
                    # *both* instances instead of only the last one
                    # making our test for the scan's existence on the disk pack
                    # fail!
                    sidx = scanName.rfind(suffix)
                    if sidx<0:
                        raise RuntimeError, "Could not find unique suffix whilst it should be there?!"
                    scanName = scanName[0:sidx]
                else:
                    raise RuntimeError, \
                            "Scan #{0} ({1}) was marked as duplicate but does not end with expected suffix '{2}'".format( \
                                scanNum, scanName, suffix)
            if not (int(reply[2])==scanNum and reply[3]==scanName):
                raise RuntimeError, "Scan #{0} ({1}) is not that anymore, it is now #{2} ({3})".format( \
                                     scanNum, scanName, int(reply[2]), reply[3])

        # (potential)scan is selected, only thing left is to turn the whole thing on
        # note that spif2net has a slightly different format:
        #  spin2net = connect : <splitmethod> : <threads>=<dest>
        #  spid2net = connect : <splitmethod> : <threads>=<dest>
        #  spif2net = connect : <filename>,r : <splitmethod> : <threads>=<dest>
        if self.ct_cmd == "spif2net":
            fmt = "{ct_cmd} = connect : {filename} : {splitmethod} : {threads}={dest}"
        else:
            fmt = "{ct_cmd} = connect : {splitmethod} : {threads}={dest}"
        CTRL.send_query(fmt.format( ct_cmd = self.ct_cmd, splitmethod = self.ct_recipe,
                                    threads = self.vdif_props.threads, dest = dataip,
                                    filename = scan.name()
                                    ), [0])
        CTRL.send_query("{ct_cmd}=on:{0}:{1}".format(sByte if sByte else "", eByte if eByte else "", ct_cmd=self.ct_cmd), [0])
        if self.ct_cmd == "spin2net":
            self.oldtstat = CTRL.send_query("tstat=")

    def progress(self):
        CTRL = self.DataSource
        if self.ct_cmd == "spin2net":
            return self.done_yet(CTRL.send_query("tstat="), self.oldtstat)
        else:
            r = CTRL.send_query(self.ct_cmd+"?")
            #  !sp...2net? 0 : active : <start> : <current> : <end>
            #  0           1   2        3         4           5
            # spid2file never terminates automatically so we'll have to
            # go by the numbers ourselves
            (c, s, e) = (int(r[4]), int(r[3]), int(r[5])) if r[2]=="active" else (0, 0, 0)
            return None if c>=e else (c, s, e)

    def cancel(self):
        self.DataSource.send_query("{0}=disconnect".format(self.ct_cmd), Mark5.anyReturn)
        if self.ct_cmd == "spin2net":
            self.DataSource.send_query("runtime={0}".format(self.inputRuntime), [0])



class net2disk(DestXFER):
    def __init__(self, datasink):
        super(net2disk, self).__init__( datasink )
        # Oops. net2disk must execute in the default runtime!
        self.DataSink.send_query("runtime=0", [0])

    def open(self, output):
        self.DataSink.send_query("net2disk=open:{0:s}".format(output), [0])

    def setInputFormat(self, fmt):
        if fmt is not None:
            self.DataSink.send_query("mode={0}".format(fmt), [0])

    def cancel(self):
        self.DataSink.send_query("net2disk=close", Mark5.anyReturn)

    def rcv_bytecount(self):
        # net2disk?  replies with:
        # net2disk? 0 : <status> : <scan nr> : <scan name> : <bytes>
        # 0         1   2          3           4             5
        r = self.DataSink.send_query("net2disk?", [0])
        return 0 if (r[2]=="inactive" or len(r)<6) else int(r[5])

    # net2disk should not require mode to be set
    def needFormat(self):
        return False

class net2file(DestXFER):
    def __init__(self, datasink):
        super(net2file, self).__init__( datasink )

    def open(self, output):
        # attempt to start net2file
        om   = 'w' if (output=="/dev/null" or allowOverwrite) else ('a' if doResume else 'n')
        qry  = "net2file=open:{0:s},{1}".format(output, om)
        r    = self.DataSink.send_query(qry, [0, 4])

        # If user sais it's ok to ignore existing files, so should we
        if int(r[1])==4:
            # must check if indeed it was because of a File exists
            exists = reduce(lambda acc, x: acc or 'File exists' in x, r[2:], False)
            if exists:
                if not ignoreExisting:
                    raise RuntimeError, "{0} exists and ignoreExisting is not set".format( output )
                else:
                    # It's ok to ignore - raise an IgnoreFile exception
                    # such that the top level knows not to try to send this
                    raise IgnoreFile
            else:
                # died of another reason than existing file
                raise RuntimeError, r
        # if net2file returns something like:
        # "!net2file = 0 : <number> ;" (in stead of "!net2file = 0 ;")
        # this means it has already <number> bytes of the file.
        # If resume is requested but we don't get a resumable reply
        # that's an error.
        if doResume and (len(r)<3 or self.DataSink.version()<supportsResume):
            loc = re.sub(":", "", self.DataSink.location())
            raise RuntimeError, "Resume requested but the remote jive5ab at {0} is too old. ".format(loc) +\
                    "Upgrade to at least {1}".format( supportsResumeVersion) + \
                    " or rerun with --allow_overwrite or --ignore_existing."

        # Only return not-None if there are bytes present remotely
        haveBytes = int(r[2]) if len(r)>=3 else 0
        return haveBytes if haveBytes>0 else None

    def setInputFormat(self, fmt):
        if fmt is not None:
            self.DataSink.send_query("mode={0}".format(fmt), [0])

    def rcv_bytecount(self):
        r = self.DataSink.send_query("net2file?")
        # this will currently fail, have to look into jive5ab code
        # 26 Jan 2015 "net2file?" reply fixed:
        #             net2file? => !net2file? 0 : active : <count>
        #                          0          1   2        3
        inactive  = len(r)>=3 and r[2]=="inactive"
        incorrect = len(r)<4
        return None if inactive or incorrect else int(r[3])

    def cancel(self):
        self.DataSink.send_query("net2file=close", Mark5.anyReturn)

    # net2file should not require mode to be set
    def needFormat(self):
        return False
        

class vbs_record(DestXFER):
    def __init__(self, datasink):
        super(vbs_record, self).__init__( datasink )

        # Are we supposed to record in Mark6 format? Or did the user
        # specify that we should record on a specific set of disks?
        mark6     = hasattr(self.DataSink.destination, 'mark6')
        disks     = hasattr(self.DataSink.destination, 'disks')
        supports6 = (self.DataSink.version()>=supportsMk6)

        # better be talking to a version of jive5ab who speaks '6 or
        # supports selecting of disks, in case either is needed
        if mark6 and not supports6:
            raise RuntimeError, "Remote jive5ab [{0}] does not support Mark6, need >=2.6.0".format( self.DataSink.get_version() )
        if disks and not supports6:
            raise RuntimeError, "Remote jive5ab [{0}] does not support selecting disks/MSNs, need >=2.6.0".format( self.DataSink.get_version() )

        # On systems that support Mark6, set the recording format explicitly
        if supports6:
            self.DataSink.send_query("record=mk6:{0}".format(1 if mark6 else 0), [0])

        # Also configure a different blocksize - the vbs file size
        # 256MB for flexbuf file chunks and 10000000 for Mark6 block size 
        # which is the MIT Haystack d-plane block size 
        self.DataSink.send_query("net_protocol=::{0}:8".format(10000000 if mark6 else "256M"))

        # Let's think about number of writers. Start with default of 4.
        nWrite = 4
        if disks:
            # set_disks = <pattern> [ : <pattern>...]
            # !set_disks = 0 : <nmatchingdisks>
            # 0            1   2
            dsk    = self.DataSink.destination.disks.replace(",", ":")
            reply  = self.DataSink.send_query("set_disks="+dsk, [0])
            nWrite = int(reply[2])

        # at the recorder, configure the number of disk writers
        self.DataSink.send_query("record=nthread:1:{0}".format(nWrite), [0])


    def setInputFormat(self, fmt):
        self.mode = fmt

    def open(self, output):
        # start a recording on the FlexBuff
        # apparently we do need a non-empty mode for that
        if self.mode is None:
            mode_required("record on FlexBuff/Mark6")
            raise RuntimeError,"data format not set"
        self.DataSink.send_query("mode={0}".format(self.mode), [0])
        self.DataSink.send_query("record=on:{0:s}".format(output), [0])

    def rcv_bytecount(self):
        # Poll the record status
        r = self.DataSink.send_query("record?", [0])
        # !record? 0 : inactive
        # !record? 0 : active : <bytecount>
        # 0        1   2        3
        inactive  = len(r)>=3 and r[2]=="inactive"
        incorrect = len(r)<4
        return None if inactive or incorrect else int(r[3])

    def cancel(self):
        # record=off on FlexBuff can take quite a long time. We'll give it a
        # minute before giving up
        self.DataSink.send_query("record=off", Mark5.anyReturn, timeout=60)
        self.DataSink.send_query("mode=none", [0])

    # vbsrecord can only record known format
    def needFormat(self):
        return True


class net2vbs(DestXFER):
    def __init__(self, datasink):
        super(net2vbs, self).__init__( datasink )

        # when configuring the number of readers/writers we make some
        # assumptions:
        #   * reading vbs disks is faster than writing (thus nDiskReader <
        #     nDiskWriter)
        #   * the number of netwriters == netreaders so they'll be a nice 
        #     balanced match
        # configure number of netreaders + diskwriters at the receiving end
        # NOTE: 'nthread' is a global parameter which is settable from the
        #       command line
        self.DataSink.send_query("net2vbs=nthread:{0}:{1}".format(nthread, max(nthread+1, 8)), [0])

        # Deal with FlexBuff/Mark6 setup; format and destination disks
        mark6     = hasattr(self.DataSink.destination, 'mark6')
        disks     = hasattr(self.DataSink.destination, 'disks')
        supports6 = (self.DataSink.version()>=supportsMk6)

        # better be talking to a version of jive5ab who speaks '6 or
        # supports selecting of disks, in case either is needed
        if mark6 and not supports6:
            raise RuntimeError, "Remote jive5ab [{0}] does not support Mark6, need >=2.6.0".format( self.DataSink.get_version() )
        if disks and not supports6:
            raise RuntimeError, "Remote jive5ab [{0}] does not support selecting disks/MSNs, need >=2.6.0".format( self.DataSink.get_version() )

        # On systems that support Mark6, set the recording format explicitly
        if supports6:
            self.DataSink.send_query("record=mk6:{0}".format(1 if mark6 else 0), [0])

        # if the destination specified some disks to record on, do configure that now
        if disks:
            # set_disks = <pattern> [ : <pattern>...]
            # !set_disks = 0 : <nmatchingdisks>
            # 0            1   2
            dsk    = self.DataSink.destination.disks.replace(",", ":")
            reply  = self.DataSink.send_query("set_disks="+dsk, [0])

    def setInputFormat(self, fmt):
        pass

    def open(self, output):
        # We ignore the output name because the "sync" method will send the
        # file name in each synchronization transfer
        self.DataSink.send_query("net2vbs=open", [0])

    def rcv_bytecount(self):
        return 0

    def cancel(self):
        self.DataSink.send_query("net2vbs=close", Mark5.anyReturn, timeout=10)

    # net2vbs doesn't need format
    def needFormat(self):
        return False

############################################################################
##
##  All possible transfer end points have been defined, now we patch
##  them up together to form the supported transfers
##
############################################################################


##### lcl transfers only allowed if media are different
def lcl_xfer(src, dst):
    matrix = {
        (media_type.DISK, media_type.FILE): (disk2file,     DiskSource, disk2file,     FileDest, True),
        (media_type.FILE, media_type.DISK): (file2disk,     FileSource, file2disk,     DiskDest, False),
        (media_type.IN,   media_type.FILE): (in2file,       InSource,   in2file,       FileDest, False),
        (media_type.IN,   media_type.DISK): (in2disk,       InSource,   in2disk,       DiskDest, False),
        (media_type.MEM,  media_type.FILE): (mem2file,      MemSource,  mem2file,      FileDest, False),
        (media_type.VBS,  media_type.FILE): (disk2file_vbs, VBSSource,  disk2file_vbs, FileDest, True),
        (media_type.MK6,  media_type.FILE): (disk2file_vbs, VBSSource,  disk2file_vbs, FileDest, True)
    }
    key = (src.mediaType, dst.mediaType)
    if not key in matrix:
        raise ValueError, "Unsupported local transfer {0} => {1}".format(src.mediaType, dst.mediaType)
    return matrix[ key ]

## local transfer with cornerturning
def lcl_ct_xfer(src, dst):
    matrix = {
        (media_type.DISK, media_type.FILE): (spid2file, DiskSource, spid2file, FileDest, False),
        (media_type.FILE, media_type.FILE): (spif2file, FileSource, spif2file, FileDest, False),
        (media_type.IN,   media_type.FILE): (spin2file, FileSource, spin2file, FileDest, False)
    }
    key = (src.mediaType, dst.mediaType)
    if not key in matrix:
        raise ValueError, "Unsupported local corner turning transfer {0} => {1}".format(src.mediaType, dst.mediaType)
    return matrix[ key ]

#### The remote transfers: *2net + net2*
# here the media may be identical
def remote_xfer(src, dst):
    matrix = {
        (media_type.DISK, media_type.DISK): (disk2net,     DiskSource, net2disk,   DiskDest, False),
        (media_type.DISK, media_type.FILE): (disk2net,     DiskSource, net2file,   FileDest, True),
        (media_type.FILE, media_type.DISK): (file2net,     FileSource, net2disk,   DiskDest, False),
        (media_type.FILE, media_type.FILE): (file2net,     FileSource, net2file,   FileDest, True),
        (media_type.IN,   media_type.DISK): (in2net,       InSource,   net2disk,   DiskDest, False),
        (media_type.IN,   media_type.FILE): (in2net,       InSource,   net2file,   FileDest, False),
        (media_type.IN,   media_type.VBS):  (in2net,       InSource,   vbs_record, VBSDest,  False),
        (media_type.IN,   media_type.MK6):  (in2net,       InSource,   vbs_record, VBSDest,  False),
        (media_type.MEM,  media_type.DISK): (mem2net,      MemSource,  net2disk,   DiskDest, False),
        (media_type.MEM,  media_type.FILE): (mem2net,      MemSource,  net2file,   FileDest, False),
        (media_type.FILE, media_type.VBS):  (file2net,     FileSource, vbs_record, VBSDest,  False),
        (media_type.FILE, media_type.MK6):  (file2net,     FileSource, vbs_record, VBSDest,  False),
        (media_type.DISK, media_type.VBS):  (disk2net,     DiskSource, vbs_record, VBSDest,  False),
        (media_type.DISK, media_type.MK6):  (disk2net,     DiskSource, vbs_record, VBSDest,  False),
        (media_type.VBS,  media_type.VBS):  (vbs2net,      VBSSource,  net2vbs,    VBSDest,  True),
        (media_type.VBS,  media_type.FILE): (disk2net_vbs, VBSSource,  net2file,   FileDest, True),
        (media_type.MK6,  media_type.FILE): (disk2net_vbs, VBSSource,  net2file,   FileDest, True),
        (media_type.VBS,  media_type.DISK): (disk2net_vbs, VBSSource,  net2disk,   DiskDest, False),
        (media_type.MK6,  media_type.DISK): (disk2net_vbs, VBSSource,  net2disk,   DiskDest, False),
    }
    key = (src.mediaType, dst.mediaType)
    if not key in matrix:
        raise ValueError, "Unsupported remote transfer {0} => {1}".format(src.mediaType, dst.mediaType)
    return matrix[ key ]

# remote corner turners
def remote_ct_xfer(src, dst):
    matrix = {
        (media_type.DISK, media_type.DISK): (split2net, DiskSource, net2disk,   DiskDest, False),
        (media_type.DISK, media_type.FILE): (split2net, DiskSource, net2file,   FileDest, False),
        (media_type.DISK, media_type.VBS):  (split2net, DiskSource, vbs_record, VBSDest,  False),
        (media_type.DISK, media_type.MK6):  (split2net, DiskSource, vbs_record, VBSDest,  False),
        (media_type.FILE, media_type.DISK): (split2net, FileSource, net2disk,   DiskDest, False),
        (media_type.FILE, media_type.FILE): (split2net, FileSource, net2file,   FileDest, False),
        (media_type.FILE, media_type.VBS):  (split2net, FileSource, vbs_record, VBSDest,  False),
        (media_type.FILE, media_type.MK6):  (split2net, FileSource, vbs_record, VBSDest,  False),
        (media_type.IN,   media_type.DISK): (split2net, InSource,   net2disk,   DiskDest, False),
        (media_type.IN,   media_type.FILE): (split2net, InSource,   net2file,   FileDest, False),
        (media_type.IN,   media_type.VBS):  (split2net, InSource,   vbs_record, VBSDest,  False),
        (media_type.IN,   media_type.MK6):  (split2net, InSource,   vbs_record, VBSDest,  False),
    }
    key = (src.mediaType, dst.mediaType)
    if not key in matrix:
        raise ValueError, "Unsupported remote transfer {0} => {1}".format(src.mediaType, dst.mediaType)
    return matrix[ key ]

# One entry point which decides if it's a local or a remote transfer
# Will return a quad-tuple with type constructors:
#    (src_xfer_type, src_type, dst_xfer_type, dst_type)
#
# The calling code can construct the DataSource and DataSink from
# the 'src_type' and 'dst_type'. Then loop over all the entries
# in the DataSource and transfer them to the DataSink, using
# the transfer types to set up the source, destination end points
def xfer_selector(src, dst):
    # we have a matrix of endpoints (disk->file, file->disk, etc)
    # and the source/destination ip addresses; now we 
    # decide which transfers to choose
    #  (e.g. "disk(local) -> file(local) => disk2file"
    #        "disk(X)     -> file(Y)     => disk2net + net2file"
    matrix = {
            (True,  False):  lcl_xfer,
            (True,  True ):  lcl_ct_xfer,
            (False, False):  remote_xfer,
            (False, True):   remote_ct_xfer
        }
    lcl = src.controlIP == dst.controlIP and src.controlPort == dst.controlPort
    return matrix[ (lcl, do_corner)  ](src, dst)


## context manager for the transfer type
class actual_xfer(object):
    def __init__(self, sx, dx):
        self.sourceXFER = sx
        self.destXFER   = dx

    def __enter__(self):
        return self

    def __exit__(self, type, value, traceback):
        self.sourceXFER.cancel()
        self.destXFER.cancel()

def attr(obj):
    import inspect
    return filter(lambda x: x[0][0]!='_', inspect.getmembers(obj, lambda x: not inspect.ismethod(x)))

## context manager for a transfer - this means we have 
## the option of doing a clean shutdown
class xfer_context:
    def __init__(self, src, dst):
        self.srcLocation = src
        self.dstLocation = dst
        # Upon construction get the 4 types of the objects we'll need for
        # the transfer
        (self.sxtype, self.stype, self.dxtype, self.dtype, resumable) = xfer_selector(self.srcLocation, self.dstLocation)
        if doResume and not resumable:
            raise RuntimeError, "Sadly, this transfer cannot be resumed. Re-run with --ignore_existing or --allow_overwrite, if that helps"

    def __enter__(self):
        # Upon entering the context, we create the DataSource and DataSink objects
        self.dataSource = self.stype(self.srcLocation)
        self.dataSink   = self.dtype(self.dstLocation)
        # Check if this will work
        if len(self.dataSource)>1 and not self.dataSink.multiple_outputs():
            raise RuntimeError, "Source specifies >1 scan but destination is explicitly set"
        return self

    def __exit__(self, tp, val, tb):
        # make sure echo is on again
        self.dataSource.echo_on()

        # and cleanup
        self.dataSource.cleanup()
        self.dataSink.cleanup()
        if not (tp is None and val is None and tb is None):
            if queries:
                print traceback.print_exception(tp, val, tb)
            else:
                print val
            sys.exit( -1 )
        return True

    def __call__(self):
        # Ok, we're requested to actually do the transfers
        dataSource = self.dataSource
        dataSink   = self.dataSink
        with actual_xfer(self.sxtype(dataSource), self.dxtype(dataSink)) as xfer:
            sxfer = xfer.sourceXFER
            dxfer = xfer.destXFER
            for scan in dataSource:
                outname = dataSink.compute_outputname(scan)
                print dataSource.location()+scan.name(), "=>", dataSink.location()+outname

                try:
                    # configure different input format for the receiver, in case it's not the same as
                    # the source data format [ie cornerturning data format X into legacy VDIF]
                    # But only do it if the destination indicates it needs it.
                    if dxfer.needFormat():
                        dxfer.setInputFormat( sxfer.outputFormat(scan) )
                    nbyte = dxfer.open(outname)
                    sxfer.start(scan, dataSink.dataIP(), haveBytes=nbyte)
                except IgnoreFile:
                    print "{0} already exists, skipping".format(outname)
                    dxfer.cancel()
                    sxfer.cancel()
                    # need to give udt quite-some-time FFS
                    time.sleep(10)
                    continue

                # turn echo off whilst polling for completeness
                dataSource.echo_off()

                progress = Progress(45) if verbose else DummyProgress()
                # new enough jive5ab's will better inform us about number
                # of bytes read and written
                nbyte    = None
                while True:
                    p = sxfer.progress()
                    if p is None:
                        break
                    if len(p)==1:
                        # new style return value: transfer completed
                        # succesfully; the return value is the number of
                        # bytes sent
                        nbyte = p[0]
                        break
                    # transfer not finished yet, update progress display & wait a bit more
                    progress(*p)
                    time.sleep(1)
                # done polling - we can safely put echo back on
                dataSource.echo_on()

                # wait for remote end to flush all data
                oldbytes = dxfer.rcv_bytecount()
                progress.say("\rWaiting for remote end to flush ... "+str(oldbytes))
                while True:
                    time.sleep(1)
                    newbytes = dxfer.rcv_bytecount()
                    if newbytes==oldbytes:
                        break
                    oldbytes = newbytes
                    progress.say("\rWaiting for remote end to flush ... "+str(oldbytes))
                # do cleanup at both ends
                sxfer.cancel()
                dxfer.cancel()
                progress.done()
                # give UDT some time to close the listening file descriptor ...
                time.sleep( 10 )
                # if number-of-bytes sent is known, we can verify if all of
                # 'm were written to the destination
                if nbyte is not None and newbytes is not None and (nbyte!=newbytes):
                    raise RuntimeError, "Not all bytes sent were written to the destination"


class catcher(object):
    def __init__(self):
        pass

    def __enter__(self):
        return self

    def __exit__(self, tp, val, tb):
        # did we exit because of an exception?
        if not (tp is None and val is None and tb is None):
            # ok, we must indicate this
            if queries:
                traceback.print_exception(tp, val, tb)
            else:
                print val
            sys.exit( -1 )
        return True

# returns None if the argument wasn't present, tp(<value>) if it was
# (such that it will give an exception if e.g. you expect int but
#  the user didn't pass a valid int
def get_val(arg, tp=str):
    conversion_error = False
    try:
        # is 'arg' given?
        aidx = sys.argv.index(arg)  # raises ValueError if not found FFS
        aval = sys.argv[aidx+1]     # raises IndexError

        # Check it doesn't start with a '-'!
        if aval[0]=='-':
            raise RuntimeError, "Option %s expects argument, got another option '%s'" % (arg, aval)

        # remove those arguments
        del sys.argv[aidx]; del sys.argv[aidx]
        # now set 'conversion_error' to True because the following
        # statement could (also) raise a ValueError (like the
        # "sys.argv.index()"). FFS Python! So we must take measures to tell
        # them apart
        conversion_error = True
        return tp(aval)
    except ValueError:
        if conversion_error:
            raise
        # no 'arg' given, don't complain
        return None
    except IndexError:
        # Mission option value to option
        raise RuntimeError, "Mission optionvalue to {0}".format(arg)


def mode_required(app):
    print "#"*24
    print """
In order to {0} the system *must* know the format of the input data.

To this effect, please add a '-mode <mode>' argument to the command line.

The <mode> parameter takes the following, canonicalized, form.  In all
cases, if necessary, the track data rate will be automatically inferred by
jive5ab from the complete setting.

    MARK5B-<total Mbps>-<# channels>-<# bits per sample>
          MARK5B-2048-16-2      for 2 Gbps, 16 ch Mark5B data (32 MHz bands)
          MARK5B-128-4-1        for 128 Mbps, 4ch Mark5B data

    VDIF[L]_<data size>-<total Mbps>-<# channels>-<# bits per sample>
          We only support simple VDIF: the same number of channels and the
          same number of bits-per-sample for each thread. The actual VDIF
          frame size is automatically computed from the <data size> and
          wether it is legacy VDIF ("VDIFL", 16 byte header) or VDIF (32
          byte header).

          VDIFL_5000-1024-16-2  for 1 Gbps legacy VDIF with 5000-byte data
                                array size
          VDIF_8192-4096-32-2   for 4 Gbps VDIF with 8192-byte data array
                                size

    [MKIV|VLBA]<i>_<j>-<total Mbps>-<# channels>-<# bits per sample>
                 (where <i>_<j> is the fan-in/fan-out, e.g. '1_2')
          MKIV1_2-1024-16-2     for 1 Gbps 16ch MarkIV data in 64 tracks@16 Mbps
          VLBA2_1-128-8-2       for 128 Mbps 8ch VLBA data in 8 tracks@16 Mbps

""".format(app)
    print "#"*24


##################
# the main program
##################

if __name__ == "__main__":
    #########################
    ## Check command line
    #########################

    # Was '-h' requested?
    if len(sys.argv)==1 or '-h' in sys.argv:
        usage()
        sys.exit( 0 )

    # Or maybe '-v' (version)
    if '-v' in sys.argv:
        print version
        sys.exit( 0 )

    # before actually starting to process the args ... we must find the "-p
    # <port>" and extract it manually (the alternative would be to say
    # "p=<port>" but that's a bit ugly and looks too much like dd(1).
    p = get_val('-p', int)
    if p:
        dataport = p
    m = get_val('-m', int)
    if m:
        if m<64:
            raise RuntimeError, "Value '{0}' for MTU is lower than ethernet minimum of 64".format(m)
        if m<1500:
            print "WARN: mtu set to value <1500. Probably negative impact on transfer speed"
        mtu = m
    n = get_val('-n', int)
    if n:
        if n<=1:
            raise RuntimeError, "Illegal number of parallel file transfers: {0}".format(n)
        nthread = n
    # Check if a rate was given
    rate = get_val('-r')
    if rate:
        # convert rate to bits per second
        rate = float(procByte(rate, float, rxBytenumRate, scaleTableMetric))
        if rate==0:
            raise RuntimeError, "Data rate 0 (zero) is not supported"
        # ipd in nano seconds = (mtu*8 / rate) * 1.0e9
        ipd = int( (float(mtu)*8 / rate)*1.0e9 )

    # override time-out value?
    timeOut = get_val('-t')
    if timeOut:
        timeOut = float(timeOut)

    # Extract/check cornerturning options (phase 1)
    # [if we record to VBS we *must* have a mode, but we must first
    #  parse the DST uri before we know that ..]
    cornerturn = get_val('-ct')
    mode       = get_val('-mode')
    vdif       = get_val('-vdif')

    # If vdif parameters are set, we do cornerturning 
    do_corner  = bool(vdif)

    # Split remaining commandline in options and arguments
    (opts, args) = partition(lambda x: re.match("^-", x), sys.argv[1:])

    # require two arguments
    if len(args)!=2:
        usage()
        sys.exit( 1 )

    # UDT requested?
    if '-udt' in opts:
        protocol="udt"

    if '-q' in opts:
        verbose=False

    if '-a' in opts:
        duplicates=True

    # hidden option '-d' - turn on debugging
    if '-d' in opts:
        queries=True

    # Rate limiting with tcp protocol is nonsense
    if rate and "tcp" in protocol:
        print "Rate limiting over TCP is not supported"
        sys.exit( 1 )

    if verbose:
        print """%s
    copy VLBI data from somewhere to elsewhere
               (c) H. Verkouter
""" % version

    # Note: we've already checked that there's exactly two arguments!
    src = parseURI(args[0], uri_type.SRC)
    dst = parseURI(args[1], uri_type.DST)

    # Now that we've parsed the SRC and DST, it is time to check again if we
    # need the mode argument: if we are recording *to* VBS but not *from*
    # VBS.
    record_vbs = (dst.mediaType in [media_type.VBS, media_type.MK6] and src.mediaType!=media_type.VBS)

    if (do_corner or record_vbs):
        #if mode is None:
        #    if do_corner:
        #        mode_required("cornerturn a data stream into its individual channels")
        #    else:
        #        mode_required("record onto a {0} system".format("Mark6" if hasattr(dst, 'mark6') else "FlexBuf"))
        #    raise RuntimeError,"The input mode (data format) must be set"
        # ok mode was given
        if mode is not None:
            mode = mode.upper()
    else:
        # if the mode has been set for a transfer that does not need/want
        # it, it is an error
        if bool(mode):
            raise RuntimeError, "A '-mode <mode>' argument was given but the current transfer does not want it."

    # In case dst addresses localhost and dataIP is not given,
    # we replace the dataIP with the external IP address of this
    # machine [only if there's a unique IP address, that is]
    if (dst.controlIP=="localhost" or dst.controlIP=="127.0.0.1") and \
       (src.controlIP!="localhost" and src.controlIP!="127.0.0.1")and dst.dataIP is None:
        dst.dataIP = get_local_ext_ip()
        if dst.dataIP is None:
            allIPs = get_local_ext_ip(False)
            print "*****************************************************"
            print "*                                                   *"
            print "*   It looks like you're copying into this machine  *"
            print "*   but m5copy cannot infer the external IPv4       *"
            print "*   address to use for this machine.                *"
            
            print "*                                                   *"
            print "*   Please specify the external IPv4 address to     *"
            print "*   use in the destination of your transfer, eg:    *"
            print "*                                                   *"
            print "*      m5copy SRC file://192.168.1.4/path/          *"
            print "*      m5copy SRC file://my.host.name/path/         *"
            if allIPs:
                line = "*                                                   *"
                print line
                print "*  Detected external addresses:                     *"
                def p(x):
                    print "*      {0}{1:{2}}*".format( x, "", len(line)-len(x)-8 )
                map(p, allIPs)
            print "*                                                   *"
            print "*****************************************************"
            sys.exit( 1 )

    # IF the '-rt' (realtime) flag is given, only allow that
    # IF the src.media_type is 'IN' or 'MEM'!
    if '-rt' in opts:
        if not (src.mediaType in [media_type.IN, media_type.MEM]):
            raise RuntimeError, "-rt (realtime) flag only supported with source URI of type 'IN' or 'MEM'"
        protocol="udps"

    # absolutely hidden option - allow overwriting of existing data files
    allowOverwrite = '--allow_overwrite' in opts
    if allowOverwrite and dst.mediaType==media_type.FILE:
        if not ('--blame_guifre' in opts):
            print "****************************************************"
            print "*   allow_overwrite requested but you haven't      *"
            print "*   indicated you know what you're doing.          *"
            print "*                                                  *"
            print "*   This option will potentially overwrite         *"
            print "*   existing file(s) at the destination.           *"
            print "*                                                  *"
            print "*   Please add the following command-line flag     *"
            print "*   as well to acknowledge you understand the      *"
            print "*   consequences.                                  *"
            print "*                                                  *"
            print "*     --blame_guifre                               *"
            print "*                                                  *"
            print "*   Thank you for your flying m5copy!              *"
            print "****************************************************"
            sys.exit( 1 )

    # Ignore existing
    ignoreExisting = '--ignore_existing' in opts
    doResume       = '--resume' in opts

    # Check orthogonality?
    if [allowOverwrite, ignoreExisting, doResume].count(True)>1:
        print "Please check consistency. Only one of:"
        print "   --allow_overwrite"
        print "   --ignore_existing"
        print "   --resume"
        print "may be given. They are mutually exclusive."
        sys.exit(3)

    if verbose:
        print src," ===> ",dst
   
    with catcher() as c:
        with xfer_context(src, dst) as xfer:
            xfer()
