#!/usr/bin/env python
from   __future__ import print_function
from   six        import iteritems
# Copy data between different machines running jive5a(b(c))
import socket, time, sys, copy, itertools, pydoc, re, os, datetime, struct, random
import string, traceback, subprocess, shlex, fnmatch, functools, glob, operator, collections



## Current version
version="$Id: m5copy,v 1.61 2021/24/12 20:23:00 verkout Exp $"

## Shorthands
RUN      = subprocess.Popen
SHLEX    = lambda arg  : shlex.split(arg) if isinstance(arg, type("")) else arg
STDOUT   = lambda cmd  : RUN(SHLEX(cmd), stdout=subprocess.PIPE).communicate(None)[0]
LINES    = lambda cmd  : STDOUT(cmd).split('\n')
const    = lambda c    : lambda _: c
Map      = lambda f    : functools.partial(map, f)
Filter   = lambda f    : functools.partial(filter, f)
choice   = lambda p,t,f: lambda x: t(x) if p(x) else f(x)
compose  = lambda *fns : lambda x: functools.reduce(lambda v, fn: fn(v), reversed(fns), x)
identity = lambda x    : x

# Very crude Py2/Py3 detection - 
# to be able to have an as efficient as possible 
# "convert map/filter/iterable into list"
# 2to3 would transform:
#   map(....) 
# unconditionally into list( map(...) ) for ensuring
# Py2/Py3 compatibility. But if that code is run under
# Py2 the map() result already *is* a list and 
# "list( list(...) )" is dumb - a 2nd copy of the list is made.
# Using our "List( ... )" below eliminates that, only transforms
# into list under Py3, and is a no-op in Py2
try:
    t       = raw_input
    List    = identity
    # In Py2 we never have to consume an iterable for its side effects
    consume = identity
    Range   = range
    Input   = raw_input
except NameError:
    List  = list
    Range = lambda *args: list(range(*args))
    # Thanks to Py3 one must sometimes drain an iterable for its side effects. Thanks guys!
    # From https://docs.python.org/2/library/itertools.html#recipes
    #     consume(), all_equal()
    consume  = functools.partial(collections.deque, maxlen=0)
    Input    = input
    # From https://portingguide.readthedocs.io/en/latest/strings.html#conversion-to-text
    unicode  = str

# Can easily insert this one in composition
def Print(x):
    print(x)
    return x

# Some systems don't have collections.Counter, ffs
Counter = collections.Counter if hasattr(collections, 'Counter') else None
if Counter is None:
    # from: /usr/local/Cellar/python/2.7.6/Frameworks/Python.framework/Versions/2.7/lib/python2.7/collections.py
    # But really heavily stripped because we only need a /very/ limited functionality in here
    from  _abcoll import Mapping
    class Counter(dict):
        def __init__(self, iterable=None, **kwds):
            super(Counter, self).__init__()
            self.update(iterable, **kwds)

        def __missing__(self, key):
            return 0

        def update(self, iterable=None, **kwds):
            '''Like dict.update() but add counts instead of replacing them.'''
            # The regular dict.update() operation makes no sense here because the
            # replace behavior results in the some of original untouched counts
            # being mixed-in with all of the other counts for a mismash that
            # doesn't have a straight-forward interpretation in most counting
            # contexts.  Instead, we implement straight-addition.  Both the inputs
            # and outputs are allowed to contain zero and negative counts.
            if iterable is not None:
                if isinstance(iterable, Mapping):
                    if self:
                        self_get = self.get
                        for elem, count in iteritems(iterable):
                            self[elem] = self_get(elem, 0) + count
                    else:
                        super(Counter, self).update(iterable) # fast path when counter is empty
                else:
                    self_get = self.get
                    for elem in iterable:
                        self[elem] = self_get(elem, 0) + 1
            if kwds:
                self.update(kwds)


## Support for m5copy acting as interpreter of a text-file, as if the
## text file were executable. m5copy can read from stdin by giving a "-"
## (dash) as last argument on the command line.
##
## The first line in the script (the #! line) is interpreted as template command
## line where occurrences of the form "{n}" will be replaced by the n-th
## field from each uncommented line.
##
##    $> cat copy_files
##    #!/usr/bin/env m5copy -udt -r {0} file://remote.host.ip/{1} file:///path/to/dest/
##    # pull the following files from remote.host.ip to local machine
##    # each file at a different line rate
##    100M /aap/noot/em048a_on_no0001.m5a
##    256k /aap/noot/rk1418.m5a
##    1G   /aap/noot/gm038_od_no0012.vdif
##
##    $> chmod +x copy_files
##    $> ./copy_files
##
## Reading from stdin:
##
##    $> echo /mnt/disk/1/* | m5copy -udt file:///{0} DST -
##    # with "DST" being the destination URL

## We never ever take a file name as command line argument.
## Unless we are being called to interprete a text file, in which case it is
## the final argument. When "./copy_files" is executed (see example above), m5copy
## is called with the following command line:
##
##      sys.argv = ["m5copy", "-udt", "-r", "{0}",
##                  "file://remote.../{1}", "file:///...",
##                  "./copy_files"]
##
## i.e. the name of the script file is appended at the end of the command
## line found in the script file itself.
##
## If the last argument on the command line is '-', we read from stdin
if len(sys.argv)>1 and (os.path.isfile(sys.argv[-1]) or sys.argv[-1]=='-'):
    # Form single string command line, stripping the last element
    cmdLine = " ".join(sys.argv[:-1])

    # Generators that generate lines from different sources of input
    def filereader(fn):
        with open(fn) as f:
            for line in f:
                yield line
        raise StopIteration
    def stdinreader():
        while True:
            try:
                line = Input()
                yield line
            except EOFError:
                raise StopIteration

    # Decide where to read from
    linesrc = sys.argv[-1]
    linesrc = stdinreader() if linesrc=='-' else filereader(linesrc)

    # And do it
    for line in linesrc:
        # strip comment and then leading + trailing whitespace
        line = re.sub("#.*$", "", line).strip()
        # if nothing left, go on
        if not line:
            continue
        # Make new commandline and execute it
        cmd = cmdLine.format(*SHLEX(line))
        print("#",cmd)
        rv  = RUN( SHLEX(cmd) ).wait()
        if rv!=0:
            print("m5copy exited with non-zero return code {0}".format(rv))
            sys.exit( rv )
    # and we're done
    sys.exit( 0 )

# parse jive5ab version number string into a number
# such that we can easily compare
def parse_version(txt):
    # jive5ab versions are X.Y[.Z[(.-)gunk]]
    # find all the sequences that are made solely out of digits -
    # the actual parts of the version number.
    # Then convert to int.
    # Then start multiplying by 10000 for the first version digit and
    # by x/100 for each next digit and add them up.
    return functools.reduce(lambda vsn_factor, x: (vsn_factor[0] + x*vsn_factor[1], vsn_factor[1]/100.0),
                            map(int, re.findall(r"[0-9]+", txt)),
                            (0.0, 10000))[0]

## Bastard Python devs. "datetime.timedelta" objects
## only acquired ".total_seconds()" in 2.7
def total_seconds(td):
    if hasattr(td, 'total_seconds'):
        return td.total_seconds()
    else:
        return  (td.microseconds + (td.seconds + td.days * 24 * 3600) * 10**6) / 10**6

## Standardized date/time format
def timestampNow():
    return datetime.datetime.now().strftime("%Y-%b-%dT%Hh%Mm%Ss")

# A very special type of exception that might be raised
class IgnoreFile(Exception):
    pass


########################################
# Attempt to find the external IP
# address of this machine. On multi-homed
# machines it will return None
#
# This method is used in order to be able
# to set a default external ip address
# in case someone tries to do a network
# copy *into* the local machine (i.e. the
# machine m5copy is running on); in this
# case, the DST::controlip == 127.0.0.1
# and telling a remote jive5ab to connect
# to that address isn't going to work
# very well, is it?
##########################################
def get_local_ext_ip(unique=True):
    # I've looked all over the 'net but there is
    # no portable Python way to get the
    # available interface addresses, other than
    # executing ifconfig ... (bah!)
    rxIf   = re.compile(r"^(?P<if>[^:]+):?\s+(Link|flags)")
    rxInet = re.compile(r"^\s*inet\s+((addr)?\s*:?\s*)(?P<inet>\S+)")

    # Note: this should never *break* m5copy
    try:
        tmp    = set()
        curIF  = None

        ifconfig = subprocess.Popen(["/sbin/ifconfig", "-a"], stdout=subprocess.PIPE)
        for line in ifconfig.communicate()[0].split('\n'):
            mo = rxIf.match(line)
            if mo:
                curIF = mo.group('if')
                continue
            mo = rxInet.match(line)
            if mo:
                # inspect the inet address; we're definitely skipping
                # 127.0.0.1 and multicast addresses
                inet = mo.group('inet')
                msb  = int( inet.split('.')[0] )
                if not (inet=="127.0.0.1" or (msb>=224 and msb<=239)):
                    tmp.add( inet )
        # tmp is the set of all IP addresses for this machine that are
        # not loopback or multicast
        if unique:
            return tmp.pop() if len(tmp)==1 else None
        else:
            return tmp
    except:
        return None


############################
## Support for 'enums'
##
## X = enum("AAP", "NOOT")
##
## var = X.AAP
##  ...
## if var == X.AAP:
##     ...
############################

class enum(object):
    def __init__(self, *seq):
        self.enums = seq
        for e in self.enums:
            setattr(self, e, e)

    # you can iterate over the enum to find out all defined values
    def __iter__(self):
        class enumiter(object):
            def __init__(self,enuminst):
                self.iterable = enuminst
                self.iter     = iter(enuminst.enums)
            # Cf. https://python-future.org/compatible_idioms.html#custom-iterators
            def __next__(self):
                return getattr(self.iterable, next(self.iter))
            next = __next__

        return enumiter(self)

    def __getitem__(self, idx):
        if idx in self.enums:
            return idx
        raise IndexError("{0} does not exist".format(idx))

## take a list of (pattern, replacement) tuples and run them
## over the string to produce the final edited string
subber   = lambda acc, pat_repl: re.sub(pat_repl[0], pat_repl[1], acc)
sub      = lambda txt, lst: functools.reduce(subber, lst, txt)

## expands string "1:10,13,20:22" into [1,2,3,4,5,6,7,8,9,10,13,20,21,22]
##   and "5:2" into [5,4,3,2]
##
## Supports arbitrary increments
##    1:10:2 => [1,3,5,7,9]
## Support arithmetic:
##  "2*10:3*10,12-2:12+2"
##  All expressions will be converted to int after evaluating
def expand_string_range(s, rchar=":"):
    rxNum = re.compile(r"^\d+$")
    rxRng = re.compile(r"^(?P<s>[-\d\.+*/%()]+)"+rchar+"(?P<e>[-\d\.+*/%()]+)(:(?P<step>[-+]?\d+))?$")
    def count_from_to(s,e,step):
        while abs(s-e)>=abs(step):
            #print("s:{0} e:{1} diff:{2}".format(s, e, abs(s-e)))
            yield s
            s = s + step
        if abs(s-e)<=abs(step):
            yield s
        raise StopIteration
    def mkcounter(item):
        mo = rxRng.match(item)
        if mo:
            # start, end may be expressions
            (s,e) = (int(eval(mo.group('s'))), int(eval(mo.group('e'))))
            defstep = 1 if (s<e) else -1
            step    = mo.group('step')
            step    = int(step) if step else defstep
            # Test if we actually *can* count from start -> end using step:
            # e.g.:    1 -> 10, step -1 isn't going to end very well is it?
            #         -1 -> -10, step 1         ,,           ,,
            # Step size "0" is ONLY allowed if start==end!
            # Also assure ourselves that the step direction and counting
            # direction are identical
            if (not step and (s-e)) or (((e-s) * step )<0):
                raise RuntimeError("cannot count from {0} to {1} with step {2}".format(s, e, step))
            return count_from_to(s, e, step)
        else:
            mo = rxNum.match(str(eval(item)))
            if not mo:
                raise ValueError("{0} is not a number! (It's a free man!)".format(item))
            # 'item' may be an expression!
            item = int(eval(item))
            # Note: seems superfluous to return a counter for 1 number but now
            # we have a list of iterables which can easily be transformed into
            # one list via itertools.chain() (see below)
            return count_from_to(item, item, 1)
    return list(itertools.chain(*[mkcounter(x) for x in s.split(",")]))


# given a number + unit, return number between 1.0 and scale +prefix+unit
#  ie.  1024000 "Byte" => "1000 kByte"
def sciprint(num, unit, scale=1000, fmt=".2f"):
    if num<1.0:
        prefixes = ["m", "u", "n", "f", "p", ""] 
        fn       = lambda n_p, pfx: (n_p[0]*scale, pfx) if n_p[0]<1.0 and (n_p[0]*scale!=n_p[0]) else n_p
    else:
        prefixes = ["k", "M", "G", "T", "P", "E"]
        fn       = lambda n_p, pfx: (n_p[0]/scale, pfx) if n_p[0]>scale else n_p
    (n, p) = functools.reduce(fn, prefixes, (float(num), ""))
    return "{0:{n_fmt}} {1}{2}".format(n, p, unit, n_fmt=fmt)



def progress_print(x):
    sys.stdout.write(x)
    sys.stdout.flush()

## A function returning a nice progress update including a bar + percentage, a la scp(1)
def progress(cur, s, e, sz):
    frac = (float(cur - s)/float(e - s)) if e!=s else 0
    pos  = int( frac * sz )
    if pos==0:
        pos = 1
    return "Progress |" + "="*(pos-1) + ">" + " "*(sz-pos)+"| {0:6.2f}%".format(frac*100)


class Progress(object):
    def __init__(self, size):
        self.now       = datetime.datetime.now
        self.size      = size
        self.lastTime  = self.now()
        self.lastCount = 0
        self.maxLen    = 0

    def __call__(self, current, start, end):
        now   = self.now()
        count = (current - start)
        dt    = total_seconds(now - self.lastTime)
        speed = 0.0
        if dt>0:
            speed = (count - self.lastCount) / dt
        txt = "\r" + progress(current, start, end, self.size)+" "+sciprint(speed, "byte/s", 1024)
        self.maxLen = max(self.maxLen, len(txt))
        progress_print( txt + " "*(self.maxLen - len(txt)) )
        self.lastTime  = now
        self.lastCount = count

    def say(self, txt):
        self.maxLen = max(self.maxLen, len(txt))
        progress_print( "\r" + txt + " "*(self.maxLen - len(txt)) )

    def done(self):
        progress_print( "\r" + " "*(self.maxLen) + "\r" )

class DummyProgress(object):
    def __init__(self):
        pass
    def __call__(self, current, start, end):
        pass
    def say(self, txt):
        pass
    def done(self):
        pass

### Sometimes you need a random sequence of 'n' alphanumerical characters
rndChars    = string.ascii_letters + string.digits
# Py2/Py3 have different ideas about the return value of os.urandom(n):
#   Py2: string of length n
#   Py3: bytes object with n bytes
# I have not been able to find a compatible way to process these return values
# transparently. Sigh. Bastards.
# The only way to generate strings of arbitray length seems to be to repeatedly
# call 'random.choice()' since 'sample()' and 'shuffle()' only generate a
# randomly ordered (sub)set of unique values from the population.
# This is not at all what we want.
random_word = lambda n: ''.join((random.choice(rndChars) for _ in range(n)))

############################################################################
## Defaults for the transfer: standard TCP protocol, Mark5 control,data port
############################################################################

mtu            = 1500
ipd            = 0
timeOut        = None
realtime       = False
nthread        = 1
queries        = False
verbose        = True
protocol       = "tcp"
socbuf         = "4M"
dataport       = 2630
duplicates     = False
controlport    = 2620
uri_type       = enum("SRC", "DST")
media_type     = enum("FILE", "DISK", "VBS", "MK6", "IN", "MEM", "ETD")
bank_type      = enum("A", "B")
uniqSuffix     = lambda scannum: ".scan." + str(scannum)
allowOverwrite = False  # this is a dangerous one ...
ignoreExisting = False
doResume       = False
xferDoneCount  = 2

# jive5ab features that are version dependent
supportsMk6           = parse_version("2.6.0") # jive5ab 2.6.0 and up support mk6/set_disks &cet
supportsEcho          = parse_version("2.6.0") # shutting down command echoing only
                                               # on cmd socket, not globally
supportsTransient     = parse_version("2.7.3") # transient runtimes - they get autmatically
                                               # deleted if the control connection dies
supportsResumeVersion = "2.6.1"
supportsResume        = parse_version(supportsResumeVersion) # net2file has to return the file size for this
                                                             # disk2file has to have a special 'resume' mode


def usage():
    elp = get_local_ext_ip()
    def_dataip= "DST::host (destination control ip/host)" if elp is None else elp
    pydoc.pager(
"""
Usage: {progname} [options] SRC DST

Copy VLBI data from SRC to DST. Both SRC and or DST may be located on remote
machines; the default is to address data on the local machine. There is a
possibility to force the data over a different network in case there exists a
different/faster network between the SRC and DST machines than the control
network. Please find examples at the end of the documentation.

SRC, DST are uri-like VLBI data locations, explained in more detail below.

    mk5://.../         mk6://.../     file://../
    vbs://.../         in://.../      mem://../
    etd://.../


Options:

    -h        print this message and exit
    -v        print current version and exit
    -q        be quiet, do not display progress (default: {def_verbose})
    -a        allow duplicate scan names on a disk pack to be
              automatically renamed to <scan>.<scannumber> (default: {def_allow})
    -e <num>  expect <num> identical receive byte counts being returned before
              deciding all bytes have, in fact, been received. Because
              m5copy does not know how many bytes the sender actually sent,
              it uses the 'received byte count' as heuristic to see if data
              is still flowing into the receiver. Default: stop transfer
              after {def_expect} identical byte counts received
    -udt      use UDT as protocol (default: {def_proto})
    -srt      use SRT as protocol (default: {def_proto})
    -rt       allow real time transfer. Only supported on "in://" and
              "mem://" SRC transfers. If set, it will enable the
              (unreliable) e-VLBI protocol "UDPs" - UDP with sequence number.
    -p <port> use this port number for data channel (default: {def_data_port})
    -m <mtu>  use this MTU (default: {def_mtu})
              Note: only used when using UDT, SRT, or real-time protocol!
    -r <rate> limit transmit data rate to <rate> bits per second.
              (default: unlimited - as fast as it will go).
              For your convenience you may use the suffixes 'kMG',
              metric thousands ("x1000"), not binary thousands.
              Note: only effective when using UDT!
    -t <#sec> set socket timeout to <#sec> seconds. Note that the
              program may use different time out values yet; m5copy knows
              that some commands generally take longer to complete than
              others. m5copy uses the maximum time out value of the
              internally specified value and the command line supplied
              value, if any.
    -n <num>  use <num> parallel chunk transfers when doing
              flexbuff => flexbuff transfers (default: {def_nthread})
    -mode <X> for some transfers it is necessary to actually know the
              actual data format. This option exists to manually override
              the automatic detection built in in m5copy (in case it
              misdetects the format) or when it fails to correctly
              determine the format. The mode <X> is given in "libmk5access"
              (cf. W. Brisken) one-string-describes-all format:
                format-datarate-numberOfChannels-bitsPerSample
              e.g.
                mark5b-1024-16-2      for 1Gbps Mark5B
                vdif_8000-8192-32-2   for 8Gbps VDIF with 8000 byte data
                                      array size

    If the destination is "file://" and it already exists, the default
    action for m5copy is to fail: no data will be overwritten. Several
    options can modify this behaviour:

    --ignore_existing
    --ignore-existing
              Ignore existing FILE(S) on the destination. With this option,
              "wildcard" file transfers can be resumed; files that have
              already been transferred will be skipped over, in stead
              of m5copy exiting. This assumes that files that exist are
              complete.
    --allow_overwrite
    --allow-overwrite
              All destination FILE(S) will be overwritten, irrespective of
              their completeness level. Basically this restarts the whole
              transfer as if nothing existed on the remote system.
    --resume
              Existing FILE(s) at the destination that are shorter than
              their corresponding source will be resumed: the bytes missing
              will be appended. The resume does not verify that source and
              destination MD5 sums are equal. If the exact same m5copy
              command is re-run with '--resume', though, it is guaranteed
              that source and destination bytes match.

    SRC, DST: uri-like VLBI data locations. Supported formats:

    mk5://[host][:port][:dataip][/BANK|VSN]/<scan id>
        This addresses a scan on a Mark5 disk pack.

        For SRC uri the <scan id> may be a name, number or a comma-
            separated list of numbers or range of numbers: 1-10,13,14.
            The name may contain the wildcard characters '*' or '?' -
            all scan names matching the pattern will be transferred.
            For scan number ranges, the range is inclusive the last number.

        For DST uri the <scan id> will ONLY be interpreted as name;
            we cannot force the scan id number - it depends on what
            is already recorded on the target disk pack. If the name
            happens to be numeric, your scan will be called that.

        The BANK may be provided as "A" or "B" (case insensitive) but is
        optional. If nothing is specified the current active bank on the
        Mark5 will be used.

        If something is specified for BANK|VSN and it's not "A" or "B", the
        string will be interpreted as VSN. An error will happen if the given
        VSN cannot be found/switched to on the indicated Mark5.

    file://[host][:port][:dataip]/path/to/(file|dir/)
        Addresses a file or directory on disk (trailing slash means directory).

        In SRC file URIs wildcards '*' and '?' are allowed, provided you're
        running m5copy on the machine itself. Remote wildcards are NOT
        supported.

        SRC file URIs may never address a directory. DST file URIs _MUST_
        name a directory IF the source consists of multiple files/scans.

    etd://host[:port]/path/to/(file|dir/)
        If the SRC jive5ab has been compiled with support for e-transfer, it
        can send data to a remote e-transfer daemon:
           https://github.com/jive-vlbi/etransfer.git

        This URI can only be used as DST. Allowed SRCs are mk5, mk6, vbs.
        The data from the scan(s) will end up as file(s):
            host:/path/to/(file/dir/<scan>.m5a)

        Using a single scan transfer it can be renamed, otherwise the file name
        on the remote end will be <scan>.m5a

        The ":port" should only be needed if the remote e-transfer daemon is
        NOT started using the default e-transfer command port "4004"; jive5ab
        knows this default as well.

        The "-udt", "-srt", "-m MTU" "-p PORT" and "-r RATE" options are ignored with
        this destination because the protocol and port will be negotiated
        between the sending jive5ab and the receiving e-transfer daemon program
        and the sending rate is /not/ controlled from jive5ab, like with normal
        jive5ab => jive5ab transfers.

        The --skip_existing, --resume, --allow_overwrite are *specifically*
        supported; they have been built in into the e-transfer daemon protocol
        based on, well, experiences with m5copy :-)

    mk6://[host][:port]/[DISKS/][recording]
        This makes the system record data in native Mark6 format(*) on the
        indicated machine. Since jive5ab 2.6.1, "mk6://" can be used as
        source URI. In order to transfer a Mark6 recording with older
        versions of jive5ab, mount a Mark6-aware FUSE file system and use
        a "file://" source URI.

        For SRC uri, the [recording] name is not optional.

        On the Mark6 the disks are mounted by module. jive5ab does NOT
        automatically scan all Mark6 modules for recording (this is by
        design). As a result, the user must specify on which disk module (by
        slot number or MSN) should be recorded: the "DISKS/" part of the
        URI.

        DISKS is a comma-separated list of disks, ending with a slash, that
        should be recorded on. Each element in the list can be one of:

            - a Mark6 module slot: "1", "2", "3" or "4" (or sequence
              thereof, like "12")
            - built-in aliases
                "flexbuff" -> select all available FlexBuff mountpoints
                "mk6"      -> select all mounted Mark6 disk modules
            - a Mark6 module's MSN (if the eMSN file is correctly created
              on the meta data partition)
            - a shell globbing pattern, e.g.:
                /mnt/disks/1/*   (which is what "1" is shorthand for)
            - a fully qualified path:
                /path/to/here

        Examples:

        This will record on the module in slot #3 (needs Mark6 expansion
        chassis):
            m5copy SRC mk6://mark6.jive.nl/3/

        This will record on the modules identified by the MSNs, irrespective
        of in which slot they're mounted:
            m5copy SRC mk6://10.88.0.45/OAN+1234,TEST0001/

        (*) Native Mark6 format is the format version 2 as written by the
        MIT Haystack dplane software.

    vbs://[host][:port][:dataip]/[DISKS/][recording]
        Addresses a vlbi_streamer (vbs) recording on a FlexBuff.  VBS -> VBS
        transfers are an 'rsync' operation rather than a copy. Therefore
        some restrictions apply for those transfers. Since jive5ab 2.6.1
        "vbs://" recordings can also be copied to any of the other, valid,
        destinations.

        In SRC vbs URIs the recording MUST be specified and wildcard
        expansion is only allowed on the local machine.

        On DST vbs URIs, the "[:dataip]" is not supported. The DST recording
        name may only be set if the data source is 'mk5://' or 'file://'
        because in VBS -> VBS transfers the name of the recording is
        transferred implicitly on account of this essentially being an
        rsync operation.

        "DISKS/" is an optional argument for vbs recordings. When given it
        is a comma-separated list of disks, ending with a slash, that should
        be recorded on. See under "mk6://" for a full description of the
        DISKS element.

    in://[host][:port]/[amount[kMGs]]
        Addresses the I/O board in the Mark5, to which the formatter or
        DBBC is directly connected to. This is a SRC URI only!

        With this SRC you can take data directly from the telescope and save
        it somewhere: on the local Mark5 or, if the network and the disks
        on the remote system are fast enough too, on a remote system.

        'amount' is the amount of data to capture. If 'amount' is not
        specified, the transfer will run until you cancel the transfer by
        pressing ^C.

        'amount' given without unit means "number of bytes". With unit
        suffix of 'k', 'M' or 'G', the program will attempt to capture as
        close to the amount of bytes, kB, MB or GB as specified. The
        'thousands' here are binary thousands, thus powers of 1024.

        'amount' with unit 's' (for seconds) will capture data for that
        amount of seconds. Again,this is only an approximation.

        When using this SRC, it is assumed that _someone else_ has correctly
        set up the Mark5 mode and play rate or clock setting (Mark5B).

    mem://[host][:port]/[amount[kMGs]]
        Addresses the memory buffer inside jive5ab. If jive5ab is started
        with the '-b' option on the Mark5, recorded data will be mirrored in
        a memory buffer inside jive5ab. This one is also SRC only URI.

        With this SRC you can take data directly from that buffer and save
        it somewhere: on the local Mark5 or, if the network and the disks
        on the remote system are fast enough too, on a remote system.

        The explanation of the 'amount' parameter is identical to that under
        the 'in://' explanation.

        It should be pointed out that with this SRC, if there is no
        recording going on, no data will flow. You can start this transfer
        and it will start the data flow as soon as someone else turns on
        recording. However, if you specified the duration in seconds, the
        time will count from the moment of invocation, irrespective of if
        there is data flowing.

        Just to be absolutely clear about it:

        IF JIVE5AB IS NOT IN BUFFERING MODE, NO DATA WIL BE TRANSFERRED BY
        THIS TRANSFER. EVAR.

        If this statement doesn't mean anything to you but still sounds like
        you want to use this form of transport, contact the author for an
        explanation.


ALL KINDS OF IPv4 ADDRESSES

    The "host" and "port" fields in the URI's are for the CONTROL channel:
    m5copy will send the VSI/S formatted commands to this address.
     
    The "dataip" override field is only allowed in the DST uri. It is
    optional and will override the destination ip/host address (the DST
    control IP) where the data will be sent to.
    
    Typically this option is used to force data over a faster network
    between the SRC and DST machines, bypassing the CONTROL network.
    
    Note: setting the data port is done using a separate option on the
    command line.

    Defaults are:
        host        localhost/127.0.0.1
        port        {def_ctrl_port}
        dataip      {def_data_ip}


EXAMPLES

    On a Mark5, copy scan 1-10 from local disk => local file ("disk2file").
    Each scan will end up in "/data/<scanname>.m5a":

        m5copy mk5:///1-10 file:///data/

    Send those scans to an e-transfer daemon running elsewhere, resuming
    the transfer - i.e. completing all files that are not complete yet

        m5copy mk5:///1-10 etd://io13.mpifr.mpg.de/data/r1680/ --resume

    Extract scan 200 and rename it:

        m5copy mk5:///200 file:///data/scan200.m5a

    You can force the scans of a specific experiment to be read from a
    specific VSN:

        m5copy mk5:///cmva-007/ek035* file:///data/

    Or from a specific bank:

        m5copy mk5:///B/*ef* file:///data/

    Do a file server => Mark5 copy, forcing data to to a specific VSN,
    "file2net2disk". Each file will become a new scan on the disk pack with
    the name of the file with its extension removed:

        m5copy file:///data/gr* mk5://10.88.0.50/jod+017/

    Do a remote disk2file; i.e. trigger a local disk2file on a Mark5 from
    e.g. your control computer ("remote disk2file"):

        m5copy mk5://10.88.0.50/1-10 file://10.88.0.50/data/

    Push data from a specified VSN loaded in a remote Mark5 to a directory
    on a remote file server. Assume the Mark5 and file server's "control"
    IPv4 addresses are on the 10.88.0.* subnet and there is a high-speed
    data link between the Mark5 and the file server over a different IPv4
    subnet, 192.42.120.*. The file server has IPv4 addresses
    10.88.0.22 (control) and 192.42.120.110 (fat data pipe).

    Using this form of m5copy ensures the data will go over the fast
    192.42.120.* network whilst the control commands are sent over the
    normal network, "disk2net2file". The SRC jive5ab will be told to open
    the data connection to "dataip=192.42.120.110":

        m5copy mk5://10.88.0.50/ file://10.88.0.22::192.42.120.110/data/


    Copy 512MB of data directly from the I/O board to a remote file:

        m5copy in://effelsberg.ip.address/512M file://io11.mpg-bonn.de/data/

""".format(progname=sys.argv[0], def_proto=protocol, def_data_port=dataport,
           def_ctrl_port=controlport, def_mtu=mtu, def_verbose=verbose,
           def_nthread=nthread, def_allow=duplicates,
           def_data_ip=def_dataip, def_expect=xferDoneCount) )


# One-liner to split a list of things into two lists, one satisfying the predicate, the other not
partition = lambda p, l: functools.reduce(lambda y_n, x: (y_n[0]+[x], y_n[1]) if p(x) else (y_n[0], y_n[1]+[x]), l, ([], []))

######
# Utils
######


# will always resolve to IPv4 address such that
# user can mix names/ip-addresses and the system will
# still compare them equal (provided they resolve to
# the same IPv4 address, of course)
def resolve_ip(host_or_ip):
    # the socket.getaddrinfo returns a list of 5-element tuples
    # we only want the IPv4 address out of the 5th element ("(ip, port)")
    # and we default to the first returned entry for the host
    try:
        return socket.getaddrinfo(host_or_ip, 0, socket.AF_INET, socket.SOCK_STREAM)[0][4][0]
    except:
        print("Failed to resolve the following name '{0}'".format(host_or_ip))
        sys.exit( -4 )


rxBytenumOffset  = re.compile(r"^(?P<sign>[-+])?(?P<amount>[0-9]+)(?P<scale>[kMG])?$")
rxBytenumRate    = re.compile(r"^(?P<sign>\+)?(?P<amount>[0-9]+(\.[0-9]*)?|\.[0-9]+)(?P<scale>[kMG])?$")
scaleTableBinary = {'k': 1024, 'M':1024*1024, 'G': 1024*1024*1024, '':1, None:1}
scaleTableMetric = {'k': 1000, 'M':1000000, 'G': 1000000000, '':1, None:1}

def procByte(bn, tp, rxBytenum, scaleTable):
    mo = rxBytenum.match(bn)
    if not mo:
        raise RuntimeError("{0}: invalid byte number".format(bn))
    # passed the regex test, now we can do stuff
    amount = tp(mo.group('amount'))
    scale  = mo.group('scale')
    sign   = mo.group('sign')
    if scale:
        amount *= scaleTable[scale]
    return (sign if sign else '')+str(amount)

rxAbsByteNumber = re.compile("^[0-9]+$")
def isAbsoluteByteNumber(bn):
    return bn is not None and rxAbsByteNumber.match(bn)

def isRelativeToEnd(bn):
    return bn is not None and bn[0]=='-'

def isRelativeToStart(bn):
    return bn is not None and bn[0]=='+'

# Make an object out of attributes+values
def mkobj(**attrs):
    return functools.reduce( lambda acc, k_v: setattr(acc, k_v[0], k_v[1]) or acc, iteritems(attrs), \
        type('', (), {'__str__': lambda self: "{" + ": ".join(["{0}={1}".format(a, getattr(self, a)) for a in attrs]) + "}"})() )

def mkse():
    return mkobj(startByte=None, endByte=None)

# process start/end byte numbers for disk2net transfer
# in: startbyte, endbyte, alreadyhave
# out: object with two attributes
#       .scan_set = object w/ attributes .startByte, .endByte
#       .disk2net =     id.
# containing the byte number strings to pass
# in the corresponding phase of the transfer
def seByte2net(startByte, endByte, alreadyHave):
    rv = mkobj( scan_set=mkse(), disk2net=mkse() )

    ss  = rv.scan_set
    d2n = rv.disk2net
    # any byte number can be:
    #   num, -num, +num, time, -time, +time
    #
    # start byte numbers that must be given in scan_set are:
    #    -num, +num, time, -time, +time
    #
    # in disk2net only absolute byte numbers can be given,
    # apart from end byte, which may be '+num' to indicate
    # relative to start
    abStart       = isAbsoluteByteNumber(startByte)
    abEnd         = isAbsoluteByteNumber(endByte)
    endRelToStart = isRelativeToStart(endByte)

    if abStart:
        # must be given in disk2net. Must account for
        # bytes already there.
        d2n.startByte = int(startByte)

        if alreadyHave:
            d2n.startByte = d2n.startByte + alreadyHave

        # does end follow start?
        if endRelToStart:
            # we can only support numbers here, no times!
            # because we have to go through the 'disk2file' method
            try:
                eb = int(endByte)
            except ValueError:
                raise RuntimeError("Cannot have absolute byte start combined with time duration")
            # do we have to account for bytes already received?
            if alreadyHave:
                eb = eb - alreadyHave
                if eb<0:
                    raise RuntimeError("The remote file has more bytes than requested via +amount")
            # make sure it comes out as relative to start (ie leading '+')
            d2n.endByte = "+"+str( eb )


    # non-absolute byte numbers/times must be set in scan_set
    if startByte and not abStart:
        # everything going into scan set is unaffected
        # by the fact if there are bytes already there
        ss.startByte = startByte
        if endRelToStart:
            ss.endByte = endByte

    # If an endByte was given, it depends on what it was (number, time,
    # absolute or relative) to where it goes.
    # Take care: one case of endByte has already been dealt with.
    if endByte and not (abStart and endRelToStart):
        # absolute byte number can only be given in one place
        # unaffected by amount of bytes already there
        if abEnd:
            d2n.endByte = endByte
        else:
            # it's not absolute nor relative to start
            # we assume it's a time and thus it must go
            # into scan_set
            ss.endByte = endByte

    # disk2net start offset None and alreadyHave not None?
    if d2n.startByte is None and alreadyHave is not None:
        d2n.startByte = "+"+str(alreadyHave)
    return rv

# process start/end byte for disk2file / scan_set combo.
# because disk2file has a special 'resume' file-open mode,
# we don't have to deal with 'alreadyHave'
def seByte2file(startByte, endByte):
    rv = mkobj( scan_set=mkse(), disk2file=mkse() )

    ss  = rv.scan_set
    d2f = rv.disk2file
    # any byte number can be:
    #   num, -num, +num, time, -time, +time
    #
    # start byte numbers that must be given in scan_set are:
    #    -num, +num, time, -time, +time
    #
    # in disk2file only absolute byte numbers can be given,
    # apart from end byte, which may be '+num' to indicate
    # relative to start
    if startByte:
        # absolute byte numbers can only be given in disk2file
        # everything else goes into scan_set
        if isAbsoluteByteNumber(startByte):
            d2f.startByte = startByte
        else:
            ss.startByte  = startByte

    if endByte:
        # same as with startByte
        if isAbsoluteByteNumber(endByte):
            d2f.endByte   = endByte
        else:
            ss.endByte    = endByte
    return rv


def seString(bn):
    return "" if bn is None else bn

class URI(object):
    ## define a static method - the URI factory
    @staticmethod
    def makeURI(src_or_dst, media):
        if src_or_dst==uri_type.SRC:
            return SourceURI(media, src_or_dst)
        elif src_or_dst==uri_type.DST:
            return DestURI(media, src_or_dst)
        else:
            raise ValueError("Cannot create neither a source or dest URI type")

    def __init__(self, media, src_or_dst):
        self.direction   = src_or_dst
        # who to talk to
        self.controlIP   = None
        self.controlPort = None

        # will be "media_type.FILE" or "media_type.DISK" or "media_type.VBS"
        if media not in media_type:
            raise RuntimeError("Unrecognized media type '{0}'".format(media))
        self.mediaType   = media

        # contents of path will depend on
        # media type
        self.path        = None

    def get_direction(self):
        return self.direction

    def __str__(self):
        # do we have these attributes?
        haveSE  = (hasattr(self,'startByte') and hasattr(self, 'endByte'))
        # are any of these not None?
        needSE  = haveSE and (self.startByte or self.endByte)
        # then we possibly need to tag them on
        seBytes = (":"+ (self.startByte if self.startByte else "") + ":" + (self.endByte if self.endByte else "")) if needSE else ''
        return "{0}::{1} [{2}:{3}{4}] {5}{6}{7}".format(self.direction, self.mediaType, self.controlIP, self.controlPort, \
                                                (":"+(self.dataIP if self.dataIP else "<controlIP>") if hasattr(self,'dataIP') else ""), \
                                                ((self.bank+"/" if self.bank else "") if hasattr(self, 'bank') else ""), self.path, \
                                                seBytes)

    def parseStartEndByte(self, sb, eb, strict=False):
        # if any of the start/end bytes are set and we
        # do not have one of the attributes ...
        if (sb or eb) and not (hasattr(self, 'startByte') and hasattr(self, 'endByte')):
            raise RuntimeError("{0} does not support configuring start and/or end byte number".format(str(self)))

        # try to convert [kMG] to numbers, if that fails, look at strict parameter
        # wether or not it's allowed to #fail
        if sb:
            try:
                self.startByte = procByte(sb, int, rxBytenumOffset, scaleTableBinary)
            except:
                if strict:
                    raise
                # ok, pass on value unmodified
                self.startByte = sb

        if eb:
            try:
                self.endByte = procByte(eb, int, rxBytenumOffset, scaleTableBinary)
            except:
                if strict:
                    raise
                # ok, pass on value unmodified
                self.endByte = eb

class SourceURI(URI):
    def __init__(self, media, src_or_dst):
        super(SourceURI, self).__init__(media, src_or_dst)

        # Some URIs support start, end byte
        # These will be *functions* which both will be
        # passed the current start and end byte of the scan
        # being processed such they can do the appropriate offset
        # magic (eg negative numbers work from the end etc),
        # but always only on data source(s)
        self.startByte   = None
        self.endByte     = None

        if self.mediaType==media_type.DISK:
            self.bank    = None
            self.VSN     = None



class DestURI(URI):
    def __init__(self, media, src_or_dst):
        super(DestURI, self).__init__(media, src_or_dst)
        self.dataIP      = None

        if self.mediaType==media_type.DISK:
            self.bank    = None
            self.VSN     = None


rxDisk    = re.compile(r"^mk5:")
rxFile    = re.compile(r"^file:")
rxETD     = re.compile(r"^etd:")
rxVBS     = re.compile(r"^(?P<type>vbs|mk6):")
rxINorMEM = re.compile("^(?P<type>in|mem):")

## For URI parsing we must know if we're parsing source or destination
## URI's. 'src_or_dst' is an 'enum' (see below)
def parseURI(uri, src_or_dst):
    if rxDisk.match(uri):
        return parseDisk(uri, src_or_dst)
    elif rxFile.match(uri):
        return parseFile(uri, src_or_dst )
    elif rxETD.match(uri):
        return parseETD(uri, src_or_dst )
    elif rxVBS.match(uri):
        return parseVBS(uri, src_or_dst )
    elif rxINorMEM.match(uri):
        return parseINorMEM(uri, src_or_dst )
    else:
        raise ValueError("Unrecognized URI '{0}'".format(uri))


## Not loosely modelled after jive5ab's OPTARG macro, honestly .... ;-)
def OPTARG(lst, n, default=None):
    try:
        return lst[n] if len(lst[n]) else default
    except IndexError:
        return default

isVSN = re.compile(r"^[a-z]{2,6}[-\\+%][0-9]{1,5}$", re.I).match
# supported:
#  mk5://[host][:port][:dataip]/[BANK|VSN/]<scanname:scanids>[:[<start>][:<end>|+<amount>]]
# So, before the first "/" is all kind of host/ip/port crap.
# note that "[:dataip]" is only supported on source URIs
def parseDisk(uri_org, src_or_dst):
    uri = re.sub("^mk5:", "", uri_org)
    rv = URI.makeURI(src_or_dst, media_type.DISK)

    # the host/port/dataip is between the leading double slash and the third
    # slash
    mo = re.match(r"^//([^/]*)/", uri)
    if not mo:
        raise RuntimeError("{0}: invalid - does not match //.../".format(uri_org))
    hoststuff = mo.group(1)

    # now that we have matched the hoststuff out of it, we can take it out
    # of the URI
    path = re.sub(r"^//[^/]*/", "", uri)

    # any slashes remaining in the path means that a bank/vsn was passed
    slashed = path.split("/")
    if len(slashed)>2:
        raise RuntimeError("{0}: invalid - too many slashes in bank/scan part".format(uri_org))

    # the last part is always the scanid/number
    # On a source disk, we MUST have a scan name, on DST it *may* be a scan name
    b, p = (None, None)
    if len(slashed)==2:
        (b, p) = slashed
    else:
        p = path
        # 03 May 2017 - UweB mistyped "m5copy ... mk5://.../A" where he
        #               meant: "m5copy ... mk5://.../A/" to copy data to
        #               bank A.
        #               Misfortune: his data source was only one recording
        #               so the code interpreted the "/A" as meaning "copy to
        #               mark5 disk pack and name the scan 'A'". He tried a
        #               few times so ended up with:
        # ---- ---------                                -------------  -------------
        #    1 EXP_STN_A                                            0    78518334048
        #    2 EXP_STN_Aa                                 78518334048   153178665568
        #    3 EXP_STN_Ab                                153178665568   218388152320
        #    4 EXP_STN_Ac                                218388152320   293054676512
        #
        # Leading to believe that the orignal recording name was lost ...
        #
        # So: here we check if the path possibly looks like a bank label or
        # a VSN and warn/fail if it does ...
        if p.upper() in bank_type or isVSN(p):
            raise RuntimeError("It looks like you forgot to append a slash to bank label or VSN in your mk5 specification")
    # Did anyone mention start/end byte?
    p_split = p.split(':')
    rv.path = p_split[0]  # path is always the first bit

    if rv.direction==uri_type.SRC:
        if not rv.path:
            raise RuntimeError("{0}: source URI MUST have a scan name/id".format(uri_org))

    # if there's a leading part, it's the bank/vsn
    if b:
        b = b.upper()
        if not b in bank_type:
            # must be VSN then
            if hasattr(rv, 'VSN'):
                rv.VSN = b
            else:
                raise RuntimeError("{0}: media type {1} does not support setting VSN to {2}".format(uri_org, rv.mediaType, b))
        else:
            if hasattr(rv, 'bank'):
                rv.bank = b
            else:
                raise RuntimeError("{0}: media type {1} does not support setting bank to {2}".format(uri_org, rv.mediaType, b))

    # Now parse the host/port stuff
    colonized = hoststuff.split(':')

    # Length check - at most three entries
    if len(colonized)>3:
        raise RuntimeError("{0}: invalid 'host:port:dataip' part".format(uri_org))

    # Because we have the ":"'s separating the entries we only need to
    # verify if they exist at all
    rv.controlIP   = resolve_ip(OPTARG(colonized, 0, "localhost"))
    rv.controlPort = OPTARG(colonized, 1, controlport)
    if rv.controlPort:
        rv.controlPort = int(rv.controlPort)

    # Only dst-type URI's parse the data ip;
    # so we only set the value if the URI object _has_ that
    # attribute
    dataip = OPTARG(colonized, 2)
    if dataip:
        if hasattr(rv, 'dataIP'):
            rv.dataIP = resolve_ip(dataip)
        else:
            raise RuntimeError("{0} does support setting of dataip ({1})".format(uri_org, src_or_dst))

    # Save the start/end byte number parsing for last such that the URI is filled in
    rv.parseStartEndByte( OPTARG(p_split, 1), OPTARG(p_split, 2) )
    return rv


## Supported:  (the leading "file:" has already been stripped)
##  file://[host][:port][:dataip]/path/to/file[:[<start>][:<end>|+<amount>]]
# note that "[:dataip]" is only supported on source URIs
# also not that for file URI's the start/end byte numbers should really
# only be numbers. This is enforced
def parseFile(uri_org, src_or_dst):
    uri = re.sub("^file:", "", uri_org)
    rv = URI.makeURI(src_or_dst, media_type.FILE)

    # the host/port/dataip is between the leading double slash and the third
    # slash
    mo = re.match(r"//([^/]*)/", uri)
    if not mo:
        raise RuntimeError("{0}: invalid - does not match //.../".format(uri_org))
    hoststuff = mo.group(1)

    # now that we have matched the hoststuff out of it, we can take it out
    # of the URI
    p = re.sub(r"^//[^/]*", "", uri)

    # Did anyone mention start/end byte?
    p_split = p.split(':')
    rv.path = p_split[0]  # path is always the first bit - start/end is last (below)

    # On source file name we MUST have a filename
    if rv.direction==uri_type.SRC:
        if len(rv.path)<=1:
            raise RuntimeError("{0}: source URI MUST have a file/path".format(uri_org))

    # Now parse the host/port stuff
    colonized = hoststuff.split(':')

    # Length check - at most three entries
    if len(colonized)>3:
        raise RuntimeError("{0}: invalid 'host:port:dataip' part".format(uri_org))

    # Because we have the ":"'s separating the entries we only need to
    # verify if they exist at all
    rv.controlIP   = resolve_ip(OPTARG(colonized, 0, "localhost"))
    rv.controlPort = OPTARG(colonized, 1, controlport)
    if rv.controlPort:
        rv.controlPort = int(rv.controlPort)

    # Only source-type URI's parse the data ip;
    # so we only set the value if the URI object _has_ that
    # attribute
    dataip = OPTARG(colonized, 2)
    if dataip:
        if hasattr(rv, 'dataIP'):
            rv.dataIP = resolve_ip(dataip)
        else:
            raise RuntimeError("{0} does not support setting of dataip ({1})".format(uri_org, src_or_dst))

    # Save the start/end byte number parsing for last such that the URI is filled in
    rv.parseStartEndByte( OPTARG(p_split, 1), OPTARG(p_split, 2), strict=True)
    return rv

# 'vbs' is a vlbi-streamer recording on a flexbuff
#  at the moment this one does *not* support 'slicing', i.e.
#  no start/end byte specification. (not anymore true since 2.6.1)
#
#
#   vbs://[host][:port][:dataip]/recording
#
#   since 2.6.1
#     vbs://..../recording[:[start][:[end]]]
#
#   since 2.6.0:
#     [vbs|mk6]://[host][:port][:dataip]/[disks/]recording
#
#   with "disks" a "," separated list of patterns for jive5ab's built-in
#   "set_disks" command.
#     Useful shortcuts:
#          "flexbuf" => /mnt/disk[0-9]+         (FlexBuff disks)
#          "[1234]+" => /mnt/disks/<num>/[0-7]  (Mark6 disks)
#                       Can also be "MSN" for Mark6
#          "^pattern$" => hand-crafted regex
#
# note that "[:dataip]" is only supported on source URIs
def parseVBS(uri_org, src_or_dst):
    tp  = rxVBS.match(uri_org).group('type')
    uri = re.sub("^(vbs|mk6):", "", uri_org)
    rv  = URI.makeURI(src_or_dst, media_type.VBS if tp=="vbs" else media_type.MK6)

    # Was this a mk6:// ... / ?
    if tp=="mk6":
        # Set the 'mark6' attribute
        rv.mark6 = True

    # the host/port/dataip is between the leading double slash and the third
    # slash
    mo = re.match(r"//([^/]*)/", uri)
    if not mo:
        raise RuntimeError("{0}: invalid - does not match //.../".format(uri_org))
    hoststuff = mo.group(1)

    # now that we have matched the hoststuff out of it, we can take it out
    # of the URI
    rv.path = re.sub(r"^//[^/]*/", "", uri)

    # Did anyone mention start/end byte?
    p_split = rv.path.split(':')
    rv.path = p_split[0]  # path is always the first bit - start/end is last (below)

    # On source vbs we MUST have a recording name
    if rv.direction==uri_type.SRC:
        if not rv.path:
            raise RuntimeError("{0}: source URI MUST have a recording name".format(uri_org))

    # find the last slash - if any. If there are any non-zero parts left
    # they're the DISKS selection and the recording name
    lastslash = rv.path.rfind('/')
    if lastslash!=-1:
        # only set disks attribute IF there are any disks to be set
        disks   = rv.path[0:lastslash]
        if disks:
            rv.disks = disks
        rv.path = rv.path[lastslash+1:]

    # Now parse the host/port stuff
    colonized = hoststuff.split(':')

    # Length check - at most three entries
    if len(colonized)>3:
        raise RuntimeError("{0}: invalid 'host:port:dataip' part".format(uri_org))

    # Because we have the ":"'s separating the entries we only need to
    # verify if they exist at all
    rv.controlIP   = resolve_ip(OPTARG(colonized, 0, "localhost"))
    rv.controlPort = OPTARG(colonized, 1, controlport)
    if rv.controlPort:
        rv.controlPort = int(rv.controlPort)

    # Only source-type URI's parse the data ip;
    # so we only set the value if the URI object _has_ that
    # attribute
    dataip = OPTARG(colonized, 2)
    if dataip:
        if hasattr(rv, 'dataIP'):
            rv.dataIP = resolve_ip(dataip)
        else:
            raise RuntimeError("{0} does not support setting of dataip ({1})".format(uri_org, src_or_dst))

    # Save the start/end byte number parsing for last such that the URI is filled in
    rv.parseStartEndByte(OPTARG(p_split, 1), OPTARG(p_split, 2))
    return rv

def parseETD(uri_org, src_or_dst):
    uri = re.sub("^etd:", "", uri_org)
    rv  = URI.makeURI(src_or_dst, media_type.ETD)
    if rv.direction==uri_type.SRC:
        raise RuntimeError("e-transfer daemon can never be the source URI")

    # the host/port/dataip is between the leading double slash and the third
    # slash
    mo = re.match(r"//([^/]*)/", uri)
    if not mo:
        raise RuntimeError("{0}: invalid - does not match //.../".format(uri_org))
    hoststuff = mo.group(1)

    # now that we have matched the hoststuff out of it, we can take it out
    # of the URI
    rv.path = "/"+re.sub(r"^//[^/]*/", "", uri)

    # Now parse the host/port stuff
    colonized = hoststuff.split(':')

    # Length check - at most two entries
    if len(colonized)>2:
        raise RuntimeError("{0}: invalid 'host:port' part".format(uri_org))

    # Because we have the ":"'s separating the entries we only need to
    # verify if they exist at all
    rv.controlIP   = resolve_ip(OPTARG(colonized, 0, "localhost"))
    rv.controlPort = OPTARG(colonized, 1)
    if rv.controlPort:
        rv.controlPort = int(rv.controlPort)
    return rv

# 'in'  is the I/O board on Mark5A/B or C
#       this one is only supported as SRC uri
# 'mem' is reading data from the memory buffer
#       that is in jive5ab. We do not know
#       who put it there but we can read it!
#
# Because 'in' and 'mem' are basically identical in usage, we
# parse them both in one method
#
#   (in|mem)://[host][:port][:dataip]/[[0-9]+[kMGs]]
#      the optional <number>[kMGs] is the amount of bytes (kMG) or
#      seconds (s) to transfer.
#      No unit implies 'just bytes'
#      If amount is in bytes, it will be an approximation; an attempt
#      will be made to retrieve the specified amount of bytes.
#      Default is to transfer indefinitely - can be stopped using ^C
rxAmount = re.compile(r"^(?P<amount>[0-9]+)(?P<unit>[kMGs])?$")
def parseINorMEM(uri_org, src_or_dst):
    if src_or_dst==uri_type.DST:
        raise RuntimeError("{0} can only be used as SRC".format(uri_org))

    # Before removing the prefix, capture what it was!
    tp  = rxINorMEM.match(uri_org).group('type')
    uri = re.sub("^(in|mem):", "", uri_org)

    if tp=='in':
        rv  = URI.makeURI(src_or_dst, media_type.IN)
    elif tp=='mem':
        rv  = URI.makeURI(src_or_dst, media_type.MEM)

    # the host/port/dataip is between the leading double slash and the third
    # slash
    mo = re.match(r"//([^/]*)/", uri)
    if not mo:
        raise RuntimeError("{0}: invalid - does not match //.../".format(uri_org))
    hoststuff = mo.group(1)

    # now that we have matched the hoststuff out of it, we can take it out
    # of the URI
    rv.path = re.sub(r"^//[^/]*/", "", uri)

    # Was there an amount of bytes/time specified?
    # (i.e. something left after taking out the initial part of the uri)
    # Note: at this point we only _verify_ that the 'path' matches.
    #       interpretation of the string will be done in the actual
    #       reading function
    if rv.path:
        if not rxAmount.match(rv.path):
            raise RuntimeError("{0} - invalid amount of bytes/seconds specified".format(uri_org))

    # Now parse the host/port stuff
    colonized = hoststuff.split(':')

    # Length check - at most three entries
    if len(colonized)>3:
        raise RuntimeError("{0}: invalid 'host:port:dataip' part".format(uri_org))

    # Because we have the ":"'s separating the entries we only need to
    # verify if they exist at all
    rv.controlIP   = resolve_ip(OPTARG(colonized, 0, "localhost"))
    rv.controlPort = OPTARG(colonized, 1, controlport)
    if rv.controlPort:
        rv.controlPort = int(rv.controlPort)

    # Only source-type URI's parse the data ip;
    # so we only set the value if the URI object _has_ that
    # attribute
    dataip = OPTARG(colonized, 2)
    if dataip:
        if hasattr(rv, 'dataIP'):
            rv.dataIP = resolve_ip(dataip)
        else:
            raise RuntimeError("{0} does not support setting of dataip ({1})".format(uri_org, src_or_dst))
    return rv

###########################################
#              cornerturning support
###########################################


# Get nr of bits per sample out of the canonical mode
#  MKIVx_y-datarate-nchannel-bitpersample
#  VLBAx_y-datarate-nchannel-bitpersample
#  MARK5B-datarate-nchannel-bitpersample
rxMode = re.compile(r"^(((?P<mk4vlba>MKIV|VLBA)(?P<fanout1>\d)_(?P<fanout2>\d))|MARK5B|VDIFL?_\d+)-(?P<rate>\d+)-\d+-(?P<bps>\d+)$", re.I)

# Split the VDIF params into an object with attributes
#   -vdif station:framesize[:[threads][:bpsample]]
def vdif_props(v):
    return functools.reduce(lambda acc, at_fn__v: setattr(acc, at_fn__v[0][0], at_fn__v[0][1](at_fn__v[1])) or acc,
                  zip([("station", identity), ("framesize", int), ("threads", identity), ("bitspersample",int)], v.split(':')),
                  type('', (), {})())

# predefined modes => cornerturning setups
known_modes = {
        'MKIV1_2-256-8-2':  "8Ch2bit1to2_hv",
        'MKIV1_2-512-8-2':  "8Ch2bit1to2_hv",               # 32 tracks 1:2 fanout
        'MKIV1_2-512-16-2':  "32bitx2 + 8Ch2bit1to2_hv*1",    # 64 tracks 1:2 fanout
        'MKIV1_2-1024-16-2':  "32bitx2 + 8Ch2bit1to2_hv*1",    # 64 tracks 1:2 fanout
        'MKIV1_4-1024-16-2':"32bitx2 + 8Ch2bit1to4_hv",   # 64 tracks 1:4 fanout
        'MARK5B-1024-16-2': "16bitx2 + 8Ch2bit_hv*4",# 1024Mbps 16ch Mk5B
        'MARK5B-512-8-2':   "8Ch2bit_hv",          # 512Mbps  8ch  Mk5B
        'MARK5B-512-16-2':   "16bitx2 + 8Ch2bit_hv*4",# 512Mbps  16ch  Mk5B
}

do_corner   = False
mode        = None     # set from cmdline
vdif        = None     # set from cmdline
cornerturn  = None     # maybe set from cmdline

# Return list of commands + cornerturn recipe + vdif properties + output data format
# In case we do cornerturning, there is a format translation
# and as such, the output format of the data does not match
# the input format anymore

def ct_setup_commands(ct_cmd):
    # if cornerturn recipe not given, check if it is one of the known ones
    m          = mode.upper()
    ct_method  = (known_modes[m] if m in known_modes else None) if cornerturn is None else cornerturn
    if ct_method is None:
        raise RuntimeError("No cornerturning known for {0}, specify '-ct ...' to run".format(mode))
    vd_props   = vdif_props(vdif)
    if not hasattr(vd_props, 'threads'):
        vd_props.threads = "0-15"
        print("cornerturn setup: no VDIF thread selection given, defaulting to {0}".format(vd_props.threads))

    # check fanout and bits-per-sample
    mo = rxMode.match(m)
    if not mo:
        raise RuntimeError("Mode {0} is not like  <FORMAT>-<RATE>-<N_CHANNEL>-<BITSPERSAMPLE>".format(mode))
    # bits per channel is not necessarily == bits per sample; especially during fan-out
    # (with fan-out 1:2, there are twice as many bits for each sample as one would expect)
    # Mode (MarkIV|VLBA)<fanout1>_<fanout2>-....
    bps = int(mo.group('bps'))
    if mo.group('mk4vlba'):
        fo1 = int(mo.group('fanout1'))
        fo2 = int(mo.group('fanout2'))
    else:
        fo1 = fo2 = 1
    bpc = bps
    if fo2>fo1:
        bpc = bpc * (fo2 / fo1)
    # the output data format will always be legacy vdif, fully cornerturned (i.e. one channel per frame)
    oFmt = "VDIFL_{framesize}-{rate}-1-{bps}".format(framesize=vd_props.framesize, rate=mo.group('rate'), bps=bps)
    return  (
        [
            "mode={0}".format(mode),
            "{0}=bitspersample:{1}".format(ct_cmd, bps),
            "{0}=bitsperchannel:{1}".format(ct_cmd, bpc),
            "{0}=station:{1}".format(ct_cmd, vd_props.station),
            "{0}=vdifsize:{1}".format(ct_cmd, vd_props.framesize)
        ],
        ct_method, vd_props, oFmt )


###########################
# VSI-S command/reply stuff
###########################

def split_reply(reply):
    end_index = reply.rfind(';')
    if end_index != -1:
        reply = reply[:end_index]
    separator_index = reply.find('=')
    if separator_index == -1:
        separator_index = reply.find('?')
        if separator_index == -1:
            return [reply]

    return List(map(unicode.strip, [reply[0:separator_index]] + reply[separator_index+1:].split(':')))

## Facilitate communication with a Mark5
class Mark5(object):
    anyReturn = Range(0,9)

    def __init__(self, address, port, timeout=5):
        self.version_s     = None
        self.timeout       = timeout
        self.connect_point = (address, port)
        self.socket        = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        self.socket.settimeout(self.timeout)
        try:
            self.socket.connect(self.connect_point)
        except:
            raise RuntimeError("Failed to connect to {0}".format(self.connect_point))

    def get_type(self):
        return self.send_query("dts_id?")[2]

    def get_program(self):
        self.get_version_s()
        return self.version_s[2]

    def get_version(self):
        self.get_version_s()
        return self.version_s[3]

    def get_version_s(self):
        if self.version_s is None:
            # this query should only return "0", not even "1"!
            self.version_s = self.send_query("version?", [0])
        return self.version_s

    def send_query(self, query, acceptable_codes=[0,1], timeout=None):
        if queries:
            print(datetime.datetime.now(),self.connect_point,"Qry:",query)

        # decide on the timeout to use
        toInternal = self.timeout if timeout is None else timeout
        toGlobal   = toInternal if timeOut is None else max(timeOut, toInternal)
        self.socket.settimeout(toGlobal)
        self.socket.send( (query + (";" if query[-1]!=';' else "") + "\n\r").encode('ascii') )
        try:
            # drain the socket until we see either ';' or newline - both
            # signify that bit of data read from the socket contains the
            # "end-of-reply". Since we expect to have 1:1 mapping of
            # query/command to reply this _should_ work ...
            orgreply = self.socket.recv(1024).decode()
            # now that we waited for a reply succesfully and didn't get a
            # timeout it's time to not wait anymore and drain the socket as
            # much (and as fast) as we can:
            try:
                self.socket.settimeout( 0.01 )
                while True:
                    orgreply += self.socket.recv(1024).decode()
            except socket.timeout:
                # in _this_ case this is not an error, assume there isn't
                # coming anything more
                pass
            # and strip junk from whatever we got
            orgreply = orgreply.strip()
        except socket.timeout:
            # uh-oh
            raise RuntimeError("Socket timeout after {0}s waiting for reply to: {1}".format(toGlobal, query))
        except Exception as E:
            orgreply = None
        if queries:
            print(datetime.datetime.now(), self.connect_point, "Reply:", orgreply)
        reply = split_reply(orgreply) if orgreply else None
        if reply is None:
            raise RuntimeError("Communication with jive5ab broken during query '{0}'".format(query))
        if reply and not int(reply[1]) in acceptable_codes:
            raise RuntimeError("Unacceptable return code {0} from query '{1}' - {2} [acceptable: {3}]".format(int(reply[1]), query, orgreply, acceptable_codes))
        return reply

    def location(self):
        return ":".join(map(str, self.connect_point))

    ## attempt to switch to bank 'bank' on the Mark5
    ## indicated by 'ctrl', assumed to be a 'Mark5' object
    ##
    ## HV 07/Nov/2016 The Mk5 could also be in non-bank mode
    ##                Old jive5ab (pre 2.8 (official release)) would return
    ##                    !bank_info? 6 : not in bank mode ;"
    ##                    0           1   2
    ##                2.8+ will return
    ##                    !bank_info? 0 : nb ;"
    ##                    0           1   2
    ##                if in non-bank mode
    def switch_bank(self, bank):
        ## test if not, by any chance, in bank mode ...
        bank     = bank.upper()
        bankinfo = self.send_query("bank_info?", [0,6])
        if bankinfo[1]=="6" or bankinfo[2].upper()=="NB":
            raise RuntimeError("{0} Requesting bank {0}: target Mark5 not in bank mode".format(self.location(), bank))
        actbank = bankinfo[2].upper()
        if actbank!=bank:
            # issue the bank switch command
            reply = self.send_query("bank_set={0}".format(bank), [1])
            # wait for it to complete
            while True:
                time.sleep(1)
                reply = self.send_query("bank_set?", [0, 6])
                if reply[1]=="0":
                    break
            # verify it's a different bank than we started with
            if actbank==reply[2].upper():
                reply = self.send_query("error?")
                raise RuntimeError("{0} could not switch to bank {1} [{2}]".format(self.location(), bank, ":".join(reply[3:])))
        return actbank

    # Attempt to switch to the bank containing the indicated VSN
    def switch_vsn(self, vsn):
        vsn = vsn.upper()

        # query which VSNs are currently loaded
        #  0          1   2       3         4       5
        #  !bank_set? 0 : [AB-] : <vsn>|- : [BA-] : <vsn>|- ;
        # Create a mapping of VSN => bank
        #
        # HV 07/Nov/2016 The Mk5 could also be in non-bank mode.
        #                Handle that gracefully.
        #  "!bank_set? 6 : not in bank mode;"  (pre 2.8/release)
        #  "!bank_set? 0 : nb ;"               (2.8 and up)
        #   0          1   2
        #
        #   If the system is in non-bank mode we should use 'vsn?'
        #   to query which vsn is loaded and accept that if it's the
        #   one that we're looking for.
        reply = self.send_query("bank_set?", [0,6])
        if reply[1]=="6" or reply[2].upper()=="NB":
            # !vsn? 0 : <vsn> [ : <optional disk serial# mismatch and whatnots>]
            # 0     1   2
            loaded_vsn = self.send_query("vsn?", [0])
            # Note: <vsn> is typically <vsn>/<capacity>/<speed>
            loaded_vsn = loaded_vsn[2].upper().split('/')[0]
            if loaded_vsn!=vsn:
                raise RuntimeError("{0} Requested VSN {1} not loaded and system is in non-bank mode".format(self.location(), vsn))
            # ok, requested VSN is loaded, nothing to do but to return 'which bank' is active
            return "nb"

        def proc_entry(acc, idx):
            # extract [<bank>, <vsn>]
            sel = reply[idx:idx+2]
            # if bank or vsn == '-':
            #     'inactive bank' or 'no module loaded'
            if not "-" in sel:
                # Note: <vsn> is typically  <vsn>/<capacity>/<speed>
                acc[ sel[1].upper().split('/')[0] ] = sel[0].upper()
            return acc
        vsnbankmap = functools.reduce(proc_entry, [2,4], {})
        if not vsn in vsnbankmap:
            raise RuntimeError("{0} VSN {1} not found on this machine".format(self.location(), vsn))
        return self.switch_bank(vsnbankmap[vsn])

# default configuration for jive5ab for m5copy - separate it from direct
# Mark5 control class
class Jive5AB(Mark5):
    def __init__(self, address, port, timeout=5, runtime=None, bs="2M", modeless=True):
        super(Jive5AB, self).__init__(address, port, timeout)

        # do we have jive5* running on that connection?
        self.program = self.get_program()
        if not re.search("^jive5", self.program):
            raise RuntimeError("{0}:{1} is not running a version of jive5a(b(c))".format(address, port))

        # get the version of jive5ab
        self.version_num= parse_version( self.get_version() )

        # check which flavour of mark5 we have (or not)
        dts_id = self.get_type().lower()

        # Save the values of things that we're going to overwrite
        # Note: we set the ipd on both ends, even though it is
        #       only useful for the sender, and then only when UDT
        #       is used
        self.runtime    = copy.deepcopy(runtime)
        self.oldRuntime = None
        self.prevState  = {}

        # If we're going to create a new runtime there's no
        # point in saving the state anyway ....
        if self.runtime:
            # newer versions of jive5ab allow transient runtimes - they get
            # auto-cleared if the control connection goes.
            rtmode = "transient" if self.version_num>=supportsTransient else "new"

            self.oldRuntime = self.send_query("runtime?", [0])[2]
            self.send_query("runtime={0}:{1}".format(runtime, rtmode), [0])
        else:
            # Only save/restore clock_set parameter in case of Mark5B
            self.save( ["net_protocol", "mtu", "ipd", "net_port", "mode" ] + ["clock_set"] if 'mark5b' in dts_id else [] )

        if modeless:
            self.send_query("mode=none", [0])
        self.send_query("net_protocol={0:s}:{2}:{1}".format(protocol, bs, socbuf), [0])
        self.send_query("mtu={0:d}".format(mtu), [0])
        self.send_query("ipd={0}ns".format(ipd))
        self.send_query("net_port={0:d}".format(dataport), [0])

    def version(self):
        return self.version_num

    def save(self, cmdlist):
        self.prevState = dict(zip(cmdlist, map(lambda x: self.send_query(x+"?", [0]), cmdlist)))

    def restore(self):
        for (k,v) in iteritems(self.prevState):
            self.send_query(k+"="+":".join(v[2:]))
        if self.oldRuntime:
            self.send_query("runtime={0}:delete".format(self.runtime))
            self.send_query("runtime={0}".format(self.oldRuntime))

    def echo_on(self):
        # only do this when talking to jive5ab which properly
        # supports it
        if self.version_num >= supportsEcho:
            # accept 'succes' or 'no such command'
            self.send_query("echo=on", [0])

    def echo_off(self):
        # see comment under "echo_on(self)"
        if self.version_num >= supportsEcho:
            # accept 'succes' or 'no such command'
            self.send_query("echo=off", [0])

####################################################################
##
##    For many transfers it's necessary to know the format
##    of the data being transferred.
##    This code allows for automatic format detection
##    by parsing the output of "scan_check?" or "file_check?"
##
####################################################################


# method 1. "scan_set=..." followed by "scan_check?"
# method 2. "file_check?"
# method 3. "mode?"  (for when taking data from the 'scope directly)
# Input to both methods is the jive5ab we're talking to and the
# scan name (ignored for "mode?")

def scan_check(jive5ab, scan):
    # force succesful scan_set=, scan_check?
    jive5ab.send_query("scan_set={0}".format(scan.id()), [0], timeout=600)
    # !scan_check = 0 : <scan #> : <scan name> : <interesting gunk>
    # 0             1   2          3             4
    reply = jive5ab.send_query("scan_check?", [0])
    if reply[3]!=scan.name():
        raise RuntimeError("After scan_set={0}, scan_check? reports {1}".format(scan.name(), reply[3]))
    # strip all the non-interesting bits from the reply
    return reply[4:]

def file_check(jive5ab, scan):
    # !file_check? = 0 : <interesting gunk>
    # 0              1   2
    # Only return <interesting gunk> to caller
    return jive5ab.send_query("file_check ? : : {0}".format(scan.name()), [0])[2:]

def mode_check(jive5ab, scan):
    # As we're apparently taking data directly from the hardware
    # we can extract the format from the "mode?" parameter
    # We must be sure to direct our query to runtime 0; the only one
    # having the real hardware settings

    # save current runtime
    # !runtime? 0 : <current> [: <more gunk>]
    # 0         1   2
    runtime = jive5ab.send_query("runtime?", [0])[2]
    # switch to 0 and query
    jive5ab.send_query("runtime=0", [0])
    mode    = jive5ab.send_query("mode?", [0])
    # before throwing exceptions &cet, go back to original runtime
    jive5ab.send_query("runtime={0}".format(runtime), [0])

    # if we get:
    # !mode? 0 : <one string>
    # 0      1   2
    # the system was configured using 'magic mode'
    if len(mode)==3:
        return [mode[2]]

    # !mode? 0 : <data mode> : <data submode> [ : <decimation (on Mk5B)> ]
    # 0      1   2             3                  4
    # on mark5b we need clock_set? to get the track bit rate, otherwise
    # we use play_rate?
    m5b     = (mode[2]=='ext') # we don't support Mark5B modes 'tvg' and 'ramp'
    m5a     = (mode[2] in ['mark4', 'vlba'] or 'mark5a+' in mode[2]) # we don't support 5a modes 'st', 'tvg'
    if m5b:
        # !clock_set? 0 : <freq> : <src> : <genfreq>
        cs = jive5ab.send_query("clock_set?", [0])
        # should we take decimation into account? On Mark5B:
        # !mode? 0 : ext : <mask> : <decimation>
        # 0      1   2     3        4
        dcm     = int(mode[4])
        trkrate = int( float(cs[2])/dcm )
        # translate bit stream mask to #-of-tracks
        ntrk    = "{0}".format( bin(int(mode[3])).count("1") )
    elif m5a:
        # !play_rate? 0 : <track bit rate> : <track clock rate> : <clockgen freq>
        # 0           1   2
        pr      = jive5ab.send_query("play_rate?", [0])
        trkrate = int( pr[2] )
        ntrk    = mode[3]
    else:
        raise RuntimeError("The code does not support mode '{0}'".format(" ".join(mode)))

    # let's make a reply that is similar to file_check/scan_check (faking/not filling in some of the
    # fields we know the caller won't be using anyway):
    #  <data mode> : <data submode> : <start time> : <scan length> : <track data rate> : <missing bytes>
    return [mode[2], ntrk, "", "", "{0}Mbps".format(trkrate), "0"]

# method must be one of 'scan_check', 'file_check' or 'mode_check'. All methods
# do some pre-processing on the reply to make sure 'detect_mode' only
# receives the relevant bits of information.
# (the output of file_check?, scan_check? and mode? differ slightly
hw_mode_map = { 'mark4': 'MKIV1_1',
        'vlba': 'VLBA1_1',
        'ext' : 'MARK5B',
        # Mark5B format detected by Mark5B/DIM
        '-': 'MARK5B',
        # mark5b playback on Mk5A
        'mark5a+0': 'MARK5B',
        'mark5a+1': 'MARK5B',
        'mark5a+2': 'MARK5B' }

rxTrackRate = re.compile(r"^(?P<rate>\d+)(Mbps)?$")

def print_retval(func):
    def do_it(*args, **kwargs):
        rv = func(*args, **kwargs)
        print("RETURNVALUE:", rv)
        return rv
    return do_it

def detect_mode(jive5ab, scan, method):
    # get the reply from the jive5ab for the given scan using the given
    # method
    mode = method(jive5ab, scan)
    if queries:
        print("detect_mode(..,{0},..) = {1}".format(scan.name(), mode))

    # reply from scan_check/file_check/mode_check is:
    #  [<data mode> , <data submode> , <start time> , <scan length> , <track data rate> , <missing bytes> {,<vdif frame sz>}]
    #   0             1                2              3               4                   5                 6
    # or:
    #  [<magic mode>]

    # if mode only gave one word, the system is in 'magic' mode - cf.
    # W.Brisken libmk5access one-string-sets-all format
    # so we're done quickly in that case.
    # It could also be that file_check/scan_check failed to detect the format,
    # in which case it would return a single '?'
    if len(mode)==1:
        if mode[0]=='?':
            raise RuntimeError("{0}: the data format could not be deduced".format(scan))
        return mode[0]

    # first parameter typically encodes the format
    fmt  = mode[0].lower()

    # if fmt == 'st' ('straight through') we don't support that
    if fmt in ['st', 'ss', 'ramp', 'tvg' ] or 'tvg' in fmt:
        raise RuntimeError("{0}: unsupported data format {1}".format(scan, fmt))

    # ok, 2nd parameter is #-of-tracks ...
    # Mark5B/DIM scan_check? returns '-' for Mark5B data and does not return #-of-tracks
    # it should return the total recording rate though
    if fmt=='-':
        trkrate = int(rxTrackRate.match( mode[4] ).group('rate'))
        ntrk    = 1
        while trkrate>64:
            ntrk    *= 2
            trkrate /= 2
    else:
        ntrk    = int( mode[1] ) if (mode[1] and mode[1]!='?') else 1
        trkrate = int(rxTrackRate.match( mode[4] ).group('rate'))

    # hardware mark4/mark5b modes are 'mark4', 'vlba', 'ext', '-' [we don't do
    # 'tvg', 'ss', test pattern &cet], typically as returned by 'mode?'
    if fmt in hw_mode_map:
        fmt     = hw_mode_map[fmt]
        # There must be some way of figuring out fan-in/fan-out on Mk4/VLBA formats?
        # the most important information is the number of
        return "{0}-{1}-{2}-1".format(fmt, ntrk*trkrate, ntrk)

    # if we have VDIF, the only two interesting bits of information are:
    #  1. is it legacy vdif or not?
    #  2. what is the data array size?
    if 'vdif' in fmt:
        # if scan_check/file_check have detected VDIF, jive5ab 2.6.1 and up
        # append the vdif frame size to the output. Without that info we
        # cannot autodetect ...
        if len(mode)<7:
            raise RuntimeError("The source jive5ab is too old for correct VDIF frame size detection. Upgrade to {0} (or later) or specify the format manually via '-mode ...'".format( supportsResumeVersion ))
        return "VDIF{0}_{1}-{2}-{3}-1".format("L" if 'legacy' in fmt else "", int(mode[6]) - (16 if 'legacy' in fmt else 32), ntrk*trkrate, ntrk)

    if fmt=='mark5b':
        return "MARK5B-{0}-{1}-1".format(ntrk*trkrate, ntrk)

    raise RuntimeError("{0}: automatic format detection failed (was: {0})".format(" ".join(mode)))


####################################################################
##
##  The model is:
##    a Source or Dest URI is passed to a DataSource or DataSink
##    the DataSource yields Scans to be transferred
##    Depending on the actual transfer a Source and Dest XFER
##    are created such that we can easily couple different
##    sources and destinations
##
####################################################################

class Scan(object):
    # no 'constructor', the only interesting bit is the interface
    # I know that in Python we could use 'duck typing' such that
    # the different objects only need to adhere to the same interface
    # but in my book that's called inheritance :D
    def name(self):
        raise RuntimeError("name() not implemented")

    def id( self ):
        raise RuntimeError("id() not implemented")

class DiskScan(Scan):
    def __init__(self, num_name, **kwargs):
        self.scanId = num_name
        # set optianal extra attribute(s)
        self.__dict__.update( kwargs )

    def name( self ):
        return self.scanId[1]
    def id( self ):
        return self.scanId[0]

class FileScan(Scan):
    def __init__(self, name):
        self.scanId = name

    def name( self ):
        return self.scanId
    def id( self ):
        return self.scanId


#####################################################################
##
## base classes for a xfer
##
##  DataSources must allow iteration over themselves; each iteration
##    step should yield the name of a transferrable unit. So even if
##    the URI addressed only a single unit, it should iterator over
##    a list of length one.
##
##  DataSinks:
##
##    * must support computing an output name, given an input
##    name. Each data sink must be able to tell wether it allows
##    multiple names to be computed. E.g. the FileDest only allows
##    computation of multiple names IF it addresses a directory. If a
##    specific name was given "/dir/file[.ext]" then obviously it
##    cannot compute >1 name.
##    For the DiskDest this is similar; if an output scan name was
##    explicitly given, no more scan names can be computed
##
##    * must be able to tell wether they can compute multiple output
##    names such that the s/w can verify if the user has made an error
##    by specifying >1 input transferrable units and one specific output
##    name
##
##    * must be able to tell the dataIP to which the data must be sent
##
#####################################################################


class DataSource(Jive5AB):
    def __init__(self, src, runtime=None, modeless=True):
        self.source  = src
        super(DataSource, self).__init__(self.source.controlIP, self.source.controlPort, runtime=runtime, modeless=modeless)

    # must return a list of source paths
    def __iter__(self):
        raise RuntimeError("Someone forgot to implement this one")
    def __next__(self):
        raise RuntimeError("Someone forgot to implement this one")

    def cleanup(self):
        raise RuntimeError("Someone forgot to implement this one")

    def startByte(self):
        return self.source.startByte

    def endByte(self):
        return self.source.endByte

    def location(self):
        return self.source.controlIP+"::"

class DataSink(Jive5AB):
    def __init__(self, dst, runtime=None):
        self.destination = dst
        super(DataSink, self).__init__(self.destination.controlIP, self.destination.controlPort, runtime=runtime)

    # Is the DataSink configured to support >1 output names?
    def multiple_outputs(self):
        raise RuntimeError("Someone forgot to implement this one!")

    # Compute the output name of the given input
    def compute_outputname(self, input):
        raise RuntimeError("Someone forgot to implement this one!")

    def cleanup(self):
        raise RuntimeError("Someone forgot to implement this one")

    def dataIP(self):
        DST = self.destination
        return DST.dataIP if hasattr(DST, 'dataIP') and DST.dataIP is not None else DST.controlIP

    def location(self):
        return self.destination.controlIP+"::"


#########################################
##
##   Concrete derivatives of
##        the base classes
##
##########################################


#################### the sources ############################

# On m5copy cmd line user can type:
#   ... mk5:///1,9-20,foo*,*?* ...
# so handle all of that gracefully:
isScanRange = re.compile(r'^(?P<first>[0-9]+)(-(?P<last>[0-9]+))?$').match
# need to check if any of the patterns is the all-scans wildcard:
# a pattern solely made out of only '*' or '?' with number of '*' > 0
allScans    = compose(choice(operator.truth, compose(operator.methodcaller('count', '*'), operator.attrgetter('string')), const(False)),
                      re.compile(r'^[\*\?]+$').match)
Sub         = lambda rx, sub: functools.partial(re.sub, rx, sub)
# Handy string processing:
# strip leading + trailing shell-style wildcards
Strip       = compose(Sub(r'^[\*\?]+', ''), Sub(r'[\*\?]+$', ''))
# Go from string-with-shell-style-wildcards to compiled regex in one fell swoop:
# change shell-style wildcards into regex style matches and escape special chars and compile
# note: we start by escaping all special chars (this way the hyphens & plusses &cet all covered Just Fine(tm))
#       but that means that we must replace the escaped shell-style wildcards (because they'll be escaped by re.escape too)
#       and we must take care to not replace literal (i.e. pre-escaped by the user) '*'s & '?'s
Shell2Regex = compose(re.compile, Sub(r'^',r'^'), Sub(r'$', r'$'), Sub(r'((?<!\\)\\\*)+',r'.*'), Sub(r'(?<!\\)\\\?', r'.'), re.escape)

def field_updater(field, how):
    # the actual value updater: given a value returns either "how(<value>)" or the constant "<how>"
    xform_    = lambda iv: (iv[0], (choice(callable, identity, const)(how))(iv[1]))
    do_update = choice(lambda t  : isinstance(t, (int, long)),
                       lambda idx: (lambda f: f[0]==idx),
                       lambda fn : (lambda f: fn(f[1])))(field)
    return compose(Map(compose(operator.itemgetter(1), choice(do_update, xform_, identity))), enumerate)

def updater(field, how, inp):
    return compose(type(inp), field_updater(field, how))(inp)

# Given a list of DiskScan objects, count the ".name()" values and return only those whose number>1
getDupScans = compose(Map(operator.itemgetter(0)), Filter(lambda kv: kv[1]>1), iteritems,
                      Counter, Map(operator.methodcaller('name')))

## Mark5 disk pack as source
class DiskSource(DataSource):

    # we're talking to jive5ab anyway so we can use undocumented "scandir" command:
    # scandir=<n>
    # !scandir= 0 : <nscan> : <name> : <start> : <length> ;
    # 0         1   2         3        4         5
    #
    # Note: scan_set=<n> is 1-based
    #       scandir=<n>  is 0-based
    def expand_scan_pattern(self, p):
        send_query = functools.partial(DiskSource.send_query, self)
        # if it's a scan range then we know it matches <first>[-<last>]
        scanrange  = isScanRange(p)
        if scanrange:
            # remember: user input is 1-based scan numbers but we'll use scandir so
            # transform to 0-based
            first = int(scanrange.group('first')) - 1
            # transform user supplied last to 0-based,
            # add '1' such that we can use it in python range() for that one has
            # end-point not included ...
            # If no last supplied it's single scan number so we put in first as last.
            # Then the "+1" for range() will sort things out Just Fine
            last  = (int(scanrange.group('last'))-1 if scanrange.group('last') else first) + 1
            # Check sanity
            if first<0 or last>self.nScan:
                raise RuntimeError("Scan selection {0} is out of range, 1-{1} scans on disk pack".format(p, self.nScan))
            # collect all matching scaninfo
            scanrange    = xrange(first, last)
            # return list with scan_set 1-based scan numbers
            return zip(xrange(first+1, last+1), map(compose(operator.itemgetter(3), send_query, "scandir={0:d};".format), scanrange))

        # hmmmm not integer scan range so must be pattern :-(
        # scan_set=<pattern> + scan_set=next should allow us to iterate through the matching scans
        # but scan_set=<pattern> does not do wildcard/regex at all
        # It tests for "scan_name.find(pattern)", so we do something 'nifty', see below
        
        # collect all matching scans in here
        scans   = set()

        # short hand for setting scan + convert return code to int:
        # "scan_set=...;" returns error code 8 if there is no scan matching or no next scan matching
        set_scan = compose(int, operator.itemgetter(1), lambda x: send_query(x, [0,8]), "scan_set={0};".format)

        # extract tuple (scan number, scan name) from scan_set? query reply:
        #   !scan_set? <return code> : <scan number> : <scan label> : <start byte#> : <stop byte#> ;
        #   0          1               2               3              ...
        get_scan = lambda: compose(tuple, field_updater(0, int), operator.itemgetter(2, 3), send_query)("scan_set?")
        # the version of get_scan() below strips the trailing [a-z]+ (the duplicate-scan-name-avoidance-scheme
        # implemented as per "record=on" ...)
        # Use only for testing handling duplicate scan name support
        #get_scan = lambda: compose(tuple, field_updater(1, Sub(r'[a-z]+$',r'')), field_updater(0, int), operator.itemgetter(2, 3), send_query)("scan_set?")

        # so what we /can/ do is some massaging of the user's pattern
        # 2) a. strip leading/trailing wildcards + split at remaining wildcards
        #    b. for each partial pattern, find all matching scans
        #    c. collect all of those matches and uniquefy
        #    d. run them past the regex filter for exact match
        for pattern in filter(operator.truth, re.findall(r'[^\\\*\?]+', Strip(p))):
            # Must do wraparound detection for this pattern *sigh*
            # so if we see the same scan number again, we know we've cycled through all matching scans
            firstMatch = None
            while True:
                return_code = set_scan(pattern)
                if return_code == 8:
                    break
                tmpScan = get_scan()
                if tmpScan[0] == firstMatch:
                    break
                if firstMatch is None:
                    firstMatch = tmpScan[0]
                scans.add( tmpScan )
                # change pattern to 'next' to trigger search for next match
                pattern = "next"
        # Put the raw set of scans through a filter with the full pattern converted to regex matcher
        # and sort by scan number
        return sorted(filter(compose(Shell2Regex(p).match, operator.itemgetter(1)), scans), key=operator.itemgetter(0))

    def __init__(self, location):
        super(DiskSource, self).__init__(location)

        SRC  = self.source

        # Select the requested bank or VSN, if one was given.
        # Note: bank and VSN are mutually exclusive at most one
        #       of them is actually set
        if SRC.bank:
            self.switch_bank(SRC.bank)
        if SRC.VSN:
            self.switch_vsn(SRC.VSN)

        # Get the list of scans and immediately filter them
        # HV: 07/Nov/2016  Mark5 could be in non-bank mode
        #                  and dir_info refuses to work pre 2.8
        #                  dir_info?  results if system in non-bank mode:
        #                    !dir_info? 6 : not in bank mode ;  (pre 2.8)
        #                    !dir_info? 0 : <nscan> : &cet   ;  (2.8 and up)
        #                  other error code 6 replies from dir_info:
        #                    !dir_info? 6 : no active bank ;    (all versions)
        #                    0          1   2
        #     11/Jul/2018  MartinL sais: "selecting scans on long distance takes looong time!"
        #                  problem: we get the whole scan dir and filter locally
        #                  solution: use "scan_set=<pattern>" + "scan_set=next"
        #                            i.e. let remote jive5ab do the filtering
        dir_info = self.send_query("dir_info?", [0, 6])

        # no active bank implies not much use in going on
        if "active" in dir_info[2]:
            raise RuntimeError("{0} there does not seem to be an active bank".format( self.location() ))
        # Remember the number of scans; use "scandir?" if in non-bank mode on old system
        # otherwise dir_info[2] already has the info
        self.nScan = int(self.send_query("scandir?")[2]) if dir_info[1]==6 else int(dir_info[2])

        # analyse the scan(s) the user wants transferred.
        # if there is /any/ pattern in there which means "all scans" we short-circuit ...
        scanSel = List(map(unicode.strip, SRC.path.split(',')))
        if List(filter(allScans, scanSel)):
            # form the input as if the user typed it - i.e. 1-based scan numbers ...
            scanSel = ["1-{0}".format(self.nScan)]

        # Now we can expand all entries
        self.scanList  = List(map(DiskScan, functools.reduce(itertools.chain, map(functools.partial(DiskSource.expand_scan_pattern, self), scanSel), list())))

        # Check for duplicate names - if there are, either fix them or fail
        # with an error + hint as to what the user should do to fix this
        duplicateNames = getDupScans(self.scanList)
        if duplicateNames:
            # uh-oh. duplicate names!
            if not duplicates:
                raise RuntimeError("Duplicate scan names found in scan selection. " +
                                   "Re-run with '-a' flag (see help) to have m5copy " +
                                    "rename them on the output")
            # Rename scans that have duplicate names
            def renamert( diskscan ):
                (num, name) = diskscan.scanId
                if name in duplicateNames:
                    return DiskScan((num, name + uniqSuffix(num)), duplicate=True)
                return diskscan
            self.scanList = List(map(renamert, self.scanList))

    # implement the DataSource part
    def __iter__(self):
        return iter(self.scanList)

    def __len__(self):
        return len(self.scanList)

    def location(self):
        SRC = self.source
        return super(DiskSource, self).location() + (SRC.bank+"/" if SRC.bank else (SRC.VSN+"/" if SRC.VSN else ""))

    def cleanup(self):
        self.restore()


class FileSource(DataSource):
    def __init__(self, location):
        # file transfers are done in a different runtime
        super(FileSource, self).__init__(location, runtime=random_word(8))

        # we cannot retrieve the list of files remotely
        # but only locally
        SRC  = self.source
        self.pathList         = [SRC.path]
        (self.dir, self.file) = os.path.split(SRC.path)

        # do we need to do wildcard processing?
        if '*' in SRC.path or '?' in SRC.path:
            if SRC.controlIP != '127.0.0.1':
                raise RuntimeError("Unfortunately we do not support wildcards in file names on remote systems")
            # HV: 17/Mar/2017 Let's be more forgiving - use glob.glob and filter out
            #                 the ones that are actually a file
            self.pathList = filter(os.path.isfile, glob.glob(SRC.path))
        self.pathList = List(map(FileScan, sorted(self.pathList)))

    def __iter__(self):
        return iter(self.pathList)

    def __len__(self):
        return len(self.pathList)

    def location(self):
        return super(FileSource, self).location()

    def cleanup(self):
        self.restore()

# Mk6 file header layout
#    uint32_t  sync_word;              // MARK6_SG_SYNC_WORD = 0xfeed6666
#    int32_t   version;                // defines format of file
#    int32_t   block_size;             // length of blocks including header (bytes)
#    int32_t   packet_format;          // format of data packets, enumerated below
#    int32_t   packet_size;            // length of packets (bytes)
mk6_hdr_f  = '<5I'
mk6_hdr_sz = struct.calcsize(mk6_hdr_f)
# something is Mark6 format if we can succesfully read the header and find the magic stuff in there
is_mk6     = compose(choice(lambda x: len(x) == mk6_hdr_sz,
                            compose(lambda y: y[0] == 0xfeed6666 and y[1] == 2, functools.partial(struct.unpack, mk6_hdr_f)),
                            const(False)),
                     operator.methodcaller('read', mk6_hdr_sz), open)
# something is vbs if directory DIR contains file(s) named "DIR.<exactly 8 digits>":
#   /path/to/DIR/DIR.[0-9]{8} must be be not empty
is_vbs     = compose(operator.truth,
                     lambda pathrx: List(filter(compose(os.path.isfile, functools.partial(os.path.join, pathrx[0])), filter(pathrx[1], os.listdir(pathrx[0])))),
                     lambda path  : (path, re.compile(r'^'+re.escape(os.path.split(path)[1])+r'\.[0-9]{8}$').match))

class VBSSource(DataSource):

    def __init__(self, location):
        # We can support >1 vbs synchronization / FlexBuff
        # by doing it in multiple runtimes
        super(VBSSource, self).__init__(location, runtime=random_word(8))

        SRC           = self.source
        self.pathList = [SRC.path]

        # do we need to do wildcard processing?
        if '*' in SRC.path or '?' in SRC.path:
            if SRC.controlIP not in [ '127.0.0.1', 'localhost']:
                raise RuntimeError("Unfortunately we do not support wildcards in file names on remote systems")
            # Note: the parseVBS has already guaranteed that the path
            # contains no slashes.
            # HV: 17/Mar/2017 To be consistent with vbs_ls, vbs_fs and pals, we
            #                 now use fnmatch.fnmatch as well
            #     10/Jul/2018 The local wildcard stuff did not do /anything/ right
            #                 on Mark6/FlexBuff! (courtesy SimoneB)
            #                 If the user specified specific disks in the m5copy URI
            #                 we send those across before querying the actual disks.
            #                 This way the user can pass anything in that "set_disks=" 
            #                 accepts. Then we grovel manually over the actual disks 
            #                 and filter out matching recordings which have the matching 
            #                 type.
            if hasattr(SRC, 'disks'):
                self.send_query("set_disks="+":".join(map(unicode.strip, SRC.disks.split(','))))
            # set_disks?  returns:
            # set_disks? <status> : <n_disk> {: <disk>}* ;
            # 0          1          2         3 and up
            disks       = List(map(unicode.strip, self.send_query("set_disks?", [0])[3:]))
            # filter candidate recordings by the type we're looking for
            isType      = choice(os.path.isfile, is_mk6, const(False)) if hasattr(SRC,'mark6') else choice(os.path.isdir, is_vbs, const(False))
            isRecording = lambda rec: fnmatch.fnmatch(rec, SRC.path)
            self.pathList = set(functools.reduce(itertools.chain,
                                       map(lambda d: filter(compose(isType, functools.partial(os.path.join, d)),
                                                         filter(isRecording, os.listdir(d))), disks),
                                       []))
            if not self.pathList:
                raise RuntimeError("No local "+ ("mk6" if hasattr(SRC,'mark6') else "vbs")+" scans found matching "+SRC.path)
        self.pathList = List(map(FileScan, sorted(self.pathList)))

    def __iter__(self):
        return iter(self.pathList)

    def __len__(self):
        return len(self.pathList)

    def location(self):
        return super(VBSSource, self).location()

    def cleanup(self):
        self.restore()

# specialization for VBS->VBS supporting remote wildcards
class VBSPattern(DataSource):

    def __init__(self, location):
        # We can support >1 vbs synchronization / FlexBuff
        # by doing it in multiple runtimes
        super(VBSPattern, self).__init__(location, runtime=random_word(8))

        SRC           = self.source

        # assume that SRC.path is a pattern (if it is just one name that's
        # just a fixed 'pattern' that only matches itself ...)
        # Transform the pattern such that it escapes any regex special
        # character and then we replace "\*" and "\?" with ".*" and "."
        # Finally, construct the FileScan object such that downstream knows
        # what to do with it
        self.pathList = [ FileScan(sub(re.escape(SRC.path), [("\\*", ".*"), ("\\?", ".")])) ]

    def __iter__(self):
        return iter(self.pathList)

    def __len__(self):
        return len(self.pathList)

    def location(self):
        return super(VBSPattern, self).location()

    def cleanup(self):
        self.restore()

## Mark5 I/O board as data source
class InSource(DataSource):
    def __init__(self, location):
        # we do *NOT* want to run 'modeless' (i.e. "mode=none")
        super(InSource, self).__init__(location, modeless=False)

        # we must verify that the jive5ab we're talking to
        # actually HAS an I/O board
        dtsid = self.send_query("dts_id?")
        if not ("mark5" in dtsid[2].lower()):
            raise RuntimeError("Data Source is not Mark5 - does not have an I/O board")

        # we have only one 'scan'
        # let's generate a scan name that makes some sense
        # like "<date>-<mode>
        self.scanList = [ FileScan('_'.join( [timestampNow()] + self.send_query("mode?")[2:])) ]

    # implement the DataSource part
    def __iter__(self):
        return iter(self.scanList)

    def __len__(self):
        return len(self.scanList)

    def location(self):
        return super(InSource, self).location()

    def cleanup(self):
        self.restore()

## jive5ab interchainqueue as source
class MemSource(DataSource):
    def __init__(self, location):
        # we *DO* want to run 'modeless' (i.e. "mode=none")
        super(MemSource, self).__init__(location, modeless=True, runtime=random_word(9))

        # we have only one 'scan'
        # let's generate a scan name that makes some sense
        # like "<date>-<mode>
        self.scanList = [ FileScan('_'.join( ["mem", timestampNow()])) ]

    # implement the DataSource part
    def __iter__(self):
        return iter(self.scanList)

    def __len__(self):
        return len(self.scanList)

    def location(self):
        return super(MemSource, self).location()

    def cleanup(self):
        self.restore()

#################### the destinations ############################

class FileDest(DataSink):
    def __init__(self, location):
        # Do the transfer in a different runtime
        super(FileDest, self).__init__(location, runtime=random_word(8))
        
        # Split the destination into path/file
        DST                   = self.destination
        (self.dir, self.file) = os.path.split(DST.path)

    def location(self):
        return super(FileDest, self).location()

    # Is the DataSink configured to support >1 output names?
    def multiple_outputs(self):
        # Yes we are if the "self.file" part is null/empty
        return not self.file

    # Compute the output name of the given input.

    # If we were constructed with an explicit file as path, then we return
    # the path we were created with, otherwise the concatenation of self.dir
    # + the input name. Append extension ".m5a" if necessary
    def compute_outputname(self, input):
        if self.file:
            return self.destination.path
        else:
            # have to split input into path/file before appending to *our* dir
            (_dir, file) = os.path.split(input.name())
            # check if the the input has an extension. If not, append it
            (base, ext)  = os.path.splitext(file)
            if not ext:
                ext = ".m5a"
            return os.path.join(self.dir, base+ext)

    def cleanup(self):
        self.restore()

class DiskDest(DataSink):
    def __init__(self, location):
        super(DiskDest, self).__init__(location)

        DST  = self.destination

        # Select the requested bank or VSN, if one was given.
        # Note: bank and VSN are mutually exclusive at most one
        #       of them is actually set
        if DST.bank:
            self.switch_bank(DST.bank)
        if DST.VSN:
            self.switch_vsn(DST.VSN)

    def location(self):
        DST = self.destination
        return super(DiskDest, self).location() + (DST.bank+"/" if DST.bank else (DST.VSN+"/" if DST.VSN else ""))

    # Is the DataSink configured to support >1 output names?
    def multiple_outputs(self):
        # Yes we are if no specific scan (==path) was configured when we
        # were created
        return not self.destination.path

    # Compute the output name of the given input.

    # If we were constructed with an explicit path, then we return the path
    # we were created with, otherwise it will be the basename of the input
    # with extension removed.
    # This means it works for "/full/path/to/file.m5a" as well as "gr036_ef_no0001"
    def compute_outputname(self, input):
        if self.destination.path:
            return self.destination.path
        else:
            # ok, first split into (dir, file)
            (_dir, file) = os.path.split(input.name())
            # strip extension
            return os.path.splitext(file)[0]

    def cleanup(self):
        self.restore()

class VBSDest(DataSink):
    def __init__(self, location):
        # Do the transfer in a different runtime
        super(VBSDest, self).__init__(location, runtime=random_word(8))

    def location(self):
        return super(VBSDest, self).location()

    # Is the DataSink configured to support >1 output names?
    def multiple_outputs(self):
        # Yes we are if no specific scan (==path) was configured when we
        # were created OR if the path was '/dev/null'!
        return not self.destination.path or self.destination.path=='/dev/null'

    # Compute the output name of the given input.

    # If we were constructed with an explicit path, then we return the path
    # we were created with, otherwise it will be the basename of the input
    # with extension removed.
    # This means it works for "/full/path/to/file.m5a" as well as "gr036_ef_no0001"
    def compute_outputname(self, input):
        if self.destination.path:
            return self.destination.path
        else:
            # ok, first split into (dir, file)
            (_dir, file) = os.path.split(input.name())
            # strip extension
            return os.path.splitext(file)[0]

    def cleanup(self):
        self.restore()

# We need to pretend to be a DataSink but we're not a jive5ab
# so we do not derive from DataSink (which derives from Jive5AB)
class ETDDest:
    def __init__(self, location):
        # Construct
        self.destination = location
        # Split the destination into path/file
        (self.dir, self.file) = os.path.split(self.destination.path)

    # We must allow this one to be called
    def dataIP(self):
        DST  = self.destination
        ip   = DST.dataIP if hasattr(DST, 'dataIP') and getattr(DST,'dataIP') is not None else DST.controlIP
        port = ("@{0}".format if DST.controlPort is not None else "".format)(DST.controlPort)
        return ip+port

    def location(self):
        return self.destination.controlIP+"::"

    # Is the DataSink configured to support >1 output names?
    def multiple_outputs(self):
        # Yes we are if the "self.file" part is null/empty
        return not self.file

    # Compute the output name of the given input.

    # If we were constructed with an explicit file as path, then we return
    # the path we were created with, otherwise the concatenation of self.dir
    # + the input name. Append extension ".m5a" if necessary
    def compute_outputname(self, input):
        print("ETDDest: computing output file name based on input '{0}'".format(input))
        if self.file:
            print(" => single destination file: '{0}'".format(self.destination.path))
            return self.destination.path
        else:
            # have to split input into path/file before appending to *our* dir
            (_dir, file) = os.path.split(input.name())
            # check if the the input has an extension. If not, append it
            (base, ext)  = os.path.splitext(file)
            print(" => input.name()='{0}' DIR='{1}' base='{2}' ext='{3}'".format(file, _dir, base, ext))
            if not ext:
                ext = ".m5a"
            print("    rv='{0}'".format( os.path.join(self.dir, base+ext) ))
            return os.path.join(self.dir, base+ext)

    # for the e-transfer fake destination these have no meaning
    def echo_on(self):
        pass
    def echo_off(self):
        pass

    def cleanup(self):
        pass


#####################################################################################
##
##
##                  The actual transfers
##
##
#####################################################################################


class SourceXFER(object):
    # interface for source xfers
    def __init__(self, source):
        self.DataSource = source

    # start transferring data from scan 'scan' to the destination 'dataip'
    def start(self, scan, dataip, **kwargs):
        raise RuntimeError("Someone forgot to implement SourceXFER::start()")

    # In case the source did something to the data, sending out a different
    # flavour than taking in, we must be able to tell what it is outputting
    def outputFormat(self, *args):
        raise RuntimeError("Someone forgot to implement SourceXFER::outputFormat()")

    # return tuple with (start, current, end) if xfer still running,
    # None if transfer is finished
    def progress(self):
        raise RuntimeError("Someone forgot to implement SourceXFER::progress()")

    # must be cancellable
    def cancel(self):
        raise RuntimeError("Someone forgot to implement SourceXFER::cancel()")

class DestXFER(object):
    def __init__(self, sink):
        self.DataSink = sink

    # open output for accepting output into 'output'
    def open(self, output):
        raise RuntimeError("Someone forgot to implement DestXFER::open()")

    # we must be able to take in a different format than was origianally
    # read - a format translation may have taken place
    def setInputFormat(self, fmt):
        raise RuntimeError("Someone forgot to implement DestXFER::setInputFormat()")

    # return received byte count. Typically the transfer will
    # wait until this number has stabilized, so be sure to return
    # the same number if the transfer is inactive or has finished
    # (in case you can tell)
    def rcv_bytecount(self):
        raise RuntimeError("Someone forgot to implement DestXFER::rcv_bytecount()")

    # must be cancellable
    def cancel(self):
        raise RuntimeError("Someone forgot to implement DestXFER::cancel()")

    # we force every destination xfer to indicate wether or not they
    # need to know the data format
    def needFormat(self):
        raise RuntimeError("Someone forgot to implement DestXFER::needFormat()")


class EXFER(SourceXFER):
    # interface for source e-transfer xfers
    def __init__(self, source):
        super(EXFER, self).__init__( source )
        # check that the jive5ab we're talking to
        # actually was compiled with etransfer support:
        # jive5ab < 3.0.0:
        # !version? 0 : <program> : <version> : <32/64bit> : <dev/release> : <build host>:<date>:<time> : <ssapi> ;
        # 0         1   2           3           4            5               6            7      8        9
        # jive5ab >= 3.0.0:
        # !version? 0 : <program> : <version> : <32/64bit> : <dev/release> : <build host>:<date>:<time> : <ssapi> : <etransfer>;
        # 0         1   2           3           4            5               6            7      8        9         10
        #
        #  <etransfer> is either empty or "/path/to/etransfer/code"
        #       the -DETRANSFER_ROOT=/path/to/etransfer/code
        #     option to cmake for jive5ab >= 3.0.0, indicating to compile in support for etransfer
        version_s = self.DataSource.get_version_s()
        if len(version_s)<=10:
            raise RuntimeError("The target jive5ab is too old for e-transfer support")
        if not version_s[10]:
            raise RuntimeError("The target jive5ab was not built with e-transfer support")

####### Actual concrete transfers

# A disk2file is both ... we must introduce a class variable
# to let the destination part and source path communicate with
# each other
class disk2file(SourceXFER, DestXFER):
    outputFileName = None

    def __init__(self, src_or_dst):
        # look at what flavour we were initialized with to decide
        # which of our base classes should be initialized
        if isinstance(src_or_dst, DataSource):
            self.isSource = True
            SourceXFER.__init__(self, src_or_dst)
        else:
            self.isSource = False
            DestXFER.__init__(self, src_or_dst)

    #### Both types (SourceXFER and DestXFER) should be
    #### cancellable
    def cancel(self):
        if self.isSource:
            self.DataSource.send_query("reset=abort", Mark5.anyReturn)
        else:
            disk2file.outputFileName = None

    #### This is the SourceXFER part of the transfer
    def outputFormat(self, *args):
        # no need to detect the data format; disk2file is local
        return None

    def start(self, scan, dataip, **kwargs):
        # shorthand to the control interface
        CTRL = self.DataSource

        # complain if resume is requested but can't be honoured
        if doResume and CTRL.version()<supportsResume:
            loc = re.sub(":", "", CTRL.location())
            raise RuntimeError("Resume requested but the jive5ab at {0} is too old (<{1})".format( loc, supportsResumeVersion ))

        # disk2file transfer is always coming from a DiskSource
        # (in case it isn't this is an error) so the "scanIds" that
        # are passed into us are really tuples, "(scan number, scan name)"
        (scanNum, scanName) = (scan.id(), scan.name())

        # resuming disk2file is handled differently from disk2net+net2*
        # must be a special mode, see below.
        se = seByte2file(CTRL.startByte(), CTRL.endByte())

        # Attempt to set the correct scan and verify it did set.
        CTRL.send_query("scan_set={0}:{1}:{2}".format(scanNum, seString(se.scan_set.startByte),
                                                      seString(se.scan_set.endByte)), [0])
        reply = CTRL.send_query("scan_set?", [0])
        # If the current disk scan was marked as duplicate, it means
        # that some unique suffix has been appended. We must strip
        # that name to do our consistency checking
        if hasattr(scan, 'duplicate'):
            suffix = uniqSuffix(scanNum)
            if scanName.endswith(suffix):
                # Ok, modify scan name
                # Find the right-most uniqSuffix(). Suppose that by chance
                # the scan with name "name.scan.2" would end up in scan
                # postions #1 and  #2 (duplicated) on the disk pack.
                # then the 2nd uniquefied scan name would be:
                #    "name.scan.2.scan.2"
                # if we then do string.sub(".scan.2", "") it would replace
                # *both* instances instead of only the last one
                # making our test for the scan's existence on the disk pack
                # fail!
                sidx = scanName.rfind(suffix)
                if sidx<0:
                    raise RuntimeError("Could not find unique suffix whilst it should be there?!")
                scanName = scanName[0:sidx]
            else:
                raise RuntimeError("Scan #{0} ({1}) was marked as duplicate but does not end with expected suffix '{2}'".format(
                                   scanNum, scanName, suffix))
        if not (int(reply[2])==scanNum and reply[3]==scanName):
            raise RuntimeError("Scan #{0} ({1}) is not that anymore, it is now #{2} ({3})".format(
                                 scanNum, scanName, int(reply[2]), reply[3]))
        
        CTRL.send_query("disk2file={0}:{1}:{2}:{3}".format( disk2file.outputFileName,
                seString(se.disk2file.startByte), seString(se.disk2file.endByte),
                'w' if (disk2file.outputFileName=="/dev/null" or allowOverwrite) else ('resume' if doResume else 'n')), [1])

    def progress(self):
        r = self.DataSource.send_query("disk2file?")
        return None if r[2]=="inactive" else (int(r[5]), int(r[4]), int(r[6]))

    #### This is the DestXFER part of the interface
    
    # The "open()" method in this local xfer stores the output file name
    def open(self, output):
        disk2file.outputFileName = output

    def setInputFormat(self, fmt):
        pass

    def rcv_bytecount(self):
        return 0

    # no need to detect the data format; disk2file is local
    def needFormat(self):
        return False

# This is the Mk5 style disk2file but then on FlexBuff/Mark6
class disk2file_vbs(SourceXFER, DestXFER):
    outputFileName = None

    def __init__(self, src_or_dst):
        # look at what flavour we were initialized with to decide
        # which of our base classes should be initialized
        if isinstance(src_or_dst, DataSource):
            self.isSource = True
            SourceXFER.__init__(self, src_or_dst)
        else:
            self.isSource = False
            DestXFER.__init__(self, src_or_dst)

    #### Both types (SourceXFER and DestXFER) should be
    #### cancellable
    def cancel(self):
        if self.isSource:
            self.DataSource.send_query("reset=abort", Mark5.anyReturn)
        else:
            disk2file.outputFileName = None

    #### This is the SourceXFER part of the transfer
    def outputFormat(self, *args):
        # no need to determine data format, disk2file(for vbs) is a local transfer
        return None

    def start(self, scan, dataip, **kwargs):
        # shorthand to the control interface
        CTRL  = self.DataSource
        mark6 = hasattr(CTRL.source, 'mark6')
        disks = hasattr(CTRL.source, 'disks')

        # disk2file for FlexBuff/Mark6 only appeared in 2.6.1
        loc = re.sub(":", "", CTRL.location())
        if CTRL.version()<supportsResume:
            raise RuntimeError("Remote jive5ab at {0} [{1}] does not support FlexBuff/Mark6 disk2file, need >={2}".format(
                    loc, CTRL.get_version(), supportsResumeVersion ))
        
        if doResume and CTRL.version()<supportsResume:
            raise RuntimeError("Resume requested but the jive5ab at {0} is too old (<{1})".format( loc, supportsResumeVersion ))

        supports6 = (CTRL.version()>=supportsMk6)

        # better be talking to a version of jive5ab who speaks '6 or
        # supports selecting of disks, in case either is needed
        if mark6 and not supports6:
            raise RuntimeError("Remote jive5ab [{0}] does not support Mark6, need >=2.6.0".format( CTRL.get_version() ))
        if disks and not supports6:
            raise RuntimeError("Remote jive5ab [{0}] does not support selecting disks/MSNs, need >=2.6.0".format( CTRL.get_version() ))

        # resuming disk2file is handled differently from disk2net+net2*
        # must be a special mode, see below.
        # First parse the start/end byte and put them in scan_set or disk2file
        se = seByte2file(CTRL.startByte(), CTRL.endByte())

        # before setting scan, we must set the disks, if the user gave any
        if disks:
            dsk    = CTRL.source.disks.replace(",", ":")
            reply  = CTRL.send_query("set_disks="+dsk, [0])
        
        # Always set the recording format
        CTRL.send_query("record=mk6:{0}".format(1 if mark6 else 0))

        # Attempt to set the correct scan
        CTRL.send_query("scan_set={0}:{1}:{2}".format(scan.id(), seString(se.scan_set.startByte),
                                                        seString(se.scan_set.endByte)),
                                                        [0], timeout=600)

        CTRL.send_query("disk2file={0}:{1}:{2}:{3}".format( disk2file.outputFileName,
                seString(se.disk2file.startByte), seString(se.disk2file.endByte),
                'w' if (disk2file.outputFileName=="/dev/null" or allowOverwrite) else ('resume' if doResume else 'n')),
                [1], timeout=100,
                )

    def progress(self):
        r = self.DataSource.send_query("disk2file?", timeout=100)
        return None if r[2]=="inactive" else (int(r[5]), int(r[4]), int(r[6]))

    #### This is the DestXFER part of the interface
    
    # The "open()" method in this local xfer stores the output file name
    def open(self, output):
        disk2file.outputFileName = output

    def setInputFormat(self, fmt):
        pass

    def rcv_bytecount(self):
        return 0

    # no need to detect the data format; disk2file is local
    def needFormat(self):
        return False

# A disk2etransfer is both ...
class disk2etd(EXFER, DestXFER):
    # we must introduce class variables
    # to let the destination part and source path communicate with
    # each other
    outputFileName    = None

    def __init__(self, src_or_dst):
        # look at what flavour we were initialized with to decide
        # which of our base classes should be initialized
        if isinstance(src_or_dst, DataSource):
            self.isSource = True
            EXFER.__init__(self, src_or_dst)
        # don't check for "isinstance(src_or_dst, DataSource) because the
        # ETDDest is not derived from Data{Source|Sink}
        else:
            self.isSource = False
            DestXFER.__init__(self, src_or_dst)

    #### Both types (SourceXFER and DestXFER) should be
    #### cancellable
    def cancel(self):
        if self.isSource:
            self.DataSource.send_query("reset=abort", Mark5.anyReturn)
        else:
            disk2etd.outputFileName    = None
            disk2etd.etransferLocation = None

    #### This is the SourceXFER part of the transfer
    def outputFormat(self, *args):
        # no need to detect the data format; disk2transfer just transfers bytes
        return None

    def start(self, scan, dataip, **kwargs):
        # shorthand to the control interface
        CTRL = self.DataSource

        # disk2etransfer source is always DiskSource
        # (in case it isn't this is an error) so the "scanIds" that
        # are passed into us are really tuples, "(scan number, scan name)"
        (scanNum, scanName) = (scan.id(), scan.name())

        # must be a special mode, see below.
        se = seByte2file(CTRL.startByte(), CTRL.endByte())

        # Attempt to set the correct scan and verify it did set.
        CTRL.send_query("scan_set={0}:{1}:{2}".format(scanNum, seString(se.scan_set.startByte),
                                                      seString(se.scan_set.endByte)), [0])
        reply = CTRL.send_query("scan_set?", [0])
        # If the current disk scan was marked as duplicate, it means
        # that some unique suffix has been appended. We must strip
        # that name to do our consistency checking
        if hasattr(scan, 'duplicate'):
            suffix = uniqSuffix(scanNum)
            if scanName.endswith(suffix):
                # Ok, modify scan name
                # Find the right-most uniqSuffix(). Suppose that by chance
                # the scan with name "name.scan.2" would end up in scan
                # postions #1 and  #2 (duplicated) on the disk pack.
                # then the 2nd uniquefied scan name would be:
                #    "name.scan.2.scan.2"
                # if we then do string.sub(".scan.2", "") it would replace
                # *both* instances instead of only the last one
                # making our test for the scan's existence on the disk pack
                # fail!
                sidx = scanName.rfind(suffix)
                if sidx<0:
                    raise RuntimeError("Could not find unique suffix whilst it should be there?!")
                scanName = scanName[0:sidx]
            else:
                raise RuntimeError("Scan #{0} ({1}) was marked as duplicate but does not end with expected suffix '{2}'".format(
                                   scanNum, scanName, suffix))
        if not (int(reply[2])==scanNum and reply[3]==scanName):
            raise RuntimeError("Scan #{0} ({1}) is not that anymore, it is now #{2} ({3})".format(
                                 scanNum, scanName, int(reply[2]), reply[3]))

        # before starting, we must crank up the the net_protocol a bit, specifically the I/O ("workbuf") size
        CTRL.send_query("net_protocol=::32M:8;", [0])

        # disk2etransfer = host [@port] : destination [ : mode ]
        # will return:
        # !disk2etransfer = 1; // transfer started
        #  ...            = 0 : <reason> ;
        #  where reason tells "destination complete or larger than source"
        #                     "remote file already exists and SkipExisting == true"
        r = CTRL.send_query("disk2etransfer={0}:{1}:{2};".format(
                dataip, disk2etd.outputFileName,
                'allowoverwrite' if (disk2etd.outputFileName=="/dev/null" or allowOverwrite) else
                 ('resume' if doResume else ('skipexisting' if ignoreExisting else 'new'))), [0,1], timeout=100)
        if int(r[1])==0:
            raise IgnoreFile

    def progress(self):
        r = self.DataSource.send_query("disk2etransfer?")
        return None if r[2]=="inactive" else (int(r[5]), int(r[4]), int(r[6]))

    #### This is the DestXFER part of the interface
    
    # The "open()" method in this local xfer stores the output file name
    def open(self, output):
        disk2etd.outputFileName    = output

    def setInputFormat(self, fmt):
        pass

    def rcv_bytecount(self):
        return 0

    # no need to detect the data format; disk2etransfer just copies bytes
    def needFormat(self):
        return False

# This is the Mk5 style disk2etransfer but then on FlexBuff/Mark6
class disk2etd_vbs(EXFER, DestXFER):
    # we must introduce class variables
    # to let the destination part and source path communicate with
    # each other
    outputFileName    = None

    def __init__(self, src_or_dst):
        # look at what flavour we were initialized with to decide
        # which of our base classes should be initialized
        if isinstance(src_or_dst, DataSource):
            self.isSource = True
            EXFER.__init__(self, src_or_dst)
        # don't check for "isinstance(src_or_dst, DataSource) because the
        # ETDDest is not derived from Data{Source|Sink}
        else:
            self.isSource = False
            DestXFER.__init__(self, src_or_dst)

    #### Both types (SourceXFER and DestXFER) should be
    #### cancellable
    def cancel(self):
        if self.isSource:
            self.DataSource.send_query("reset=abort", Mark5.anyReturn)
        else:
            disk2etd_vbs.outputFileName    = None
            disk2etd_vbs.etransferLocation = None

    #### This is the SourceXFER part of the transfer
    def outputFormat(self, *args):
        # no need to detect the data format; disk2transfer just transfers bytes
        return None

    def start(self, scan, dataip, **kwargs):
        # shorthand to the control interface
        CTRL  = self.DataSource
        mark6 = hasattr(CTRL.source, 'mark6')
        disks = hasattr(CTRL.source, 'disks')

        # don't have to check for version(s) here since
        # the c'tor already checks if the jive5ab is compiled
        # with support for e-transfer (which immediately implies
        # there is support for FlexBuff/Mark6)

        # resuming disk2file is handled differently from disk2net+net2*
        # must be a special mode, see below.
        # First parse the start/end byte and put them in scan_set or disk2file
        se = seByte2file(CTRL.startByte(), CTRL.endByte())

        # before setting scan, we must set the disks, if the user gave any
        if disks:
            dsk    = CTRL.source.disks.replace(",", ":")
            reply  = CTRL.send_query("set_disks="+dsk, [0])
        
        # Always set the recording format
        CTRL.send_query("record=mk6:{0}".format(1 if mark6 else 0))

        # Attempt to set the correct scan
        CTRL.send_query("scan_set={0}:{1}:{2}".format(scan.id(), seString(se.scan_set.startByte),
                                                        seString(se.scan_set.endByte)),
                                                        [0], timeout=600)
        # before starting, we must crank up the the net_protocol a bit, specifically the I/O ("workbuf") size
        CTRL.send_query("net_protocol=::32M:8;", [0])

        # disk2etransfer = host [@port] : destination [ : mode ]
        # will return:
        # !disk2etransfer = 1; // transfer started
        #  ...            = 0 : <reason> ;
        #  where reason tells "destination complete or larger than source"
        #                     "remote file already exists and SkipExisting == true"
        r = CTRL.send_query("disk2etransfer={0}:{1}:{2};".format(
                dataip, disk2etd_vbs.outputFileName,
                'allowoverwrite' if (disk2etd_vbs.outputFileName=="/dev/null" or allowOverwrite) else
                 ('resume' if doResume else ('skipexisting' if ignoreExisting else 'new'))), [0,1,4], timeout=100)
        if int(r[1])==0:
            raise IgnoreFile

    def progress(self):
        r = self.DataSource.send_query("disk2etransfer?")
        return None if r[2]=="inactive" else (int(r[5]), int(r[4]), int(r[6]))

    #### This is the DestXFER part of the interface
    
    # The "open()" method in this local xfer stores the output file name
    def open(self, output):
        disk2etd_vbs.outputFileName    = output

    def setInputFormat(self, fmt):
        pass

    def rcv_bytecount(self):
        return 0

    # no need to detect the data format; disk2etransfer just copies bytes
    def needFormat(self):
        return False

# file2disk is, like disk2file, both
class file2disk(SourceXFER, DestXFER):
    outputScanName = None
    inputRuntime   = None

    def __init__(self, src_or_dst):
        # look at what flavour we were initialized with to decide
        # which of our base classes should be initialized
        if isinstance(src_or_dst, DataSource):
            self.isSource = True
            SourceXFER.__init__(self, src_or_dst)
            # we must change from arbitrary runtime to
            # runtime
            r = self.DataSource.send_query("runtime?", [0])
            file2disk.inputRuntime = r[2]
            self.DataSource.send_query("runtime=0", [0])
        else:
            self.isSource = False
            DestXFER.__init__(self, src_or_dst)

    #### Both types (SourceXFER and DestXFER) should be
    #### cancellable
    def cancel(self):
        if self.isSource:
            self.DataSource.send_query("reset=abort", Mark5.anyReturn)
            self.DataSource.send_query("runtime={0}".format(file2disk.inputRuntime), [0])
            file2disk.inputRuntime = None
        else:
            file2disk.outputFileName = None

    #### This is the SourceXFER part of the transfer
    def outputFormat(self, *args):
        # no need to determine data format for local transfer
        return None

    def start(self, scan, dataip, **kwargs):
        CTRL = self.DataSource
        startByte = CTRL.startByte()
        endByte   = CTRL.endByte()
        CTRL.send_query("file2disk={0}:{1}:{2}:{3}".format(scan.name(), \
                (startByte if startByte else ""), (endByte if endByte else ""), \
                            file2disk.outputScanName), [1])

    def progress(self):
        r = self.DataSource.send_query("file2disk?")
        return None if r[2]=="inactive" else (int(r[5]), int(r[4]), int(r[6]))

    #### This is the DestXFER part of the interface

    # The "open()" method in this local xfer creates the
    # function that will run the actual command, apart from
    # two arguments the ".start()" will supply - the input
    # file name and the actual control interface
    def open(self, outputScanName):
        file2disk.outputScanName = outputScanName

    def setOutputFormat(self, fmt):
        pass

    def rcv_bytecount(self):
        return 0

    # no need to detect the data format; disk2file is local
    def needFormat(self):
        return False

#### Local cornerturn operations
class spid2file(SourceXFER, DestXFER):
    outputFileName = None

    def __init__(self, src_or_dst):
        # look at what flavour we were initialized with to decide
        # which of our base classes should be initialized
        if isinstance(src_or_dst, DataSource):
            self.isSource = True
            SourceXFER.__init__(self, src_or_dst)

            # Analyze the cornerturning setup. In this case, because there is no
            # receiver, we can forget about the output format
            (self.ct_setup, self.ct_recipe, self.vdif_props, dummy) = ct_setup_commands("spid2file")
            # We can already program the VDIF setup
            consume(map(lambda cmd: self.DataSource.send_query(cmd, [0]), self.ct_setup))
        else:
            self.isSource = False
            DestXFER.__init__(self, src_or_dst)

    #### Both types (SourceXFER and DestXFER) should be
    #### cancellable
    def cancel(self):
        if self.isSource:
            self.DataSource.send_query("spid2file=disconnect", Mark5.anyReturn)
        else:
            spid2file.outputFileName = None

    #### This is the SourceXFER part of the transfer

    # For cornerturning, we cannot ignore the data format
    def outputFormat(self, *args):
        return None

    def start(self, scan, dataip, **kwargs):
        # shorthand to the control interface
        CTRL = self.DataSource

        # disk2file transfer is always coming from a DiskSource
        # (in case it isn't this is an error) so the "scanIds" that
        # are passed into us are really tuples, "(scan number, scan name)"
        (scanNum, scanName) = (scan.id(), scan.name())

        # This transfer cannot be resumed. Complain if resume would
        # actually be required. Silently ignore in case it wouldn't be
        # needed anyway
        alreadyHave = kwargs.get("haveBytes", None)

        if doResume and alreadyHave:
            raise RuntimeError("Resume requested and needed, but this transfer cannot be resumed")

        # process the start/end byte and in which phase of the
        # scan_set/spid2file they'd belong
        se  = seByte2file(CTRL.startByte(), CTRL.endByte())

        CTRL.send_query("scan_set={0:d}:{1}:{2}".format(scanNum), seString(se.scan_set.startByte),
                        seString(se.scan_set.endByte), [0], timeout=600)

        reply = CTRL.send_query("scan_set?", [0])
        # If the current disk scan was marked as duplicate, it means
        # that some unique suffix has been appended. We must strip
        # that name to do our consistency checking
        if hasattr(scan, 'duplicate'):
            suffix = uniqSuffix(scanNum)
            if scanName.endswith(suffix):
                # Ok, modify scan name
                # Find the right-most uniqSuffix(). Suppose that by chance
                # the scan with name "name.scan.2" would end up in scan
                # postions #1 and  #2 (duplicated) on the disk pack.
                # then the 2nd uniquefied scan name would be:
                #    "name.scan.2.scan.2"
                # if we then do string.sub(".scan.2", "") it would replace
                # *both* instances instead of only the last one
                # making our test for the scan's existence on the disk pack
                # fail!
                sidx = scanName.rfind(suffix)
                if sidx<0:
                    raise RuntimeError("Could not find unique suffix whilst it should be there?!")
                scanName = scanName[0:sidx]
            else:
                raise RuntimeError("Scan #{0} ({1}) was marked as duplicate but does not end with expected suffix '{2}'".format(
                                   scanNum, scanName, suffix))
        if not (int(reply[2])==scanNum and reply[3]==scanName):
            raise RuntimeError("Scan #{0} ({1}) is not that anymore, it is now #{2} ({3})".format(
                                 scanNum, scanName, int(reply[2]), reply[3]))
        
        # Scan is selected, only thing left is to turn the whole thing on
        CTRL.send_query("spid2file=connect:{0}:{1}={2},{3}".format(
                                    self.ct_recipe, self.vdif_props.threads,
                                    spid2file.outputFileName,
                                    'w' if (spid2file.outputFileName=="/dev/null" or allowOverwrite) else 'n'
                                    ), [0])
        CTRL.send_query("spid2file=on:{0}:{1}".format(seString(se.disk2file.startByte),
                        seString(se.disk2file.endByte)), [0])

    def progress(self):
        r = self.DataSource.send_query("spid2file?")
        #  !spid2file? 0 : active : <start> : <current> : <end>
        #  0           1   2        3         4           5
        # spid2file never terminates automatically so we'll have to
        # go by the numbers ourselves
        (c, s, e) = (int(r[4]), int(r[3]), int(r[5])) if r[2]=="active" else (0, 0, 0)
        return None if c>=e else (c, s, e)

    #### This is the DestXFER part of the interface
    
    # The "open()" method in this local xfer stores the output file name
    def open(self, output):
        spid2file.outputFileName = output

    def setInputFormat(self, fmt):
        pass

    def rcv_bytecount(self):
        return 0

    # local cornerturning operation doesn't need a format
    def needFormat(self):
        return False


class spif2file(SourceXFER, DestXFER):
    outputFileName = None

    def __init__(self, src_or_dst):
        # look at what flavour we were initialized with to decide
        # which of our base classes should be initialized
        if isinstance(src_or_dst, DataSource):
            self.isSource = True
            SourceXFER.__init__(self, src_or_dst)

            # Analyze the cornerturning setup, forget about the output format;
            # we don't have to set it because there is no receiving jive5ab
            (self.ct_setup, self.ct_recipe, self.vdif_props, dummy) = ct_setup_commands("spif2file")
            # We can already program the VDIF setup
            consume(map(lambda cmd: self.DataSource.send_query(cmd, [0]), self.ct_setup))
        else:
            self.isSource = False
            DestXFER.__init__(self, src_or_dst)

    #### Both types (SourceXFER and DestXFER) should be
    #### cancellable
    def cancel(self):
        if self.isSource:
            self.DataSource.send_query("spif2file=disconnect", Mark5.anyReturn)
        else:
            spid2file.outputFileName = None

    #### This is the SourceXFER part of the transfer
    # note: for a local format translation, we can still ignore the output format
    def outputFormat(self, *args):
        return None

    def start(self, scan, dataip, **kwargs):
        # shorthand to the control interface
        CTRL = self.DataSource

        # if the remote end indicates they already have some
        # bytes, we don't have to start from the beginning
        # remember to deal with None as possible value passed in for
        # 'haveBytes'
        startByte   = CTRL.startByte()
        endByte     = CTRL.endByte()

        # Scan is selected, only thing left is to turn the whole thing on
        CTRL.send_query("spif2file=connect:{4}:{0}:{1}={2},{3}".format(
                                    self.ct_recipe, self.vdif_props.threads,
                                    spif2file.outputFileName,
                                    'w' if (spif2file.outputFileName=="/dev/null" or allowOverwrite) else 'n',
                                    scan.name()
                                    ), [0])
        CTRL.send_query("spif2file=on:{0}:{1}".format(startByte if startByte else "", endByte if endByte else ""))

    def progress(self):
        r = self.DataSource.send_query("spif2file?")
        #  !spid2file? 0 : active : <start> : <current> : <end>
        #  0           1   2        3         4           5
        # spid2file never terminates automatically so we'll have to
        # go by the numbers ourselves
        (c, s, e) = (int(r[4]), int(r[3]), int(r[5])) if r[2]=="active" else (0, 0, 0)
        return None if c>=e else (c, s, e)

    #### This is the DestXFER part of the interface
    
    # The "open()" method in this local xfer stores the output file name
    def open(self, output):
        spif2file.outputFileName = output

    def setInputFormat(self, fmt):
        pass

    def rcv_bytecount(self):
        return 0

    # local cornerturning operation doesn't need in inputformat
    def needFormat(self):
        return False

#### Some helper functions for dealing with IN/MEM style
#### 'paths' - the path can be a runtime in seconds or
#### a runtime in amount of bytes
def mk_tstat_cmp(l, h, fn):
    def act_tstat_cmp(tsnew, tsold):
        if queries:
            print("act_tstat_cmp/tsnew=",tsnew)
            print("              tsold=",tsold)
        if len(tsnew)<5 or len(tsold)<5:
            return None
        cur = fn(tsnew, tsold)
        if queries:
            print("              cur  =",cur)
        return (cur, l, h) if cur<h else None
    return act_tstat_cmp

## Parse the path for runtime by time, bytes or indefinite
## we'll add a function
def add_done_yet(obj, path):
    # Set up a function that detects wether we're done or not
    # if there is no 'path', we run 'indefinitely'.
    # If there is a 'path' it's either an amount of bytes
    # or an amount of seconds that we should transfer
    # Progress is measured by comparing different fields
    # from "tstat=" command (so the values come from
    # jive5ab, not from us)
    #    !tstat = 0 : <transfer> : <time> : <step1> : <count1> : ...
    #    0        1   2            3        4         5
    if path:
        mo   = rxAmount.match( path )
        amt  = int(mo.group('amount'))
        unit = mo.group('unit')
        if unit=='s':
            # runtime in seconds
            obj.done_yet = mk_tstat_cmp(0, amt, lambda n, o: float(n[2]) - float(o[2]))
        else:
            # runtime in bytes
            obj.done_yet = mk_tstat_cmp(0, amt*scaleTableBinary[unit], lambda n, o: int(n[5]) - int(o[5]))
    else:
        # run indefinitely (well, until 2**63 bytes have been
        # transferred)
        obj.done_yet = mk_tstat_cmp(0, 2**63, lambda n, o: int(n[5]) - int(o[5]))


# in2file is also a simple, local transfer, which is both SRC and DST
class in2file(SourceXFER, DestXFER):
    outputFileName = None
    inputRuntime   = None

    def __init__(self, src_or_dst):
        # look at what flavour we were initialized with to decide
        # which of our base classes should be initialized
        if isinstance(src_or_dst, DataSource):
            self.isSource = True
            SourceXFER.__init__(self, src_or_dst)
            # we must change from arbitrary runtime to
            # runtime '0', because that one has access to the h/w
            r = self.DataSource.send_query("runtime?", [0])
            in2file.inputRuntime = r[2]
            self.DataSource.send_query("runtime=0", [0])
            add_done_yet(self, self.DataSource.source.path)
        else:
            self.isSource = False
            DestXFER.__init__(self, src_or_dst)

    #### Both types (SourceXFER and DestXFER) should be
    #### cancellable
    def cancel(self):
        if self.isSource:
            self.DataSource.send_query("in2file=disconnect", Mark5.anyReturn)
            self.DataSource.send_query("runtime={0}".format(in2file.inputRuntime), [0])
            in2file.inputRuntime = None
        else:
            in2file.outputFileName = None

    #### This is the SourceXFER part of the transfer
    # for a local transfer, the output data format is irrelevant
    def outputFormat(self, *args):
        return None

    def start(self, scan, dataip, **kwargs):
        CTRL      = self.DataSource
        CTRL.send_query("in2file=connect:{0}".format(in2file.outputFileName, [1]))
        CTRL.send_query("in2file=on")
        self.oldtstat = CTRL.send_query("tstat=")

    def progress(self):
        return self.done_yet(self.DataSource.send_query("tstat="), self.oldtstat)

    #### This is the DestXFER part of the interface

    # The "open()" method in this local xfer creates the
    # function that will run the actual command, apart from
    # two arguments the ".start()" will supply - the input
    # file name and the actual control interface
    def open(self, outputScanName):
        in2file.outputFileName = outputScanName

    def setInputFormat(self, fmt):
        pass

    def rcv_bytecount(self):
        return 0

    # local recording doesn't need to be aware of data format
    def needFormat(self):
        return False

### in2disk is basically "record=on:scan"
class in2disk(SourceXFER, DestXFER):
    outputScanName = None
    inputRuntime   = None

    def __init__(self, src_or_dst):
        # look at what flavour we were initialized with to decide
        # which of our base classes should be initialized
        if isinstance(src_or_dst, DataSource):
            self.isSource = True
            SourceXFER.__init__(self, src_or_dst)
            # we must change from arbitrary runtime to
            # runtime '0', because that one has access to the h/w
            r = self.DataSource.send_query("runtime?", [0])
            in2disk.inputRuntime = r[2]
            self.DataSource.send_query("runtime=0", [0])
            add_done_yet(self, self.DataSource.source.path)
        else:
            self.isSource = False
            DestXFER.__init__(self, src_or_dst)

    #### Both types (SourceXFER and DestXFER) should be
    #### cancellable
    def cancel(self):
        if self.isSource:
            self.DataSource.send_query("record=off", Mark5.anyReturn)
            self.DataSource.send_query("runtime={0}".format(in2file.inputRuntime), [0])
            in2disk.inputRuntime = None
        else:
            in2disk.outputScanName = None

    #### This is the SourceXFER part of the transfer
    # local transfer thus output format is irrelevant
    def outputFormat(self, *args):
        return None

    def start(self, scan, dataip, **kwargs):
        CTRL      = self.DataSource
        CTRL.send_query("record=on:{0}".format(in2disk.outputScanName))
        self.oldtstat = CTRL.send_query("tstat=")

    def progress(self):
        return self.done_yet(self.DataSource.send_query("tstat="), self.oldtstat)

    #### This is the DestXFER part of the interface

    # The "open()" method in this local xfer creates the
    # function that will run the actual command, apart from
    # two arguments the ".start()" will supply - the input
    # file name and the actual control interface
    def open(self, outputScanName):
        in2disk.outputScanName = outputScanName

    def setInputFormat(self, fmt):
        pass

    def rcv_bytecount(self):
        return 0

    # local recording doesn't need to be aware of data format
    def needFormat(self):
        return False

## split input (corner turn directly from telescope)
class spin2file(SourceXFER, DestXFER):
    outputFileName = None

    def __init__(self, src_or_dst):
        # look at what flavour we were initialized with to decide
        # which of our base classes should be initialized
        if isinstance(src_or_dst, DataSource):
            self.isSource = True
            SourceXFER.__init__(self, src_or_dst)

            # we must change from arbitrary runtime to
            # runtime '0', because that one has access to the h/w
            r = self.DataSource.send_query("runtime?", [0])
            spin2file.inputRuntime = r[2]
            self.DataSource.send_query("runtime=0", [0])

            # Analyze the "in://path" 'path' and form
            # a termination condition
            add_done_yet(self, self.DataSource.source.path)

            # Analyze the cornerturning setup, forget about the output format;
            # we don't have to set it because there is no receiving program
            (self.ct_setup, self.ct_recipe, self.vdif_props, dummy) = ct_setup_commands("spin2file")
            # We can already program the VDIF setup
            consume(map(lambda cmd: self.DataSource.send_query(cmd, [0]), self.ct_setup))
        else:
            self.isSource = False
            DestXFER.__init__(self, src_or_dst)

    #### Both types (SourceXFER and DestXFER) should be
    #### cancellable
    def cancel(self):
        if self.isSource:
            self.DataSource.send_query("spin2file=disconnect", Mark5.anyReturn)
            self.DataSource.send_query("runtime={0}".format(spin2file.inputRuntime), [0])
        else:
            spin2file.outputFileName = None

    #### This is the SourceXFER part of the transfer

    # note: for a local format translation, we can still ignore the output format
    def outputFormat(self, *args):
        return None

    def start(self, scan, dataip, **kwargs):
       # shorthand to the control interface
        CTRL = self.DataSource
        # Scan is selected, only thing left is to turn the whole thing on
        CTRL.send_query("spin2file=connect:{0}:{1}={2},{3}".format(
            self.ct_recipe, self.vdif_props.threads,
            spin2file.outputFileName,
            'w' if (spin2file.outputFileName=="/dev/null" or allowOverwrite) else 'n'
            ), [0])
        CTRL.send_query("spin2file=on")
        self.oldtstat = CTRL.send_query("tstat=")

    def progress(self):
        return self.done_yet(self.DataSource.send_query("tstat="), self.oldtstat)

    #### This is the DestXFER part of the interface

    # The "open()" method in this local xfer stores the output file name
    def open(self, output):
        spin2file.outputFileName = output

    def setInputFormat(self, fmt):
        pass

    def rcv_bytecount(self):
        return 0

    # local recording doesn't need to be aware of data format
    def needFormat(self):
        return False


# likewise for mem2file. it is also a simple, local transfer, which is both SRC and DST
class mem2file(SourceXFER, DestXFER):
    outputScanName = None

    def __init__(self, src_or_dst):
        # look at what flavour we were initialized with to decide
        # which of our base classes should be initialized
        if isinstance(src_or_dst, DataSource):
            self.isSource = True
            SourceXFER.__init__(self, src_or_dst)
            add_done_yet(self, self.DataSource.source.path)
        else:
            self.isSource = False
            DestXFER.__init__(self, src_or_dst)

    #### Both types (SourceXFER and DestXFER) should be
    #### cancellable
    def cancel(self):
        if self.isSource:
            self.DataSource.send_query("mem2file=close", Mark5.anyReturn)
            file2disk.inputRuntime = None
        else:
            file2disk.outputFileName = None

    #### This is the SourceXFER part of the transfer
    # for local transfer, output data format is irrelevant
    def outputFormat(self, *args):
        return None

    def start(self, scan, dataip, **kwargs):
        CTRL      = self.DataSource
        CTRL.send_query("mem2file=on:{0}".format(mem2file.outputScanName, [1]))
        self.oldtstat = CTRL.send_query("tstat=")

    def progress(self):
        return self.done_yet(self.DataSource.send_query("tstat="), self.oldtstat)

    #### This is the DestXFER part of the interface

    # The "open()" method in this local xfer creates the
    # function that will run the actual command, apart from
    # two arguments the ".start()" will supply - the input
    # file name and the actual control interface
    def open(self, outputScanName):
        mem2file.outputScanName = outputScanName

    def setInputFormat(self, fmt):
        pass

    def rcv_bytecount(self):
        return 0

    # local transfer doesn't need data format
    def needFormat(self):
        return False


def parse_stuff2net_reply(r):
    if len(r)<3:
        raise RuntimeError("The reply was too short, cannot check for (in)active")
    # if we get 7 fields or more, it always inclused start, current and end
    # (new style replies yield the byte counts of the last transfer in case
    # of inactive)
    (start, current, end) = List(map(int, r[4:7]) if len(r)>=7 else [None]*3)
    if r[2]=="inactive":
        # new style reply sends numbers
        if start is not None:
            # new style jive5ab - we can check if succesful finish
            # and return number of bytes that *should've* been
            # transferred in that case. Otherwise cry out loud
            if current==end:
                return [end-start]
            raise RuntimeError("Transfer did not finish correctly")
        # old style finish
        return None
    # must've been 'active', return the parsed numbers
    return (current, start, end)

## disk2net

class disk2net(SourceXFER):
    def __init__(self, datasource):
        super(disk2net, self).__init__( datasource )

    # return the mode that was input by the user, if any
    def outputFormat(self, scan):
        # if user gave external mode, accept that
        if mode is not None:
            return mode
        # ok use autodetection
        return detect_mode(self.DataSource, scan, scan_check)

    def start(self, scan, dataip, **kwargs):
        # shorthand to the control interface
        CTRL = self.DataSource

        # disk2net transfer is always coming from a DiskSource
        # (in case it isn't this is an error) so the "scanIds" that
        # are passed into us are really tuples, "(scan number, scan name)"
        (scanNum, scanName) = scan.scanId

        # Make sure to switch off resuming if not needed
        alreadyHave = kwargs.get("haveBytes", None) if doResume else None

        if doResume and alreadyHave is not None and CTRL.version()<supportsResume:
            loc = re.sub(":", "", CTRL.location())
            raise RuntimeError("Resume requested and file does exist remotely but "+
                                "the source jive5ab at {0} does not support resuming. ".format( loc ) +
                                "Please rerun with --allow_overwrite, --ignore_existing " +
                                "or upgrade the source jive5ab to at least {0}.".format( supportsResumeVersion ))

        # Process byte numbers to put them in the commands
        # they should be in: scan_set or disk2net
        se     = seByte2net(CTRL.startByte(), CTRL.endByte(), alreadyHave)

        # Attempt to set the correct scan and verify it did set.
        CTRL.send_query("scan_set={0}:{1}:{2}".format(scanNum, seString(se.scan_set.startByte),
                                                        seString(se.scan_set.endByte)), [0], timeout=600)

        reply = CTRL.send_query("scan_set?", [0])
        if hasattr(scan, 'duplicate'):
            suffix = uniqSuffix(scanNum)
            if scanName.endswith(suffix):
                # Ok, modify scan name
                # Find the right-most uniqSuffix(). Suppose that by chance
                # the scan with name "name.scan.2" would end up in scan
                # postions #1 and  #2 (duplicated) on the disk pack.
                # then the 2nd uniquefied scan name would be:
                #    "name.scan.2.scan.2"
                # if we then do string.sub(".scan.2", "") it would replace
                # *both* instances instead of only the last one
                # making our test for the scan's existence on the disk pack
                # fail!
                sidx = scanName.rfind(suffix)
                if sidx<0:
                    raise RuntimeError("Could not find unique suffix whilst it should be there?!")
                scanName = scanName[0:sidx]
            else:
                raise RuntimeError("Scan #{0} ({1}) was marked as duplicate but does not end with expected suffix '{2}'".format(
                                   scanNum, scanName, suffix))
        if not (int(reply[2])==scanNum and reply[3]==scanName):
            raise RuntimeError("Scan #{0} ({1}) is not that anymore, it is now #{2} ({3})".format(
                                scanNum, scanName, int(reply[2]), reply[3]))

        # Attempt to connect to remote side
        CTRL.send_query("disk2net=connect:{0:s}".format(dataip), [0,1])

        # And let it flow!
        # HV: 9 dec 2014  Roger H. finds that, sometimes, the connect
        #                 initiated by the previous command takes
        #                 so long that disk2net isn't connected
        #                 yet by the time we send it the "=on" command.
        #     4 jan 2016  BE finds that there's some race conditions; let's
        #                 fix them neatly
        r = CTRL.send_query("disk2net?", [0])
        endTime = time.time() + (max(timeOut, 10) if timeOut is not None else 10)
        while time.time()<endTime:
            if "connected" in r:
                break
            progress_print("\r>>>> Waiting for disk2net to connect")
            time.sleep(1)
            r = CTRL.send_query("disk2net?", [0])
        if "connected" not in r:
            raise RuntimeError("Timeout connecting to {0}".format(dataip))
        CTRL.send_query("disk2net=on:{0}:{1}".format(seString(se.disk2net.startByte), seString(se.disk2net.endByte)), [0])

        # HV: 9 dec 2014  GRRRR. Roger H. finds that, sometimes,
        #                 "disk2net=on" takes so long that it remains
        #                 in the connected state by the time we get to the
        #                 .progress(self) method. So we must wait here
        #                 for the status to become active
        #     4 jan 2016  BE finds that status could go to inactive
        #                 if the transfer finishes (very) quickly
        while True:
            r = CTRL.send_query("disk2net?", [0])
            if "connected" not in r:
                break
            progress_print("\r>>>> Waiting for disk2net to start")
            time.sleep(1)
        if "inactive" in r:
            # Sender immediately stopped sending because everything is already there!
            raise IgnoreFile

    def progress(self):
        return parse_stuff2net_reply( self.DataSource.send_query("disk2net?") )

    def cancel(self):
        self.DataSource.send_query("disk2net=disconnect", Mark5.anyReturn)

class disk2net_vbs(SourceXFER):
    def __init__(self, datasource):
        super(disk2net_vbs, self).__init__( datasource )

    # we may couple this to a remote VBS if the type is
    # different or it's two Mark6's?
    def outputFormat(self, scan):
        # if user gave external mode, accept that
        if mode is not None:
            return mode
        # ok use autodetection
        return detect_mode(self.DataSource, scan, scan_check)

    def start(self, scan, dataip, **kwargs):
        # shorthand to the control interface
        CTRL  = self.DataSource
        mark6 = hasattr(CTRL.source, 'mark6')
        disks = hasattr(CTRL.source, 'disks')

        # disk2net for FlexBuff/Mark6 only appeared in 2.6.1
        loc = re.sub(":", "", CTRL.location())
        if CTRL.version()<supportsResume:
            raise RuntimeError("Remote jive5ab at {0} [{1}] does not support FlexBuff/Mark6 disk2net, need >={2}".format(
                    loc, CTRL.get_version(), supportsResumeVersion ))
        
        supports6 = (CTRL.version()>=supportsMk6)

        # better be talking to a version of jive5ab who speaks '6 or
        # supports selecting of disks, in case either is needed
        if mark6 and not supports6:
            raise RuntimeError("Remote jive5ab [{0}] does not support Mark6, need >=2.6.0".format( CTRL.get_version() ))
        if disks and not supports6:
            raise RuntimeError("Remote jive5ab [{0}] does not support selecting disks/MSNs, need >=2.6.0".format( CTRL.get_version() ))

        # Make sure to switch off resuming if not needed
        alreadyHave = kwargs.get("haveBytes", None) if doResume else None

        if doResume and alreadyHave is not None and CTRL.version()<supportsResume:
            loc = re.sub(":", "", CTRL.location())
            raise RuntimeError("Resume requested and file does exist remotely but "+
                                "the source jive5ab at {0} does not support resuming. ".format( loc ) +
                                "Please rerun with --allow_overwrite, --ignore_existing " +
                                "or upgrade the source jive5ab to at least {0}.".format( supportsResumeVersion ))

        # Process byte numbers to put them in the commands
        # they should be in: scan_set or disk2net
        se     = seByte2net(CTRL.startByte(), CTRL.endByte(), alreadyHave)

        # before setting scan, we must set the disks, if the user gave any
        if disks:
            dsk    = CTRL.source.disks.replace(",", ":")
            reply  = CTRL.send_query("set_disks="+dsk, [0])

        # Always set the recording format
        CTRL.send_query("record=mk6:{0}".format(1 if mark6 else 0))

        # Attempt to set the correct scan and verify it did set.
        CTRL.send_query("scan_set={0}:{1}:{2}".format(scan.id(), \
                seString(se.scan_set.startByte),
                seString(se.scan_set.endByte)), [0], timeout=600)
        reply = CTRL.send_query("scan_set?", [0])

        # Attempt to connect to remote side and wait for it to be connected
        CTRL.send_query("disk2net=connect:{0:s}".format(dataip), [0,1], timeout=10)

        r = CTRL.send_query("disk2net?", [0])
        endTime = time.time() + (max(timeOut, 10) if timeOut is not None else 10)
        while time.time()<endTime:
            if "connected" in r:
                break
            progress_print("\r>>>> Waiting for disk2net to connect")
            time.sleep(1)
            r = CTRL.send_query("disk2net?", [0])
        if "connected" not in r:
            raise RuntimeError("Timeout connecting to {0}".format(dataip))

        # Now the dataflow can be turned on - wait until it actually starts
        CTRL.send_query("disk2net=on:{0}:{1}".format(seString(se.disk2net.startByte), seString(se.disk2net.endByte)),
                        [0], timeout=10)

        while True:
            r = CTRL.send_query("disk2net?", [0], timeout=10)
            if "connected" not in r:
                break
            progress_print("\r>>>> Waiting for disk2net to start")
            time.sleep(1)
        if "inactive" in r:
            # sender stopped immediately because everything already there!
            raise IgnoreFile

    def progress(self):
        return parse_stuff2net_reply( self.DataSource.send_query("disk2net?", timeout=100) )

    def cancel(self):
        self.DataSource.send_query("disk2net=disconnect", Mark5.anyReturn)


class file2net(SourceXFER):
    def __init__(self, datasource):
        super(file2net, self).__init__( datasource )

    # return the mode that was input by the user, if any
    # otherwise, do autodetection
    def outputFormat(self, scan):
        if mode is not None:
            return mode
        return detect_mode(self.DataSource, scan, file_check)

    def start(self, scan, dataip, **kwargs):
        # shorthand to the control interface
        CTRL = self.DataSource

        # if the remote end indicates they already have some
        # bytes, we don't have to start from the beginning
        # remember to deal with None as possible value passed in for
        # 'haveBytes'
        startByte   = CTRL.startByte()
        endByte     = CTRL.endByte()
        alreadyHave = kwargs.get("haveBytes", None)

        # do byte number administration here, but only if needed
        # (which is when we need to resume a transfer)
        if alreadyHave is not None and doResume:
            # file2net only supports numbers, not time based start/end
            if startByte and not rxBytenumOffset.match(startByte):
                raise RuntimeError("start byte number is invalid; only numbers supported, not time")
            if endByte and not rxBytenumOffset.match(endByte):
                raise RuntimeError("end byte number is invalid; only numbers supported, not time")

            # ok, resume requested and the remote thingy already has
            # data. Let's see what we can make of the byte numbers
            # We must alter start/end byte numbers in order to account
            # for the amount of bytes already present at the destination
            startByte = int(startByte) if startByte is not None else 0
            eofOffset = (startByte<0)

            # if startByte < 0, this meant offset wrt to end-of-file
            # we already have some bytes so this offset can then be lowered
            # For positive starByte or one that starts with '+' it doesn't
            # matter; the start position becomes absolute in that case
            startByte = startByte + alreadyHave
            if eofOffset and startByte>0:
                raise RuntimeError("Destination already has more bytes than requested via start byte number")

            # Now comes the end byte number
            relativeEnd = isRelativeToStart(endByte)
            endByte     = int(endByte) if endByte is not None else 0

            # endByte < 0 implies offset wrt to end of file, does not change
            # by the fact that we already have bytes
            # endByte > 0: two cases:
            #    - just a number: absolute end byte number, unaffected by
            #      how many bytes we already have
            #    - '+'<amount> (starting with an explicit '+') means: amount
            #      of bytes wrt to start. If we already have bytes at
            #      destination, then this relative amount must be adjusted
            if endByte>0 and relativeEnd:
                endByte = endByte - alreadyHave
                # if we now end up with a negative values, something's awry
                if endByte<0:
                    raise RuntimeError("Destination has more bytes than requested via end byte number")
                if endByte==0:
                    # file already there, nothing to do!
                    raise IgnoreFile

            # any of the byte offsets 0? Then they can be removed
            if startByte==0:
                startByte = None
            if relativeEnd:
                endByte = "+"+str(endByte)
            elif endByte==0:
                endByte = None

        CTRL.send_query("file2net=connect:{0:s}:{1:s}".format(dataip, scan.name()), [0])

        # Let's be ahead of the curve here. Wait for file2net to become connected
        r = CTRL.send_query("file2net?", [0])
        endTime = time.time() + (max(timeOut, 10) if timeOut is not None else 10)
        while time.time()<endTime:
            if "connected" in r:
                break
            progress_print("\r>>>> Waiting for file2net to connect")
            time.sleep(1)
            r = CTRL.send_query("file2net?", [0])
        if "connected" not in r:
            raise RuntimeError("Timeout connecting to {0}".format(dataip))

        CTRL.send_query("file2net=on:{0}:{1}".format(startByte if startByte else "", \
                                                     endByte if endByte else "", [0]))
        while True:
            r = CTRL.send_query("file2net?", [0])
            if "connected" not in r:
                break
            progress_print("\r>>>> Waiting for file2net to start")
            time.sleep(1)
        if "inactive" in r:
            # sender stopped immediately because everything already there!
            raise IgnoreFile

    def progress(self):
        return parse_stuff2net_reply( self.DataSource.send_query("file2net?") )

    def cancel(self):
        self.DataSource.send_query("file2net=disconnect", Mark5.anyReturn)

class vbs2net(SourceXFER):
    def __init__(self, datasource):
        super(vbs2net, self).__init__( datasource )
        # when configuring the number of readers/writers we make some
        # assumptions:
        #   * reading vbs disks is faster than writing (thus nDiskReader <
        #     nDiskWriter)
        # NOTE: 'nthread' is a global parameter, settable from the command
        #       line
        self.DataSource.send_query("vbs2net=nthread:{0}:{1}".format(nthread+1, nthread))

        # If someone configured disks to read from, then do support that
        disks     = hasattr(self.DataSource.source, 'disks')
        supports6 = (self.DataSource.version()>=supportsMk6)

        # better be talking to a version of jive5ab who speaks '6 or
        # supports selecting of disks, in case it's needed
        if disks and not supports6:
            raise RuntimeError("Remote jive5ab [{0}] does not support selecting disks/MSNs, need >=2.6.0".format( self.DataSource.get_version() ))

        # if the destination specified some disks to record on, do configure that now
        if disks:
            # set_disks = <pattern> [ : <pattern>...]
            # !set_disks = 0 : <nmatchingdisks>
            # 0            1   2
            dsk    = self.DataSource.source.disks.replace(",", ":")
            reply  = self.DataSource.send_query("set_disks="+dsk, [0])

    # no format translation
    def outputFormat(self, *args):
        return None

    def start(self, scan, dataip, **kwargs):
        # shorthand to the control interface
        CTRL = self.DataSource

        # On vbs -> vbs transfers we don't support start/end byte numbers
        # Take care to test for 'is not None' because an endbyte value of 0
        # would then also be considered False but we really really shouldn't support it
        if CTRL.startByte() is not None or CTRL.endByte() is not None:
            raise RuntimeError("VBS -> VBS transfers do not support start/end byte setting")
        # Note: this can take a while because both local and remote must
        # grovel over their disks to find the pieces of the recording
        # and negotiate what needs to be sent
        CTRL.send_query("vbs2net=connect:{0}:{1}".format(scan.name(), dataip), [0], timeout=600)

    def progress(self):
        r = self.DataSource.send_query("tstat=")
        # we don't know the length of the vbs recording (yet) so let's put
        # in something such that it's always ~98%
        if r[3]!="vbs2net":
            return None
        c = int(r[5])
        return (c, 0, c + max(1, int(float(c)*0.02)))

    def cancel(self):
        self.DataSource.send_query("vbs2net=disconnect", Mark5.anyReturn)


class in2net(SourceXFER):
    def __init__(self, datasource):
        super(in2net, self).__init__( datasource )
        add_done_yet(self, self.DataSource.source.path)

    # return the mode that was input by the user
    def outputFormat(self, scan):
        # if user gave external mode, accept that
        if mode is not None:
            return mode
        # ok use autodetection
        return detect_mode(self.DataSource, scan, mode_check)

    def start(self, scan, dataip, **kwargs):
        CTRL = self.DataSource
        CTRL.send_query("in2net=connect:{0}".format(dataip), [0])
        CTRL.send_query("in2net=on", [0])
        self.oldtstat = CTRL.send_query("tstat=")

    def progress(self):
        return self.done_yet(self.DataSource.send_query("tstat="), self.oldtstat)

    def cancel(self):
        self.DataSource.send_query("in2net=disconnect", Mark5.anyReturn)

class mem2net(SourceXFER):
    def __init__(self, datasource):
        super(mem2net, self).__init__( datasource )
        add_done_yet(self, self.DataSource.source.path)

    # no format translation
    def outputFormat(self, scan):
        # if user gave external mode, accept that
        if mode is not None:
            return mode
        # ok use autodetection
        return detect_mode(self.DataSource, scan, mode_check)

    def start(self, scan, dataip, **kwargs):
        CTRL = self.DataSource
        CTRL.send_query("mem2net=connect:{0}".format(dataip), [0])
        CTRL.send_query("mem2net=on", [0])
        self.oldtstat = CTRL.send_query("tstat=")

    def progress(self):
        return self.done_yet(self.DataSource.send_query("tstat="), self.oldtstat)

    def cancel(self):
        self.DataSource.send_query("mem2net=disconnect", Mark5.anyReturn)

# would it be possible to let spif2net look at the
# 'datasource' instance and set itself up for
# spid2net, spif2net and spin2net?
class split2net(SourceXFER):
    def __init__(self, datasource):
        super(split2net, self).__init__( datasource )

        # Check our actual datasource
        if isinstance(datasource, DiskSource):
            self.ct_cmd = "spid2net"
        elif isinstance(datasource, FileSource):
            self.ct_cmd = "spif2net"
        elif isinstance(datasource, InSource):
            self.ct_cmd = "spin2net"

            # we must change from arbitrary runtime to
            # runtime '0', because that one has access to the h/w
            r = self.DataSource.send_query("runtime?", [0])
            self.inputRuntime = r[2]
            self.DataSource.send_query("runtime=0", [0])

            # Analyze the "in://path" 'path' and form
            # a termination condition
            add_done_yet(self, self.DataSource.source.path)
        else:
            raise RuntimeError("Unsupported input data source for split2net {0}".format(datasource))

        # Analyze the cornerturning setup
        (self.ct_setup, self.ct_recipe, self.vdif_props, self.oFmt) = ct_setup_commands(self.ct_cmd)
        # We can already program the VDIF setup
        consume(map(lambda cmd: self.DataSource.send_query(cmd, [0]), self.ct_setup))

    # data format translation!
    def outputFormat(self, *args):
        return self.oFmt

    def start(self, scan, dataip, **kwargs):
        CTRL = self.DataSource

        supportSEByte = self.ct_cmd in ["spid2net", "spif2net"]
        sByte = CTRL.startByte() if supportSEByte else None
        eByte = CTRL.endByte()   if supportSEByte else None

        # When doing transfer from disk, we have to do some more work
        if self.ct_cmd=="spid2net":
            # For transfers from disk, the "scanIds" that
            # are passed into us are really tuples, "(scan number, scan name)"
            (scanNum, scanName) = (scan.id(), scan.name())

            # Attempt to set the correct scan and verify it did set.
            CTRL.send_query("scan_set={0}".format(scanNum), [0])
            reply = CTRL.send_query("scan_set?", [0])
            # If the current disk scan was marked as duplicate, it means
            # that some unique suffix has been appended. We must strip
            # that name to do our consistency checking
            if hasattr(scan, 'duplicate'):
                suffix = uniqSuffix(scanNum)
                if scanName.endswith(suffix):
                    # Ok, modify scan name
                    # Find the right-most uniqSuffix(). Suppose that by chance
                    # the scan with name "name.scan.2" would end up in scan
                    # postions #1 and  #2 (duplicated) on the disk pack.
                    # then the 2nd uniquefied scan name would be:
                    #    "name.scan.2.scan.2"
                    # if we then do string.sub(".scan.2", "") it would replace
                    # *both* instances instead of only the last one
                    # making our test for the scan's existence on the disk pack
                    # fail!
                    sidx = scanName.rfind(suffix)
                    if sidx<0:
                        raise RuntimeError("Could not find unique suffix whilst it should be there?!")
                    scanName = scanName[0:sidx]
                else:
                    raise RuntimeError("Scan #{0} ({1}) was marked as duplicate but does not end with expected suffix '{2}'".format(
                                       scanNum, scanName, suffix))
            if not (int(reply[2])==scanNum and reply[3]==scanName):
                raise RuntimeError("Scan #{0} ({1}) is not that anymore, it is now #{2} ({3})".format(
                                   scanNum, scanName, int(reply[2]), reply[3]))

        # (potential)scan is selected, only thing left is to turn the whole thing on
        # note that spif2net has a slightly different format:
        #  spin2net = connect : <splitmethod> : <threads>=<dest>
        #  spid2net = connect : <splitmethod> : <threads>=<dest>
        #  spif2net = connect : <filename>,r : <splitmethod> : <threads>=<dest>
        if self.ct_cmd == "spif2net":
            fmt = "{ct_cmd} = connect : {filename} : {splitmethod} : {threads}={dest}"
        else:
            fmt = "{ct_cmd} = connect : {splitmethod} : {threads}={dest}"
        CTRL.send_query(fmt.format( ct_cmd = self.ct_cmd, splitmethod = self.ct_recipe,
                                    threads = self.vdif_props.threads, dest = dataip,
                                    filename = scan.name()
                                    ), [0])
        CTRL.send_query("{ct_cmd}=on:{0}:{1}".format(sByte if sByte else "", eByte if eByte else "", ct_cmd=self.ct_cmd), [0])
        if self.ct_cmd == "spin2net":
            self.oldtstat = CTRL.send_query("tstat=")

    def progress(self):
        CTRL = self.DataSource
        if self.ct_cmd == "spin2net":
            return self.done_yet(CTRL.send_query("tstat="), self.oldtstat)
        else:
            r = CTRL.send_query(self.ct_cmd+"?")
            #  !sp...2net? 0 : active : <start> : <current> : <end>
            #  0           1   2        3         4           5
            # spid2file never terminates automatically so we'll have to
            # go by the numbers ourselves
            (c, s, e) = (int(r[4]), int(r[3]), int(r[5])) if r[2]=="active" else (0, 0, 0)
            return None if c>=e else (c, s, e)

    def cancel(self):
        self.DataSource.send_query("{0}=disconnect".format(self.ct_cmd), Mark5.anyReturn)
        if self.ct_cmd == "spin2net":
            self.DataSource.send_query("runtime={0}".format(self.inputRuntime), [0])



class net2disk(DestXFER):
    def __init__(self, datasink):
        super(net2disk, self).__init__( datasink )
        # Oops. net2disk must execute in the default runtime!
        self.DataSink.send_query("runtime=0", [0])

    def open(self, output):
        self.DataSink.send_query("net2disk=open:{0:s}".format(output), [0])

    def setInputFormat(self, fmt):
        if fmt is not None:
            self.DataSink.send_query("mode={0}".format(fmt), [0])

    def cancel(self):
        self.DataSink.send_query("net2disk=close", Mark5.anyReturn)

    def rcv_bytecount(self):
        # net2disk?  replies with:
        # net2disk? 0 : <status> : <scan nr> : <scan name> : <bytes>
        # 0         1   2          3           4             5
        r = self.DataSink.send_query("net2disk?", [0])
        return 0 if (r[2]=="inactive" or len(r)<6) else int(r[5])

    # net2disk should not require mode to be set
    def needFormat(self):
        return False

class net2file(DestXFER):
    def __init__(self, datasink):
        super(net2file, self).__init__( datasink )

    def open(self, output):
        # attempt to start net2file
        om   = 'w' if (output=="/dev/null" or allowOverwrite) else ('a' if doResume else 'n')
        qry  = "net2file=open:{0:s},{1}".format(output, om)
        r    = self.DataSink.send_query(qry, [0, 4])

        # If user sais it's ok to ignore existing files, so should we
        if int(r[1])==4:
            # must check if indeed it was because of a File exists
            exists = functools.reduce(lambda acc, x: acc or 'File exists' in x, r[2:], False)
            if exists:
                if not ignoreExisting:
                    raise RuntimeError("{0} exists and ignoreExisting is not set".format( output ))
                else:
                    # It's ok to ignore - raise an IgnoreFile exception
                    # such that the top level knows not to try to send this
                    raise IgnoreFile
            else:
                # died of another reason than existing file
                raise RuntimeError(r)
        # if net2file returns something like:
        # "!net2file = 0 : <number> ;" (in stead of "!net2file = 0 ;")
        # this means it has already <number> bytes of the file.
        # If resume is requested but we don't get a resumable reply
        # that's an error.
        if doResume and (len(r)<3 or self.DataSink.version()<supportsResume):
            loc = re.sub(":", "", self.DataSink.location())
            raise RuntimeError("Resume requested but the remote jive5ab at {0} is too old. ".format(loc) +
                    "Upgrade to at least {1}".format( supportsResumeVersion) +
                    " or rerun with --allow_overwrite or --ignore_existing.")

        # Only return not-None if there are bytes present remotely
        haveBytes = int(r[2]) if len(r)>=3 else 0
        return haveBytes if haveBytes>0 else None

    def setInputFormat(self, fmt):
        if fmt is not None:
            self.DataSink.send_query("mode={0}".format(fmt), [0])

    def rcv_bytecount(self):
        r = self.DataSink.send_query("net2file?")
        # this will currently fail, have to look into jive5ab code
        # 26 Jan 2015 "net2file?" reply fixed:
        #             net2file? => !net2file? 0 : active : <count>
        #                          0          1   2        3
        inactive  = len(r)>=3 and r[2]=="inactive"
        incorrect = len(r)<4
        return None if inactive or incorrect else int(r[3])

    def cancel(self):
        self.DataSink.send_query("net2file=close", Mark5.anyReturn)

    # net2file should not require mode to be set
    def needFormat(self):
        return False


class vbs_record(DestXFER):
    def __init__(self, datasink):
        super(vbs_record, self).__init__( datasink )

        # Are we supposed to record in Mark6 format? Or did the user
        # specify that we should record on a specific set of disks?
        mark6     = hasattr(self.DataSink.destination, 'mark6')
        disks     = hasattr(self.DataSink.destination, 'disks')
        supports6 = (self.DataSink.version()>=supportsMk6)

        # better be talking to a version of jive5ab who speaks '6 or
        # supports selecting of disks, in case either is needed
        if mark6 and not supports6:
            raise RuntimeError("Remote jive5ab [{0}] does not support Mark6, need >=2.6.0".format( self.DataSink.get_version() ))
        if disks and not supports6:
            raise RuntimeError("Remote jive5ab [{0}] does not support selecting disks/MSNs, need >=2.6.0".format( self.DataSink.get_version() ))

        # On systems that support Mark6, set the recording format explicitly
        if supports6:
            self.DataSink.send_query("record=mk6:{0}".format(1 if mark6 else 0), [0])

        # Also configure a different blocksize - the vbs file size
        # 256MB for flexbuf file chunks and 10000000 for Mark6 block size
        # which is the MIT Haystack d-plane block size
        self.DataSink.send_query("net_protocol=::{0}:8".format(10000000 if mark6 else "256M"))

        # Let's think about number of writers. Start with default of 4.
        nWrite = 4
        if disks:
            # set_disks = <pattern> [ : <pattern>...]
            # !set_disks = 0 : <nmatchingdisks>
            # 0            1   2
            dsk    = self.DataSink.destination.disks.replace(",", ":")
            reply  = self.DataSink.send_query("set_disks="+dsk, [0])
            nWrite = int(reply[2])

        # at the recorder, configure the number of disk writers
        self.DataSink.send_query("record=nthread:1:{0}".format(nWrite), [0])


    def setInputFormat(self, fmt):
        self.mode = fmt

    def open(self, output):
        # start a recording on the FlexBuff
        # apparently we do need a non-empty mode for that
        if self.mode is None:
            mode_required("record on FlexBuff/Mark6")
            raise RuntimeError("data format not set")
        self.DataSink.send_query("mode={0}".format(self.mode), [0])
        r = self.DataSink.send_query("record=on:{0:s}".format(output), [0])
        # We may have to deal with IgnoreFile - if the target recording
        # already exists this is indicated by the record= reply:
        #  !record = 0 : extending scan name with X;
        # in stead of a simple:
        #  !record = 0;
        if len(r) > 2:
            raise IgnoreFile

    def rcv_bytecount(self):
        # Poll the record status
        r = self.DataSink.send_query("record?", [0])
        # !record? 0 : inactive
        # !record? 0 : off                 [since 2.8.1, BeppeM suggests record? return on/off
        # !record? 0 : active : <bytecount>
        # !record? 0 : active : <scan name>   : <bytecount>  [2.8.0!]  [this breaks the field system!]
        # !record? 0 : on     : <scan number> : <scan name> : <bytecount> [2.8.1]
        # 0        1   2        3               4             5
        inactive  = len(r)>=3 and r[2] in ["inactive", "off"]
        incorrect = len(r)<4
        return None if (inactive or incorrect) else int(r[-1])

    def cancel(self):
        # record=off on FlexBuff can take quite a long time. We'll give it a
        # minute before giving up
        self.DataSink.send_query("record=off", Mark5.anyReturn, timeout=60)
        self.DataSink.send_query("mode=none", [0])

    # vbsrecord can only record known format
    def needFormat(self):
        return True


class net2vbs(DestXFER):
    def __init__(self, datasink):
        super(net2vbs, self).__init__( datasink )

        # When doing vbs=>vbs transfers there is no path allowed to be
        # specified on the destination VBS. The "disks" argument determines
        # where the data will be scattered, the scan name(s) will be
        # transferred in each transfer
        if self.DataSink.destination.path:
            (_dir, _file) = os.path.split( self.DataSink.destination.path )
            raise RuntimeError("vbs->vbs transfers do not allow the destination {0} to be set".format("file" if _file else "path"))

        # when configuring the number of readers/writers we make some
        # assumptions:
        #   * reading vbs disks is faster than writing (thus nDiskReader <
        #     nDiskWriter)
        #   * the number of netwriters == netreaders so they'll be a nice
        #     balanced match
        # configure number of netreaders + diskwriters at the receiving end
        # NOTE: 'nthread' is a global parameter which is settable from the
        #       command line
        self.DataSink.send_query("net2vbs=nthread:{0}:{1}".format(nthread, max(nthread+1, 8)), [0])

        # Deal with FlexBuff/Mark6 setup; format and destination disks
        mark6     = hasattr(self.DataSink.destination, 'mark6')
        disks     = hasattr(self.DataSink.destination, 'disks')
        supports6 = (self.DataSink.version()>=supportsMk6)


        # better be talking to a version of jive5ab who speaks '6 or
        # supports selecting of disks, in case either is needed
        if disks and not supports6:
            raise RuntimeError("Remote jive5ab [{0}] does not support selecting disks/MSNs, need >=2.6.0".format( self.DataSink.get_version() ))

        # if the destination specified some disks to record on, do configure that now
        if disks:
            # set_disks = <pattern> [ : <pattern>...]
            # !set_disks = 0 : <nmatchingdisks>
            # 0            1   2
            dsk    = self.DataSink.destination.disks.replace(",", ":")
            reply  = self.DataSink.send_query("set_disks="+dsk, [0])

    def setInputFormat(self, fmt):
        pass

    def open(self, output):
        # We ignore the output name because the "sync" method will send the
        # file name in each synchronization transfer
        self.DataSink.send_query("net2vbs=open", [0])

    def rcv_bytecount(self):
        return 0

    def cancel(self):
        self.DataSink.send_query("net2vbs=close", Mark5.anyReturn, timeout=10)

    # net2vbs doesn't need format
    def needFormat(self):
        return False

############################################################################
##
##  All possible transfer end points have been defined, now we patch
##  them up together to form the supported transfers
##
############################################################################


##### lcl transfers only allowed if media are different
def lcl_xfer(src, dst):
    matrix = {
        (media_type.DISK, media_type.FILE): (disk2file,     DiskSource, disk2file,     FileDest, True),
        (media_type.FILE, media_type.DISK): (file2disk,     FileSource, file2disk,     DiskDest, False),
        (media_type.IN,   media_type.FILE): (in2file,       InSource,   in2file,       FileDest, False),
        (media_type.IN,   media_type.DISK): (in2disk,       InSource,   in2disk,       DiskDest, False),
        (media_type.MEM,  media_type.FILE): (mem2file,      MemSource,  mem2file,      FileDest, False),
        (media_type.VBS,  media_type.FILE): (disk2file_vbs, VBSSource,  disk2file_vbs, FileDest, True),
        (media_type.MK6,  media_type.FILE): (disk2file_vbs, VBSSource,  disk2file_vbs, FileDest, True)
    }
    key = (src.mediaType, dst.mediaType)
    if not key in matrix:
        raise ValueError("Unsupported local transfer {0} => {1}".format(src.mediaType, dst.mediaType))
    return matrix[ key ]

## local transfer with cornerturning
def lcl_ct_xfer(src, dst):
    matrix = {
        (media_type.DISK, media_type.FILE): (spid2file, DiskSource, spid2file, FileDest, False),
        (media_type.FILE, media_type.FILE): (spif2file, FileSource, spif2file, FileDest, False),
        (media_type.IN,   media_type.FILE): (spin2file, FileSource, spin2file, FileDest, False)
    }
    key = (src.mediaType, dst.mediaType)
    if not key in matrix:
        raise ValueError("Unsupported local corner turning transfer {0} => {1}".format(src.mediaType, dst.mediaType))
    return matrix[ key ]

#### The remote transfers: *2net + net2*
# here the media may be identical
def remote_xfer(src, dst):
    matrix = {
        (media_type.DISK, media_type.DISK): (disk2net,     DiskSource, net2disk,   DiskDest, False),
        (media_type.DISK, media_type.FILE): (disk2net,     DiskSource, net2file,   FileDest, True),
        (media_type.DISK, media_type.ETD):  (disk2etd,     DiskSource, disk2etd,   ETDDest,  True),
        (media_type.FILE, media_type.DISK): (file2net,     FileSource, net2disk,   DiskDest, False),
        (media_type.FILE, media_type.FILE): (file2net,     FileSource, net2file,   FileDest, True),
        (media_type.IN,   media_type.DISK): (in2net,       InSource,   net2disk,   DiskDest, False),
        (media_type.IN,   media_type.FILE): (in2net,       InSource,   net2file,   FileDest, False),
        (media_type.IN,   media_type.VBS):  (in2net,       InSource,   vbs_record, VBSDest,  False),
        (media_type.IN,   media_type.MK6):  (in2net,       InSource,   vbs_record, VBSDest,  False),
        (media_type.MEM,  media_type.DISK): (mem2net,      MemSource,  net2disk,   DiskDest, False),
        (media_type.MEM,  media_type.FILE): (mem2net,      MemSource,  net2file,   FileDest, False),
        (media_type.FILE, media_type.VBS):  (file2net,     FileSource, vbs_record, VBSDest,  False),
        (media_type.FILE, media_type.MK6):  (file2net,     FileSource, vbs_record, VBSDest,  False),
        (media_type.DISK, media_type.VBS):  (disk2net,     DiskSource, vbs_record, VBSDest,  False),
        (media_type.DISK, media_type.MK6):  (disk2net,     DiskSource, vbs_record, VBSDest,  False),
        (media_type.VBS,  media_type.VBS):  (vbs2net,      VBSPattern, net2vbs,    VBSDest,  True),
        (media_type.VBS,  media_type.FILE): (disk2net_vbs, VBSSource,  net2file,   FileDest, True),
        (media_type.MK6,  media_type.FILE): (disk2net_vbs, VBSSource,  net2file,   FileDest, True),
        (media_type.VBS,  media_type.ETD):  (disk2etd_vbs, VBSSource,  disk2etd_vbs,ETDDest, True),
        (media_type.MK6,  media_type.ETD):  (disk2etd_vbs, VBSSource,  disk2etd_vbs,ETDDest, True),
        (media_type.VBS,  media_type.DISK): (disk2net_vbs, VBSSource,  net2disk,   DiskDest, False),
        (media_type.MK6,  media_type.DISK): (disk2net_vbs, VBSSource,  net2disk,   DiskDest, False),
        (media_type.MK6,  media_type.VBS):  (disk2net_vbs, VBSSource,  vbs_record, VBSDest,  False),
        (media_type.MK6,  media_type.MK6):  (disk2net_vbs, VBSSource,  vbs_record, VBSDest,  False),
    }
    key = (src.mediaType, dst.mediaType)
    if not key in matrix:
        raise ValueError("Unsupported remote transfer {0} => {1}".format(src.mediaType, dst.mediaType))
    return matrix[ key ]

# remote corner turners
def remote_ct_xfer(src, dst):
    matrix = {
        (media_type.DISK, media_type.DISK): (split2net, DiskSource, net2disk,   DiskDest, False),
        (media_type.DISK, media_type.FILE): (split2net, DiskSource, net2file,   FileDest, False),
        (media_type.DISK, media_type.VBS):  (split2net, DiskSource, vbs_record, VBSDest,  False),
        (media_type.DISK, media_type.MK6):  (split2net, DiskSource, vbs_record, VBSDest,  False),
        (media_type.FILE, media_type.DISK): (split2net, FileSource, net2disk,   DiskDest, False),
        (media_type.FILE, media_type.FILE): (split2net, FileSource, net2file,   FileDest, False),
        (media_type.FILE, media_type.VBS):  (split2net, FileSource, vbs_record, VBSDest,  False),
        (media_type.FILE, media_type.MK6):  (split2net, FileSource, vbs_record, VBSDest,  False),
        (media_type.IN,   media_type.DISK): (split2net, InSource,   net2disk,   DiskDest, False),
        (media_type.IN,   media_type.FILE): (split2net, InSource,   net2file,   FileDest, False),
        (media_type.IN,   media_type.VBS):  (split2net, InSource,   vbs_record, VBSDest,  False),
        (media_type.IN,   media_type.MK6):  (split2net, InSource,   vbs_record, VBSDest,  False),
    }
    key = (src.mediaType, dst.mediaType)
    if not key in matrix:
        raise ValueError("Unsupported remote transfer {0} => {1}".format(src.mediaType, dst.mediaType))
    return matrix[ key ]

# One entry point which decides if it's a local or a remote transfer
# Will return a quad-tuple with type constructors:
#    (src_xfer_type, src_type, dst_xfer_type, dst_type)
#
# The calling code can construct the DataSource and DataSink from
# the 'src_type' and 'dst_type'. Then loop over all the entries
# in the DataSource and transfer them to the DataSink, using
# the transfer types to set up the source, destination end points
def xfer_selector(src, dst):
    # we have a matrix of endpoints (disk->file, file->disk, etc)
    # and the source/destination ip addresses; now we
    # decide which transfers to choose
    #  (e.g. "disk(local) -> file(local) => disk2file"
    #        "disk(X)     -> file(Y)     => disk2net + net2file"
    matrix = {
            (True,  False):  lcl_xfer,
            (True,  True ):  lcl_ct_xfer,
            (False, False):  remote_xfer,
            (False, True):   remote_ct_xfer
        }
    lcl = src.controlIP == dst.controlIP and src.controlPort == dst.controlPort
    return matrix[ (lcl, do_corner)  ](src, dst)


## context manager for the transfer type
class actual_xfer(object):
    def __init__(self, sx, dx):
        self.sourceXFER = sx
        self.destXFER   = dx

    def __enter__(self):
        return self

    def __exit__(self, type, value, traceback):
        self.sourceXFER.cancel()
        self.destXFER.cancel()

def attr(obj):
    import inspect
    return List(filter(lambda x: x[0][0]!='_', inspect.getmembers(obj, lambda x: not inspect.ismethod(x))))

## context manager for a transfer - this means we have
## the option of doing a clean shutdown
class xfer_context:
    def __init__(self, src, dst):
        self.srcLocation = src
        self.dstLocation = dst
        # Upon construction get the 4 types of the objects we'll need for
        # the transfer
        (self.sxtype, self.stype, self.dxtype, self.dtype, resumable) = xfer_selector(self.srcLocation, self.dstLocation)
        if doResume and not resumable:
            raise RuntimeError("Sadly, this transfer cannot be resumed. Re-run with --ignore_existing or --allow_overwrite, if that helps")

    def __enter__(self):
        # Upon entering the context, we create the DataSource and DataSink objects
        self.dataSource = self.stype(self.srcLocation)
        self.dataSink   = self.dtype(self.dstLocation)
        # Check if this will work
        if len(self.dataSource)>1 and not self.dataSink.multiple_outputs():
            raise RuntimeError("Source specifies >1 scan but destination is explicitly set")
        return self

    def __exit__(self, tp, val, tb):
        # make sure echo is on again
        self.dataSource.echo_on()

        # and cleanup
        self.dataSource.cleanup()
        self.dataSink.cleanup()
        if not (tp is None and val is None and tb is None):
            if queries:
                print(traceback.print_exception(tp, val, tb))
            else:
                print(val)
            sys.exit( -1 )
        return True

    def __call__(self):
        # Ok, we're requested to actually do the transfers
        dataSource = self.dataSource
        dataSink   = self.dataSink
        with actual_xfer(self.sxtype(dataSource), self.dxtype(dataSink)) as xfer:
            sxfer = xfer.sourceXFER
            dxfer = xfer.destXFER
            for scan in dataSource:
                outname = dataSink.compute_outputname(scan)
                print(dataSource.location()+scan.name(), "=>", dataSink.location()+outname)

                try:
                    # configure different input format for the receiver, in case it's not the same as
                    # the source data format [ie cornerturning data format X into legacy VDIF]
                    # But only do it if the destination indicates it needs it.
                    if dxfer.needFormat():
                        dxfer.setInputFormat( sxfer.outputFormat(scan) )
                    nbyte = dxfer.open(outname)
                    sxfer.start(scan, dataSink.dataIP(), haveBytes=nbyte)
                except IgnoreFile:
                    print("\r{0} already exists, skipping".format(outname))
                    dxfer.cancel()
                    sxfer.cancel()
                    # need to give udt quite-some-time FFS
                    if protocol=="udt":
                        time.sleep(10)
                    continue

                # turn echo off whilst polling for completeness
                dataSource.echo_off()
                dataSink.echo_off()

                progress = Progress(45) if verbose else DummyProgress()
                # new enough jive5ab's will better inform us about number
                # of bytes read and written
                nbyte      = None
                dxInterval = 60
                while True:
                    p = sxfer.progress()
                    # also keep remote socket alive
                    if dxInterval==0:
                        dxfer.rcv_bytecount()
                        dxInterval = 60
                    if p is None:
                        break
                    if len(p)==1:
                        # new style return value: transfer completed
                        # succesfully; the return value is the number of
                        # bytes sent
                        nbyte = p[0]
                        break
                    # transfer not finished yet, update progress display & wait a bit more
                    # but only if there are no 'None's in p!
                    #   JonQ 21/Apr/2017 debug finds that file2net can reply
                    #                    literally with:
                    #                    !file2net?  0 : active : 144.6.253.12 ;
                    #                    Arguably this is an error in the
                    #                    state (disk2net.cc:105) because
                    #                    is RUNNING but not CONNECTED
                    #                    (anymore) so the byte numbers don't
                    #                    get sent. But by fixing it here we
                    #                    at least are safe against any
                    #                    stuff2net reply being substandard.
                    # Note: do not use "if all(p):" because then, if all the
                    # bytecounts are zero, it won't update the progress
                    # because 0 is not true ...
                    if None not in p:
                        progress(*p)
                    time.sleep(1)
                    dxInterval = dxInterval - 1
                # done polling - we can safely put echo back on
                dataSource.echo_on()
                dataSink.echo_on()

                # wait for remote end to flush all data
                oldbytes    = dxfer.rcv_bytecount()
                n_time_same = 0
                progress.say("\rWaiting for remote end to flush ... "+str(oldbytes))
                while n_time_same<xferDoneCount:
                    time.sleep(1)
                    newbytes = dxfer.rcv_bytecount()
                    if newbytes==oldbytes:
                        # still same value as seen last time
                        n_time_same += 1
                        continue
                    # saw a different byte count so re-start counting
                    n_time_same = 0
                    oldbytes    = newbytes
                    progress.say("\rWaiting for remote end to flush ... "+str(oldbytes))
                # do cleanup at both ends
                sxfer.cancel()
                dxfer.cancel()
                progress.done()
                # give UDT some time to close the listening file descriptor ...
                # need to give udt quite-some-time FFS
                if protocol=="udt":
                    time.sleep(10)
                # if number-of-bytes sent is known, we can verify if all of
                # 'm were written to the destination
                if nbyte is not None and newbytes is not None and (nbyte!=newbytes):
                    raise RuntimeError("Not all bytes sent were written to the destination")


class catcher(object):
    def __init__(self):
        pass

    def __enter__(self):
        return self

    def __exit__(self, tp, val, tb):
        # did we exit because of an exception?
        if not (tp is None and val is None and tb is None):
            # ok, we must indicate this
            if queries:
                traceback.print_exception(tp, val, tb)
            else:
                print(val)
            sys.exit( -1 )
        return True

# returns None if the argument wasn't present, tp(<value>) if it was
# (such that it will give an exception if e.g. you expect int but
#  the user didn't pass a valid int
def get_val(arg, tp=str):
    conversion_error = False
    try:
        # is 'arg' given?
        aidx = sys.argv.index(arg)  # raises ValueError if not found FFS
        aval = sys.argv[aidx+1]     # raises IndexError

        # Check it doesn't start with a '-'!
        if aval[0]=='-':
            raise RuntimeError("Option {0} expects argument, got another option '{1}'".format(arg, aval))

        # remove those arguments
        del sys.argv[aidx]; del sys.argv[aidx]
        # now set 'conversion_error' to True because the following
        # statement could (also) raise a ValueError (like the
        # "sys.argv.index()"). FFS Python! So we must take measures to tell
        # them apart
        conversion_error = True
        return tp(aval)
    except ValueError:
        if conversion_error:
            raise
        # no 'arg' given, don't complain
        return None
    except IndexError:
        # Mission option value to option
        raise RuntimeError("Missing optionvalue to {0}".format(arg))

# Input: options: list of strings/command line flags
#        flag: string to find ("-udt", "--allow-overwrite" etc)
# Returns flag if flag in options, else None
# side effect: removes the flag from options!
def pop_option(options, flag):
    try:
        fidx = options.index(flag)
        del options[fidx]
        return flag
    except ValueError:
        #  flag not found in options
        return None

def mode_required(app):
    print("#"*24)
    print("""
In order to {0} the system *must* know the format of the input data.

To this effect, please add a '-mode <mode>' argument to the command line.

The <mode> parameter takes the following, canonicalized, form.  In all
cases, if necessary, the track data rate will be automatically inferred by
jive5ab from the complete setting.

    MARK5B-<total Mbps>-<# channels>-<# bits per sample>
          MARK5B-2048-16-2      for 2 Gbps, 16 ch Mark5B data (32 MHz bands)
          MARK5B-128-4-1        for 128 Mbps, 4ch Mark5B data

    VDIF[L]_<data size>-<total Mbps>-<# channels>-<# bits per sample>
          We only support simple VDIF: the same number of channels and the
          same number of bits-per-sample for each thread. The actual VDIF
          frame size is automatically computed from the <data size> and
          wether it is legacy VDIF ("VDIFL", 16 byte header) or VDIF (32
          byte header).

          VDIFL_5000-1024-16-2  for 1 Gbps legacy VDIF with 5000-byte data
                                array size
          VDIF_8192-4096-32-2   for 4 Gbps VDIF with 8192-byte data array
                                size

    [MKIV|VLBA]<i>_<j>-<total Mbps>-<# channels>-<# bits per sample>
                 (where <i>_<j> is the fan-in/fan-out, e.g. '1_2')
          MKIV1_2-1024-16-2     for 1 Gbps 16ch MarkIV data in 64 tracks@16 Mbps
          VLBA2_1-128-8-2       for 128 Mbps 8ch VLBA data in 8 tracks@16 Mbps

""".format(app))
    print("#"*24)


##################
# the main program
##################

if __name__ == "__main__":
    #########################
    ## Check command line
    #########################

    # Was '-h' requested?
    if len(sys.argv)==1 or '-h' in sys.argv:
        usage()
        sys.exit( 0 )

    # Or maybe '-v' (version)
    if '-v' in sys.argv:
        print(version)
        sys.exit( 0 )

    # before actually starting to process the args ... we must find the "-p
    # <port>" and extract it manually (the alternative would be to say
    # "p=<port>" but that's a bit ugly and looks too much like dd(1).
    p = get_val('-p', int)
    if p:
        dataport = p
    m = get_val('-m', int)
    if m:
        if m<64:
            raise RuntimeError("Value '{0}' for MTU is lower than ethernet minimum of 64".format(m))
        if m<1500:
            print("WARN: mtu set to value <1500. Probably negative impact on transfer speed")
        mtu = m
    n = get_val('-n', int)
    if n:
        if n<=1:
            raise RuntimeError("Illegal number of parallel file transfers: {0}".format(n))
        nthread = n
    # Check if a rate was given
    rate = get_val('-r')
    if rate:
        # convert rate to bits per second
        rate = float(procByte(rate, float, rxBytenumRate, scaleTableMetric))
        if rate==0:
            raise RuntimeError("Data rate 0 (zero) is not supported")
        # ipd in nano seconds = (mtu*8 / rate) * 1.0e9
        ipd = int( (float(mtu)*8 / rate)*1.0e9 )

    # override time-out value?
    timeOut = get_val('-t')
    if timeOut:
        timeOut = float(timeOut)

    # Override expectation count for the heuristic when a transfer is 'done'
    doneCount = get_val('-e', int)
    if doneCount is not None:
        if doneCount<1:
            raise RuntimeError("Cannot expect less then 1 repeated byte count value!")
        xferDoneCount = doneCount

    # Extract/check cornerturning options (phase 1)
    # [if we record to VBS we *must* have a mode, but we must first
    #  parse the DST uri before we know that ..]
    cornerturn = get_val('-ct')
    mode       = get_val('-mode')
    vdif       = get_val('-vdif')

    # If vdif parameters are set, we do cornerturning
    do_corner  = bool(vdif)

    # Split remaining commandline in options and arguments
    (opts, args) = partition(lambda x: re.match("^-", x), sys.argv[1:])

    # require two arguments
    if len(args)!=2:
        usage()
        sys.exit( 1 )

    # UDT/SRT requested?
    udt = pop_option(opts, '-udt')
    srt = pop_option(opts, '-srt')
    # can't have both!
    if udt or srt:
        if udt and srt:
            raise RuntimeError("Cannot have both -udt and -srt flags at the same time")
        protocol = "udt" if udt else "srt"

    if pop_option(opts, '-q'):
        verbose=False

    if pop_option(opts, '-a'):
        duplicates=True

    # hidden option '-d' - turn on debugging
    if pop_option(opts, '-d'):
        queries=True

    # Rate limiting with tcp protocol is nonsense
    if rate and "tcp" in protocol:
        print("Rate limiting over TCP is not supported")
        sys.exit( 1 )

    if verbose:
        print("""{0}
    copy VLBI data from somewhere to elsewhere
               (c) H. Verkouter
""".format(version))

    # Note: we've already checked that there's exactly two arguments!
    src = parseURI(args[0], uri_type.SRC)
    dst = parseURI(args[1], uri_type.DST)

    # Now that we've parsed the SRC and DST, it is time to check again if we
    # need the mode argument: if we are recording *to* VBS but not *from*
    # VBS.
    record_vbs = (dst.mediaType in [media_type.VBS, media_type.MK6] and src.mediaType!=media_type.VBS)

    if (do_corner or record_vbs):
        #if mode is None:
        #    if do_corner:
        #        mode_required("cornerturn a data stream into its individual channels")
        #    else:
        #        mode_required("record onto a {0} system".format("Mark6" if hasattr(dst, 'mark6') else "FlexBuf"))
        #    raise RuntimeError,"The input mode (data format) must be set"
        # ok mode was given
        if mode is not None:
            mode = mode.upper()
    else:
        # if the mode has been set for a transfer that does not need/want
        # it, it is an error
        if bool(mode):
            raise RuntimeError("A '-mode <mode>' argument was given but the current transfer does not want it.")

    # In case DST is e-transfer daemon, udt, port, mtu and rate options are not allowed
    if dst.mediaType is media_type.ETD and (p or m or n or rate or protocol=="udt"):
        raise RuntimeError("When using e-transfer as DST, -m MTU, -r RATE, -n NUMPARALLEL and -udt options are forbidden")

    # In case dst addresses localhost and dataIP is not given,
    # we replace the dataIP with the external IP address of this
    # machine [only if there's a unique IP address, that is]
    if (dst.controlIP=="localhost" or dst.controlIP=="127.0.0.1") and \
       (src.controlIP!="localhost" and src.controlIP!="127.0.0.1") and dst.dataIP is None:
        dst.dataIP = get_local_ext_ip()
        if dst.dataIP is None:
            allIPs = get_local_ext_ip(False)
            print("*****************************************************")
            print("*                                                   *")
            print("*   It looks like you're copying into this machine  *")
            print("*   but m5copy cannot infer the external IPv4       *")
            print("*   address to use for this machine.                *")
            print("*                                                   *")
            print("*   Please specify the external IPv4 address to     *")
            print("*   use in the destination of your transfer, eg:    *")
            print("*                                                   *")
            print("*      m5copy SRC file://192.168.1.4/path/          *")
            print("*      m5copy SRC file://my.host.name/path/         *")
            if allIPs:
                line = "*                                                   *"
                print(line)
                print("*  Detected external addresses:                     *")
                def p(x):
                    print("*      {0}{1:{2}}*".format( x, "", len(line)-len(x)-8 ))
                consume(map(p, allIPs))
            print("*                                                   *")
            print("*****************************************************")
            sys.exit( 1 )

    # IF the '-rt' (realtime) flag is given, only allow that
    # IF the src.media_type is 'IN' or 'MEM'!
    if pop_option(opts, '-rt'):
        if not (src.mediaType in [media_type.IN, media_type.MEM]):
            raise RuntimeError("-rt (realtime) flag only supported with source URI of type 'IN' or 'MEM'")
        protocol="udps"

    # absolutely hidden option - allow overwriting of existing data files
    allowOverwrite = pop_option(opts, '--allow_overwrite') or pop_option(opts, '--allow-overwrite')
    if allowOverwrite and dst.mediaType==media_type.FILE:
        if not pop_option(opts, '--blame_guifre'):
            print("****************************************************")
            print("*   allow_overwrite requested but you haven't      *")
            print("*   indicated you know what you're doing.          *")
            print("*                                                  *")
            print("*   This option will potentially overwrite         *")
            print("*   existing file(s) at the destination.           *")
            print("*                                                  *")
            print("*   Please add the following command-line flag     *")
            print("*   as well to acknowledge you understand the      *")
            print("*   consequences.                                  *")
            print("*                                                  *")
            print("*     --blame_guifre                               *")
            print("*                                                  *")
            print("*   Thank you for flying m5copy!                   *")
            print("****************************************************")
            sys.exit( 1 )
    # Ignore existing
    ignoreExisting = pop_option(opts, '--ignore_existing') or pop_option(opts, '--ignore-existing')
    doResume       = pop_option(opts, '--resume')

    # Check orthogonality?
    if [allowOverwrite, ignoreExisting, doResume].count(True)>1:
        print("Please check consistency. Only one of:")
        print("   --allow_overwrite")
        print("   --ignore_existing")
        print("   --resume")
        print("may be given. They are mutually exclusive.")
        sys.exit(3)

    # allow overwrite cannot be honoured when DST is Mk6/VBS/mk5
    # because transferring to any of these basically starts a new recording
    # which can never be resumed or overwritten
    # (even though vbs=>vbs does not start a new recording, it still can't
    # do allow-overwrite)
    if allowOverwrite and dst.mediaType is not media_type.FILE:
        print("*********************************************************")
        print("   The transfer {0} to {1} ".format(src.mediaType, dst.mediaType))
        print("   does not support overwriting")
        print("*********************************************************")
        sys.exit( 2 )
    # IgnoreExisting cannot be honoured by vbs=>vbs
    if ignoreExisting and src.mediaType==media_type.VBS and dst.mediaType==media_type.VBS:
        print("*********************************************************")
        print("   The transfer {0} to {1} ".format(src.mediaType, dst.mediaType))
        print("   does not support ignoring existing recordings")
        print("*********************************************************")
        sys.exit( 3 )

    # final check: any unprocessed options left?
    # because that means we didn't understand them
    if opts:
        print("*********************************************************")
        print("Unrecognized command line option{0} present:".format( "" if len(opts)==1 else "s" ))
        print(" ".join(opts))
        print("*********************************************************")
        sys.exit( 4 )

    if verbose:
        print(src," ===> ",dst)

    with catcher() as c:
        with xfer_context(src, dst) as xfer:
            xfer()
